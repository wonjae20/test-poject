{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "yolov3_training_furits (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae20/test-poject/blob/main/yolov3_training_furits_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpvZnHe4OeLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "fc5d6567-4fda-4b45-d994-a4615b6e159e"
      },
      "source": [
        "import os, sys \n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('./drive')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-83982e1d4980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 254\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "os.chdir(r'/content/drive/MyDrive/fruit/train')\n",
        "path = r'/content/drive/MyDrive/fruit/train'\n",
        "\n",
        "def xml_to_txt(path):\n",
        "    txt_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        everyrow_xml_list = []\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        everyrow_xml_list.append(path + '/' + root.find('filename').text)\n",
        "        for member in root.findall('object'):\n",
        "            xmin = str(int(member[4][0].text))\n",
        "            ymin = str(int(member[4][1].text))\n",
        "            xmax = str(int(member[4][2].text))\n",
        "            ymax = str(int(member[4][3].text))\n",
        "            if xmin==\"0\":\n",
        "                xmin=\"1\"\n",
        "            if ymin==\"0\":\n",
        "                ymin=\"1\"\n",
        "            if xmax==\"0\":\n",
        "                xmax=\"1\"\n",
        "            if ymax==\"0\":\n",
        "                ymax=\"1\"\n",
        "            if member.find('name').text == 'apple':\n",
        "              obj_class = \"0\"\n",
        "            elif member.find('name').text == 'banana':\n",
        "              obj_class = \"1\"\n",
        "            elif member.find('name').text == 'orange':\n",
        "              obj_class = \"2\"\n",
        "            value = xmin+','+ymin+','+xmax+','+ymax+','+obj_class\n",
        "            everyrow_xml_list.append(value)\n",
        "        txt_list.append(everyrow_xml_list)#image_path x_min,y_min,x_max,y_max,class_id  x_min,y_min,x_max,y_max,class_id ……\n",
        "    return txt_list\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    image_path = path\n",
        "    xml2txt_list = xml_to_txt(image_path)\n",
        "    with open(r'/content/drive/MyDrive/fruit/train.txt', 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f,delimiter=' ')\n",
        "        writer.writerows(xml2txt_list)\n",
        "    print('Successfully converted xml to txt.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "qSBfkOaC4FxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "os.chdir(r'/content/drive/MyDrive/fruit/test')\n",
        "path = r'/content/drive/MyDrive/fruit/test'\n",
        "\n",
        "def xml_to_txt(path):\n",
        "    txt_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        everyrow_xml_list = []\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        everyrow_xml_list.append(path + '/' + root.find('filename').text)\n",
        "        for member in root.findall('object'):\n",
        "            xmin = str(int(member[4][0].text))\n",
        "            ymin = str(int(member[4][1].text))\n",
        "            xmax = str(int(member[4][2].text))\n",
        "            ymax = str(int(member[4][3].text))\n",
        "            if xmin==\"0\":\n",
        "                xmin=\"1\"\n",
        "            if ymin==\"0\":\n",
        "                ymin=\"1\"\n",
        "            if xmax==\"0\":\n",
        "                xmax=\"1\"\n",
        "            if ymax==\"0\":\n",
        "                ymax=\"1\"\n",
        "            if member.find('name').text == 'apple':\n",
        "              obj_class = \"0\"\n",
        "            elif member.find('name').text == 'banana':\n",
        "              obj_class = \"1\"\n",
        "            elif member.find('name').text == 'orange':\n",
        "              obj_class = \"2\"\n",
        "            value = xmin+','+ymin+','+xmax+','+ymax+','+obj_class\n",
        "            everyrow_xml_list.append(value)\n",
        "        txt_list.append(everyrow_xml_list)#image_path x_min,y_min,x_max,y_max,class_id  x_min,y_min,x_max,y_max,class_id ……\n",
        "    return txt_list\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    image_path = path\n",
        "    xml2txt_list = xml_to_txt(image_path)\n",
        "    with open(r'/content/drive/MyDrive/fruit/test.txt', 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f,delimiter=' ')\n",
        "        writer.writerows(xml2txt_list)\n",
        "    print('Successfully converted xml to txt.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "9SYCag8o4FnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "B0f4OjZhFxlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5740eb7e-8e02-4458-f838-0ddc273090fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_77.jpg  apple_89.xml   banana_83.jpg  mixed_21.jpg   orange_84.xml\n",
            "apple_77.xml  apple_90.jpg   banana_83.xml  mixed_21.xml   orange_85.jpg\n",
            "apple_78.jpg  apple_90.xml   banana_84.jpg  mixed_22.jpg   orange_85.xml\n",
            "apple_78.xml  apple_91.jpg   banana_84.xml  mixed_22.xml   orange_86.jpg\n",
            "apple_79.jpg  apple_91.xml   banana_85.jpg  mixed_23.jpg   orange_86.xml\n",
            "apple_79.xml  apple_92.jpg   banana_85.xml  mixed_23.xml   orange_87.jpg\n",
            "apple_80.jpg  apple_92.xml   banana_86.jpg  mixed_24.jpg   orange_87.xml\n",
            "apple_80.xml  apple_93.jpg   banana_86.xml  mixed_24.xml   orange_89.jpg\n",
            "apple_81.jpg  apple_93.xml   banana_87.jpg  mixed_25.jpg   orange_89.xml\n",
            "apple_81.xml  apple_94.jpg   banana_87.xml  mixed_25.xml   orange_90.jpg\n",
            "apple_82.jpg  apple_94.xml   banana_88.jpg  orange_77.jpg  orange_90.xml\n",
            "apple_82.xml  apple_95.jpg   banana_88.xml  orange_77.xml  orange_91.jpg\n",
            "apple_83.jpg  apple_95.xml   banana_89.jpg  orange_78.jpg  orange_91.xml\n",
            "apple_83.xml  banana_77.jpg  banana_89.xml  orange_78.xml  orange_92.jpg\n",
            "apple_84.jpg  banana_77.xml  banana_90.jpg  orange_79.jpg  orange_92.xml\n",
            "apple_84.xml  banana_78.jpg  banana_90.xml  orange_79.xml  orange_93.jpg\n",
            "apple_85.jpg  banana_78.xml  banana_91.jpg  orange_80.jpg  orange_93.xml\n",
            "apple_85.xml  banana_79.jpg  banana_91.xml  orange_80.xml  orange_94.jpg\n",
            "apple_86.jpg  banana_79.xml  banana_92.jpg  orange_81.jpg  orange_94.xml\n",
            "apple_86.xml  banana_80.jpg  banana_92.xml  orange_81.xml  orange_95.jpg\n",
            "apple_87.jpg  banana_80.xml  banana_93.jpg  orange_82.jpg  orange_95.xml\n",
            "apple_87.xml  banana_81.jpg  banana_93.xml  orange_82.xml\n",
            "apple_88.jpg  banana_81.xml  banana_94.jpg  orange_83.jpg\n",
            "apple_88.xml  banana_82.jpg  banana_94.xml  orange_83.xml\n",
            "apple_89.jpg  banana_82.xml  \u001b[0m\u001b[01;34mchkpt_fruits\u001b[0m/  orange_84.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKw7HZG7LgtP",
        "outputId": "f99ee047-dd26-4f93-cf19-21dea2e6f585"
      },
      "source": [
        "cd /content/content/My Drive/LSCV/project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/content/My Drive/LSCV/project'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0epuu1ng1Sp",
        "outputId": "d1d1aab5-dec7-45c5-8289-cc26917fa096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_77.jpg  apple_89.xml   banana_83.jpg  mixed_21.jpg   orange_84.xml\n",
            "apple_77.xml  apple_90.jpg   banana_83.xml  mixed_21.xml   orange_85.jpg\n",
            "apple_78.jpg  apple_90.xml   banana_84.jpg  mixed_22.jpg   orange_85.xml\n",
            "apple_78.xml  apple_91.jpg   banana_84.xml  mixed_22.xml   orange_86.jpg\n",
            "apple_79.jpg  apple_91.xml   banana_85.jpg  mixed_23.jpg   orange_86.xml\n",
            "apple_79.xml  apple_92.jpg   banana_85.xml  mixed_23.xml   orange_87.jpg\n",
            "apple_80.jpg  apple_92.xml   banana_86.jpg  mixed_24.jpg   orange_87.xml\n",
            "apple_80.xml  apple_93.jpg   banana_86.xml  mixed_24.xml   orange_89.jpg\n",
            "apple_81.jpg  apple_93.xml   banana_87.jpg  mixed_25.jpg   orange_89.xml\n",
            "apple_81.xml  apple_94.jpg   banana_87.xml  mixed_25.xml   orange_90.jpg\n",
            "apple_82.jpg  apple_94.xml   banana_88.jpg  orange_77.jpg  orange_90.xml\n",
            "apple_82.xml  apple_95.jpg   banana_88.xml  orange_77.xml  orange_91.jpg\n",
            "apple_83.jpg  apple_95.xml   banana_89.jpg  orange_78.jpg  orange_91.xml\n",
            "apple_83.xml  banana_77.jpg  banana_89.xml  orange_78.xml  orange_92.jpg\n",
            "apple_84.jpg  banana_77.xml  banana_90.jpg  orange_79.jpg  orange_92.xml\n",
            "apple_84.xml  banana_78.jpg  banana_90.xml  orange_79.xml  orange_93.jpg\n",
            "apple_85.jpg  banana_78.xml  banana_91.jpg  orange_80.jpg  orange_93.xml\n",
            "apple_85.xml  banana_79.jpg  banana_91.xml  orange_80.xml  orange_94.jpg\n",
            "apple_86.jpg  banana_79.xml  banana_92.jpg  orange_81.jpg  orange_94.xml\n",
            "apple_86.xml  banana_80.jpg  banana_92.xml  orange_81.xml  orange_95.jpg\n",
            "apple_87.jpg  banana_80.xml  banana_93.jpg  orange_82.jpg  orange_95.xml\n",
            "apple_87.xml  banana_81.jpg  banana_93.xml  orange_82.xml\n",
            "apple_88.jpg  banana_81.xml  banana_94.jpg  orange_83.jpg\n",
            "apple_88.xml  banana_82.jpg  banana_94.xml  orange_83.xml\n",
            "apple_89.jpg  banana_82.xml  \u001b[0m\u001b[01;34mchkpt_fruits\u001b[0m/  orange_84.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.19.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "kHTotNPCGdB5",
        "outputId": "9d661bf3-3e3c-42fc-8cdd-22a8ec33b48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.0\n",
            "  Downloading numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 34.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.19.0 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.0 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISd6eTgXQNd"
      },
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQzbsaxpXSVs"
      },
      "source": [
        "# YOLO options\n",
        "YOLO_DARKNET_WEIGHTS        = \"/model_data/yolov3.weights\"\n",
        "YOLO_COCO_CLASSES           = \"/model_data/coco.names\"\n",
        "YOLO_STRIDES                = [8, 16, 32]\n",
        "YOLO_IOU_LOSS_THRESH        = 0.5\n",
        "YOLO_ANCHOR_PER_SCALE       = 3\n",
        "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
        "YOLO_INPUT_SIZE             = 416\n",
        "YOLO_ANCHORS                = [[[10,  13], [16,   30], [33,   23]],\n",
        "                               [[30,  61], [62,   45], [59,  119]],\n",
        "                               [[116, 90], [156, 198], [373, 326]]]\n",
        "# Train options\n",
        "TRAIN_CLASSES               = \"/content/drive/MyDrive/fruits.names\"\n",
        "TRAIN_ANNOT_PATH            = \"/content/drive/MyDrive/train.txt\"\n",
        "TRAIN_BATCH_SIZE            = 4\n",
        "TRAIN_INPUT_SIZE            = 416\n",
        "TRAIN_DATA_AUG              = True\n",
        "TRAIN_TRANSFER              = False\n",
        "TRAIN_FROM_CHECKPOINT       = False #\"./checkpoints_furits/yolov3_custom\"\n",
        "\n",
        "TRAIN_LR_INIT               = 1e-4\n",
        "TRAIN_LR_END                = 1e-6\n",
        "TRAIN_WARMUP_EPOCHS         = 2\n",
        "TRAIN_EPOCHS                = 20\n",
        "\n",
        "# TEST options\n",
        "TEST_ANNOT_PATH             = \"/content/drive/MyDrive/test.txt\"\n",
        "TEST_BATCH_SIZE             = 4\n",
        "TEST_INPUT_SIZE             = 416\n",
        "TEST_DATA_AUG               = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KzpkCyp95zC"
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import colorsys\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8JMPV9_-m1M"
      },
      "source": [
        "utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raaIsjRk98PJ"
      },
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() # used to reset layer names\n",
        "    # load Darknet original weights to Keras model\n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(75):\n",
        "            if i > 0:\n",
        "                conv_layer_name = 'conv2d_%d' %i\n",
        "            else:\n",
        "                conv_layer_name = 'conv2d'\n",
        "                \n",
        "            if j > 0:\n",
        "                bn_layer_name = 'batch_normalization_%d' %j\n",
        "            else:\n",
        "                bn_layer_name = 'batch_normalization'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBrLfn24-CaP"
      },
      "source": [
        "def read_class_names(class_file_name):\n",
        "    # loads class name from a file\n",
        "    #print(class_file_name)\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXTy87MuLlX0",
        "outputId": "ef2781c4-529a-4ab7-d14d-657eda1fe440"
      },
      "source": [
        "read_class_names(TRAIN_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'apple', 1: 'banana', 2: 'orange'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IKBK700-EXF"
      },
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "    print(gt_boxes)\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDX_984L-F1Y"
      },
      "source": [
        "\n",
        "def draw_bbox(image, bboxes, CLASSES=TRAIN_CLASSES, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors=''):   \n",
        "    NUM_CLASS = read_class_names(CLASSES)\n",
        "    num_classes = len(NUM_CLASS)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    #print(\"hsv_tuples\", hsv_tuples)\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != ''else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        #print(image_h, image_w, bbox_thick)\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = f' {score:.2f}' if show_confidence else '' \n",
        "            label = f'{NUM_CLASS[class_ind]}' + score_str\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                                                                  fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY2vi4Fi-OsJ"
      },
      "source": [
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(float).eps)\n",
        "\n",
        "    return ious\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxduNYb6-QNh"
      },
      "source": [
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3):\n",
        "\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
        "        while len(cls_bboxes) > 0:\n",
        "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            # Process 3: Calculate this bounding box A and\n",
        "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=float)\n",
        "\n",
        "            iou_mask = iou > iou_threshold\n",
        "            weight[iou_mask] = 0.0\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcenMeqH-SeO"
      },
      "source": [
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "    #print(coors)\n",
        "\n",
        "    #print(coors[0])\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf91vRsKXTQd"
      },
      "source": [
        "def detect_image(YoloV3, image_path, output_path, input_size=416, show=False, CLASSES=TRAIN_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    original_image      = cv2.imread(image_path)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    #original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "    image_data = tf.expand_dims(image_data, 0)\n",
        "\n",
        "    pred_bbox = YoloV3.predict(image_data)\n",
        "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "    \n",
        "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "    #xx=np.array(bboxes)\n",
        "    #print(xx.shape)\n",
        "\n",
        "    bboxes = nms(bboxes, iou_threshold)\n",
        "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "    #cv2.imwrite('./output.jpg', image)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWfbwjQ-fiU"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDDDzxjh-qmA"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "STRIDES         = np.array(YOLO_STRIDES)\n",
        "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "IOU_LOSS_THRESH = YOLO_IOU_LOSS_THRESH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMrWDDaDXaE_"
      },
      "source": [
        "class BatchNormalization(BatchNormalization):\n",
        "    # \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
        "    # `layer.trainable = False` is to freeze the layer, so the layer will use\n",
        "    # stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n",
        "    # and `beta` will not be updated !\n",
        "    def call(self, x, training=False):\n",
        "        if not training:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True):\n",
        "    if downsample:\n",
        "        input_layer = ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=l2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        conv = LeakyReLU(alpha=0.1)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1))\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2))\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
        "\n",
        "\n",
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32))\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3,  64, 128), downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128,  64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data\n",
        "\n",
        "def YOLOv3(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1,  512,  256))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "\n",
        "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    \n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def Create_Yolov3(input_size=416, channels=3, training=False, CLASSES=TRAIN_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    input_layer  = Input([input_size, input_size, channels])\n",
        "\n",
        "    conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "        if training: output_tensors.append(conv_tensor)\n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    YoloV3 = tf.keras.Model(input_layer, output_tensors)\n",
        "    return YoloV3\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0):\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
        "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
        "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
        "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box \n",
        "\n",
        "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
        "    y = tf.range(output_size, dtype=tf.int32)\n",
        "    y = tf.expand_dims(y, -1)\n",
        "    y = tf.tile(y, [1, output_size])\n",
        "    x = tf.range(output_size,dtype=tf.int32)\n",
        "    x = tf.expand_dims(x, 0)\n",
        "    x = tf.tile(x, [output_size, 1])\n",
        "\n",
        "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "def bbox_iou(boxes1, boxes2):\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area\n",
        "\n",
        "def bbox_giou(boxes1, boxes2):\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "\n",
        "def compute_loss(pred, conv, label, bboxes, i=0, CLASSES=TRAIN_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    conv_shape  = tf.shape(conv)\n",
        "    batch_size  = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "    input_size  = STRIDES[i] * output_size\n",
        "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
        "\n",
        "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
        "    pred_conf     = pred[:, :, :, :, 4:5]\n",
        "\n",
        "    label_xywh    = label[:, :, :, :, 0:4]\n",
        "    respond_bbox  = label[:, :, :, :, 4:5]\n",
        "    label_prob    = label[:, :, :, :, 5:]\n",
        "\n",
        "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
        "    input_size = tf.cast(input_size, tf.float32)\n",
        "\n",
        "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
        "    giou_loss = respond_bbox * bbox_loss_scale * (1- giou)\n",
        "\n",
        "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
        "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
        "\n",
        "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < IOU_LOSS_THRESH, tf.float32)\n",
        "\n",
        "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
        "\n",
        "    conf_loss = conf_focal * (\n",
        "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "            +\n",
        "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "    )\n",
        "\n",
        "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
        "\n",
        "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
        "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
        "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
        "\n",
        "    return giou_loss, conf_loss, prob_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoTCdT7V-isD"
      },
      "source": [
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9FsKyf7Xdfu"
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class Dataset(object):\n",
        "    # Dataset preprocess implementation\n",
        "    def __init__(self, dataset_type):\n",
        "        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n",
        "        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE\n",
        "        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n",
        "        self.data_aug    = TRAIN_DATA_AUG   if dataset_type == 'train' else TEST_DATA_AUG\n",
        "\n",
        "        self.train_input_sizes = TRAIN_INPUT_SIZE\n",
        "        self.strides = np.array(YOLO_STRIDES)\n",
        "        self.classes = read_class_names(TRAIN_CLASSES)\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
        "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
        "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
        "\n",
        "        self.annotations = self.load_annotations(dataset_type)\n",
        "        self.num_samples = len(self.annotations)\n",
        "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
        "        self.batch_count = 0\n",
        "\n",
        "\n",
        "    def load_annotations(self, dataset_type):\n",
        "        final_annotations = []\n",
        "        with open(self.annot_path, 'r') as f:\n",
        "            txt = f.readlines()\n",
        "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
        "        np.random.shuffle(annotations)\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            # fully parse annotations\n",
        "            line = annotation.split()\n",
        "            image_path, index = \"\", 1\n",
        "            for i, one_line in enumerate(line):\n",
        "                if not one_line.replace(\",\",\"\").isnumeric():\n",
        "                    if image_path != \"\": image_path += \" \"\n",
        "                    image_path += one_line\n",
        "                else:\n",
        "                    index = i\n",
        "                    break\n",
        "            if not os.path.exists(image_path):\n",
        "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
        "\n",
        "            final_annotations.append([image_path, line[index:]])\n",
        "\n",
        "        return final_annotations\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.train_input_size = random.choice([self.train_input_sizes])\n",
        "            self.train_output_sizes = self.train_input_size // self.strides\n",
        "\n",
        "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
        "\n",
        "            batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "\n",
        "            batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "\n",
        "            num = 0\n",
        "            if self.batch_count < self.num_batchs:\n",
        "                while num < self.batch_size:\n",
        "                    index = self.batch_count * self.batch_size + num\n",
        "                    if index >= self.num_samples: index -= self.num_samples\n",
        "                    annotation = self.annotations[index]\n",
        "                    image, bboxes = self.parse_annotation(annotation)\n",
        "                    label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
        "\n",
        "                    batch_image[num, :, :, :] = image\n",
        "                    batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
        "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
        "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
        "                    batch_sbboxes[num, :, :] = sbboxes\n",
        "                    batch_mbboxes[num, :, :] = mbboxes\n",
        "                    batch_lbboxes[num, :, :] = lbboxes\n",
        "                    num += 1\n",
        "                self.batch_count += 1\n",
        "                batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
        "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
        "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
        "\n",
        "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
        "            else:\n",
        "                self.batch_count = 0\n",
        "                np.random.shuffle(self.annotations)\n",
        "                raise StopIteration\n",
        "\n",
        "    def random_horizontal_flip(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            _, w, _ = image.shape\n",
        "            image = image[:, ::-1, :]\n",
        "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_crop(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
        "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
        "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
        "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
        "\n",
        "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_translate(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
        "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
        "\n",
        "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
        "            image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def parse_annotation(self, annotation):\n",
        "\n",
        "        image_path = annotation[0]\n",
        "        image = cv2.imread(image_path)\n",
        "            \n",
        "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
        "\n",
        "        if self.data_aug:\n",
        "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image, bboxes = image_preprocess(np.copy(image), [self.train_input_size, self.train_input_size], np.copy(bboxes))\n",
        "        return image, bboxes\n",
        "\n",
        "    def preprocess_true_boxes(self, bboxes):\n",
        "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
        "                           5 + self.num_classes)) for i in range(3)]\n",
        "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(3)]\n",
        "        bbox_count = np.zeros((3,))\n",
        "\n",
        "        for bbox in bboxes:\n",
        "            bbox_coor = bbox[:4]\n",
        "            bbox_class_ind = bbox[4]\n",
        "\n",
        "            onehot = np.zeros(self.num_classes, dtype=np.float64)\n",
        "            onehot[bbox_class_ind] = 1.0\n",
        "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
        "            deta = 0.01\n",
        "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
        "\n",
        "            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
        "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n",
        "\n",
        "            iou = []\n",
        "            exist_positive = False\n",
        "            for i in range(3):\n",
        "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
        "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
        "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
        "\n",
        "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
        "                iou.append(iou_scale)\n",
        "                iou_mask = iou_scale > 0.3\n",
        "\n",
        "                if np.any(iou_mask):\n",
        "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
        "\n",
        "                    label[i][yind, xind, iou_mask, :] = 0\n",
        "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
        "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
        "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
        "\n",
        "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
        "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
        "                    bbox_count[i] += 1\n",
        "\n",
        "                    exist_positive = True\n",
        "\n",
        "            if not exist_positive:\n",
        "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
        "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
        "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
        "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
        "\n",
        "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
        "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
        "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
        "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
        "                \n",
        "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
        "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
        "                bbox_count[best_detect] += 1\n",
        "\n",
        "        label_sbbox, label_mbbox, label_lbbox = label\n",
        "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
        "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgvPlA8Ufp8f",
        "outputId": "1f974d26-0bba-4352-f9da-1dbeefeffac5"
      },
      "source": [
        "trainset = Dataset('train')\n",
        "steps_per_epoch = len(trainset)\n",
        "\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIQuRMfmXpgX"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMp-XBHSXicX",
        "outputId": "de7523c8-c200-4876-bcca-859038534573"
      },
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "global TRAIN_FROM_CHECKPOINT\n",
        "input_size = YOLO_INPUT_SIZE\n",
        "Darknet_weights = YOLO_DARKNET_WEIGHTS\n",
        "\n",
        "\n",
        "save_best_only = True # saves only best model according validation loss\n",
        "save_checkpoints = False # saves all best validated checkpoints in training process (may require a lot disk space)\n",
        "\n",
        "\n",
        "trainset = Dataset('train')\n",
        "testset = Dataset('test')\n",
        "\n",
        "steps_per_epoch = len(trainset)\n",
        "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
        "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
        "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
        "\n",
        "if TRAIN_TRANSFER:\n",
        "    Darknet = Create_Yolov3(input_size=input_size)\n",
        "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
        "\n",
        "yolo = Create_Yolov3(input_size=input_size, training=True, CLASSES=TRAIN_CLASSES)\n",
        "\n",
        "#TRAIN_FROM_CHECKPOINT = False\n",
        "if TRAIN_FROM_CHECKPOINT:\n",
        "    yolo.load_weights(TRAIN_FROM_CHECKPOINT)\n",
        "\n",
        "## transfer && Not use checkpoint\n",
        "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
        "    for i, l in enumerate(Darknet.layers):\n",
        "        layer_weights = l.get_weights()\n",
        "        if layer_weights != []:\n",
        "            try:\n",
        "                yolo.layers[i].set_weights(layer_weights)\n",
        "            except:\n",
        "                print(\"skipping\", yolo.layers[i].name)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def train_step(image_data, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred_result = yolo(image_data, training=True)\n",
        "        giou_loss=conf_loss=prob_loss=0\n",
        "        # optimizing process\n",
        "        for i in range(3):\n",
        "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
        "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
        "            giou_loss += loss_items[0]\n",
        "            conf_loss += loss_items[1]\n",
        "            prob_loss += loss_items[2]\n",
        "        total_loss = giou_loss + conf_loss + prob_loss\n",
        "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
        "\n",
        "\n",
        "        # update learning rate\n",
        "        global_steps.assign_add(1)\n",
        "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
        "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
        "        else:\n",
        "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
        "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
        "        optimizer.lr.assign(lr.numpy())\n",
        "\n",
        "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
        "\n",
        "\n",
        "\n",
        "def validate_step(image_data, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred_result = yolo(image_data, training=False)\n",
        "        giou_loss=conf_loss=prob_loss=0\n",
        "\n",
        "        # optimizing process\n",
        "        for i in range(3):\n",
        "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
        "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
        "            giou_loss += loss_items[0]\n",
        "            conf_loss += loss_items[1]\n",
        "            prob_loss += loss_items[2]\n",
        "\n",
        "        total_loss = giou_loss + conf_loss + prob_loss\n",
        "        \n",
        "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
        "\n",
        "\n",
        "best_val_loss = 1000 # should be large at start\n",
        "\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    for image_data, target in trainset:\n",
        "        results = train_step(image_data, target)\n",
        "        cur_step = results[0]%steps_per_epoch\n",
        "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
        "                  .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
        "        \n",
        "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
        "    for image_data, target in testset:\n",
        "        results = validate_step(image_data, target)\n",
        "        count += 1\n",
        "        giou_val += results[0]\n",
        "        conf_val += results[1]\n",
        "        prob_val += results[2]\n",
        "        total_val += results[3]\n",
        "\n",
        "        \n",
        "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
        "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
        "\n",
        "    if save_best_only and best_val_loss > total_val/count: \n",
        "        yolo.save_weights(\"./chkpt_fruits/yolov3_custom\")\n",
        "        best_val_loss = total_val/count\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[[249 144 585 514   2]\n",
            " [603 133 932 455   2]]\n",
            "epoch:12 step:   21/60, lr:0.000039, giou_loss:   2.80, conf_loss:  24.10, prob_loss:   6.70, total_loss:  33.59\n",
            "[[ 64   1 427 348   0]]\n",
            "[[ 77  24 226 239   1]]\n",
            "[[ 17 104 138 247   2]\n",
            " [ 38   1 144 115   2]\n",
            " [110  62 240 187   2]\n",
            " [130   2 240  70   2]\n",
            " [ 89 201 211 250   2]]\n",
            "[[143 105 469 380   0]]\n",
            "epoch:12 step:   22/60, lr:0.000039, giou_loss:   2.31, conf_loss:  23.38, prob_loss:   2.81, total_loss:  28.50\n",
            "[[123  24 554 465   2]]\n",
            "[[ 82  98 541 348   1]]\n",
            "[[242 146 605 635   1]]\n",
            "[[ 70  89 540 531   0]]\n",
            "epoch:12 step:   23/60, lr:0.000039, giou_loss:   0.84, conf_loss:  21.01, prob_loss:   0.42, total_loss:  22.27\n",
            "[[159 119 324 314   2]\n",
            " [317 114 510 337   0]\n",
            " [ 19 332 564 585   1]]\n",
            "[[ 34  91 705 348   1]]\n",
            "[[  8  17 347 219   1]]\n",
            "[[ 46  20 295 252   2]]\n",
            "epoch:12 step:   24/60, lr:0.000039, giou_loss:   1.58, conf_loss:  22.41, prob_loss:   3.03, total_loss:  27.02\n",
            "[[ 18 139 437 333   1]\n",
            " [ 24  76 346 213   1]\n",
            " [ 65  21 340 156   1]]\n",
            "[[ 213  146  587  524    2]\n",
            " [ 355  117 1012  331    1]\n",
            " [ 409  250  995  534    1]]\n",
            "[[  2  11 295 127   1]]\n",
            "[[ 26   4 233 212   0]]\n",
            "epoch:12 step:   25/60, lr:0.000038, giou_loss:   2.40, conf_loss:  22.98, prob_loss:   2.15, total_loss:  27.53\n",
            "[[ 38   6 738 713   0]]\n",
            "[[ 51  10 352 330   2]]\n",
            "[[242  38 505 326   0]\n",
            " [  2   5 261 257   0]]\n",
            "[[ 207  160  729  494    1]\n",
            " [  30    0  571  297    1]\n",
            " [ 787    2 1198  343    1]\n",
            " [ 939  248 1198  668    1]\n",
            " [ 489  448  970  673    1]\n",
            " [   1  479  377  673    1]]\n",
            "epoch:12 step:   26/60, lr:0.000038, giou_loss:   4.69, conf_loss:  26.48, prob_loss:   7.41, total_loss:  38.58\n",
            "[[ 13  15 311 303   0]]\n",
            "[[  8  10 282 277   2]]\n",
            "[[108   1 544 238   1]]\n",
            "[[  62   44 1929 1864    2]]\n",
            "epoch:12 step:   27/60, lr:0.000038, giou_loss:   0.36, conf_loss:  20.29, prob_loss:   0.55, total_loss:  21.20\n",
            "[[ 153   42 1554 1433    2]]\n",
            "[[ 11   2 165 147   2]]\n",
            "[[  4  11 300 283   1]\n",
            " [493  41 761 384   1]\n",
            " [389  59 678 403   1]\n",
            " [389 139 649 533   1]\n",
            " [265 126 435 552   1]\n",
            " [ 78 125 369 460   1]\n",
            " [ 42  40 415 321   1]]\n",
            "[[ 96 154 516 596   0]]\n",
            "epoch:12 step:   28/60, lr:0.000038, giou_loss:   5.18, conf_loss:  27.49, prob_loss:   6.38, total_loss:  39.05\n",
            "[[148  77 536 252   1]]\n",
            "[[203 153 285 241   2]\n",
            " [145 150 218 225   2]\n",
            " [ 15  36 245 132   1]\n",
            " [  4 171  98 262   0]]\n",
            "[[ 54  14 306 273   2]]\n",
            "[[ 28 257 512 733   0]\n",
            " [311  55 678 528   0]]\n",
            "epoch:12 step:   29/60, lr:0.000038, giou_loss:   2.47, conf_loss:  23.45, prob_loss:   4.28, total_loss:  30.19\n",
            "[[ 69  45 238 153   1]]\n",
            "[[106 156 586 360   1]]\n",
            "[[ 19   5 165 148   2]\n",
            " [  8 147 314 229   1]\n",
            " [169   0 306 145   0]]\n",
            "[[154  91 556 180   1]\n",
            " [153  99 549 251   1]\n",
            " [143 135 540 344   1]\n",
            " [ 66 155 417 426   1]]\n",
            "epoch:12 step:   30/60, lr:0.000038, giou_loss:   3.19, conf_loss:  24.93, prob_loss:   6.46, total_loss:  34.58\n",
            "[[558 422 841 692   0]\n",
            " [466 125 714 378   0]\n",
            " [150 183 464 450   0]\n",
            " [341   1 593 224   0]\n",
            " [616  19 881 253   0]]\n",
            "[[123  43 549 374   1]]\n",
            "[[270  30 713 425   1]]\n",
            "[[404 173 827 595   0]\n",
            " [235 115 559 441   0]]\n",
            "epoch:12 step:   31/60, lr:0.000038, giou_loss:   3.36, conf_loss:  27.34, prob_loss:   6.53, total_loss:  37.24\n",
            "[[193  33 439 258   0]\n",
            " [464  30 651 280   0]\n",
            " [315   5 536 220   0]]\n",
            "[[205  57 416 253   2]\n",
            " [254 296 463 514   2]\n",
            " [ 74 376 286 575   2]\n",
            " [149 461 351 631   2]]\n",
            "[[ 14  18 161 162   0]]\n",
            "[[106  22 436 354   2]]\n",
            "epoch:12 step:   32/60, lr:0.000037, giou_loss:   3.08, conf_loss:  26.36, prob_loss:   7.46, total_loss:  36.89\n",
            "[[ 47   1 852 214   1]]\n",
            "[[ 49 213 613 793   0]\n",
            " [420 176 932 665   0]]\n",
            "[[128   3 392 275   2]]\n",
            "[[ 53 105 265 310   2]]\n",
            "epoch:12 step:   33/60, lr:0.000037, giou_loss:   0.98, conf_loss:  22.20, prob_loss:   1.17, total_loss:  24.35\n",
            "[[ 22 113 478 599   2]]\n",
            "[[511 237 744 504   0]\n",
            " [335 325 574 549   0]\n",
            " [  6 219 210 451   0]\n",
            " [189 171 419 386   0]\n",
            " [438 156 631 307   0]\n",
            " [297   2 529 196   0]\n",
            " [531  35 696 200   0]]\n",
            "[[ 327  143 1834  919    1]]\n",
            "[[ 25   2 275 257   0]]\n",
            "epoch:12 step:   34/60, lr:0.000037, giou_loss:   3.55, conf_loss:  26.90, prob_loss:  10.39, total_loss:  40.85\n",
            "[[ 80 261 385 567   0]\n",
            " [407 426 695 691   0]\n",
            " [323 290 606 545   0]]\n",
            "[[155  99 411 329   2]\n",
            " [ 24   1 239 187   2]\n",
            " [401  47 600 297   2]\n",
            " [205  25 417 209   2]\n",
            " [302 272 566 398   2]]\n",
            "[[ 19  13 275 269   0]]\n",
            "[[148   5 509 296   2]]\n",
            "epoch:12 step:   35/60, lr:0.000037, giou_loss:   3.12, conf_loss:  25.25, prob_loss:   5.22, total_loss:  33.59\n",
            "[[232 101 405 273   2]\n",
            " [  4 107 289 390   1]\n",
            " [ 82  19 246 180   0]]\n",
            "[[ 10   3 239 227   2]]\n",
            "[[ 31  25 633 478   1]\n",
            " [ 55   1 626 298   1]\n",
            " [ 92   5 603 214   1]\n",
            " [  1 145 200 478   1]]\n",
            "[[ 23  12 210 214   2]]\n",
            "epoch:12 step:   36/60, lr:0.000037, giou_loss:   2.22, conf_loss:  23.49, prob_loss:   4.91, total_loss:  30.62\n",
            "[[ 287  233 1141 1111    0]]\n",
            "[[373 104 514 345   1]\n",
            " [298  93 382 354   1]\n",
            " [219 110 292 349   1]\n",
            " [121 117 216 354   1]]\n",
            "[[270 114 773 360   1]]\n",
            "[[  16  482  971 1118    1]\n",
            " [  16  686  797 1194    1]\n",
            " [ 335  197 1515 1070    1]]\n",
            "epoch:12 step:   37/60, lr:0.000037, giou_loss:   4.65, conf_loss:  24.51, prob_loss:   7.57, total_loss:  36.73\n",
            "[[218 163 546 487   0]\n",
            " [265 448 583 713   0]\n",
            " [  0 470 197 716   0]\n",
            " [ 73 179 332 467   0]\n",
            " [492  63 799 414   0]]\n",
            "[[107  17 248 174   0]\n",
            " [  6  12 108 121   0]\n",
            " [ 46  80 157 189   0]]\n",
            "[[ 65  52 311 313   2]]\n",
            "[[  68  305  947 1191    2]]\n",
            "epoch:12 step:   38/60, lr:0.000037, giou_loss:   2.37, conf_loss:  23.93, prob_loss:   3.16, total_loss:  29.46\n",
            "[[ 82  30 660 542   2]]\n",
            "[[  10  625 2466 4515    1]]\n",
            "[[ 37  52 205 222   0]]\n",
            "[[  6  10 329 344   0]]\n",
            "epoch:12 step:   39/60, lr:0.000036, giou_loss:   0.71, conf_loss:  20.29, prob_loss:   0.45, total_loss:  21.45\n",
            "[[107 120 193 208   2]\n",
            " [ 83 107 161 198   2]]\n",
            "[[154  74 387 293   2]]\n",
            "[[ 95  65 431 428   2]]\n",
            "[[  3  43 365 370   2]]\n",
            "epoch:12 step:   40/60, lr:0.000036, giou_loss:   1.64, conf_loss:  22.09, prob_loss:   6.16, total_loss:  29.90\n",
            "[[ 672  450 1050  861    2]\n",
            " [  24  129  746  557    1]\n",
            " [  46  261  716  879    1]]\n",
            "[[ 30  14 658 188   1]\n",
            " [ 85 102 672 412   1]\n",
            " [244  10 685 304   1]]\n",
            "[[324 192 636 480   2]\n",
            " [ 56 344 881 540   1]\n",
            " [ 66 463 909 671   1]]\n",
            "[[ 39  79 495 448   2]]\n",
            "epoch:12 step:   41/60, lr:0.000036, giou_loss:   3.57, conf_loss:  24.47, prob_loss:   8.61, total_loss:  36.66\n",
            "[[119  77 722 688   2]]\n",
            "[[ 41 161 160 276   0]\n",
            " [181 181 312 306   0]\n",
            " [237  64 343 159   0]\n",
            " [304   1 439 105   0]\n",
            " [393  46 514 162   0]\n",
            " [297 104 411 211   0]]\n",
            "[[ 53 110 277 341   1]\n",
            " [173 136 546 322   1]\n",
            " [138  61 513 209   1]]\n",
            "[[109  99 576 374   1]\n",
            " [133  38 566 268   1]]\n",
            "epoch:12 step:   42/60, lr:0.000036, giou_loss:   6.49, conf_loss:  30.38, prob_loss:   7.26, total_loss:  44.13\n",
            "[[ 131  145 1237 1172    0]]\n",
            "[[  7  56 176 211   2]\n",
            " [126  48 286 211   2]\n",
            " [188   1 330 142   2]]\n",
            "[[ 15  75 340 404   0]\n",
            " [285  42 556 333   0]]\n",
            "[[  1 171 532 676   2]]\n",
            "epoch:12 step:   43/60, lr:0.000036, giou_loss:   1.85, conf_loss:  22.14, prob_loss:   4.47, total_loss:  28.46\n",
            "[[1631   33 3096 1607    2]]\n",
            "[[ 96  18 273 181   0]]\n",
            "[[ 95  63 597 266   1]]\n",
            "[[ 496  168 1603  923    1]\n",
            " [ 199  587 1470 1268    1]\n",
            " [ 797    1 1772  611    1]\n",
            " [1052    1 1916  550    1]]\n",
            "epoch:12 step:   44/60, lr:0.000036, giou_loss:   2.09, conf_loss:  20.97, prob_loss:   6.39, total_loss:  29.46\n",
            "[[ 46 274 161 373   2]\n",
            " [456 252 536 327   2]\n",
            " [430 195 528 272   2]\n",
            " [ 60 162 317 262   1]\n",
            " [ 98 204 332 299   1]\n",
            " [234 161 391 306   1]\n",
            " [262 211 398 340   1]\n",
            " [239  86 348 189   0]\n",
            " [349 119 463 224   0]]\n",
            "[[  44   79 2776 2562    1]]\n",
            "[[  3  14 407 158   1]]\n",
            "[[ 28  38 202 213   0]\n",
            " [175  25 325 193   0]]\n",
            "epoch:12 step:   45/60, lr:0.000036, giou_loss:   8.13, conf_loss:  30.35, prob_loss:  11.53, total_loss:  50.01\n",
            "[[1146  145 1569  552    2]\n",
            " [ 718  242 1102  669    2]\n",
            " [ 678  628 1158 1060    2]]\n",
            "[[268 104 511 327   2]]\n",
            "[[ 54   7 567 519   2]]\n",
            "[[168  31 764 698   1]]\n",
            "epoch:12 step:   46/60, lr:0.000035, giou_loss:   1.90, conf_loss:  23.81, prob_loss:   5.09, total_loss:  30.80\n",
            "[[  1  43 288 329   0]]\n",
            "[[  5 174 562 408   1]]\n",
            "[[ 208  778 1011 1599    0]\n",
            " [  99   49  505  665    0]\n",
            " [ 202   52  722  605    0]]\n",
            "[[ 10  65 290 366   2]]\n",
            "epoch:12 step:   47/60, lr:0.000035, giou_loss:   1.71, conf_loss:  22.04, prob_loss:   2.39, total_loss:  26.15\n",
            "[[ 10  18 445 460   0]]\n",
            "[[433  50 853 426   2]\n",
            " [ 33 303 980 605   1]\n",
            " [108  91 477 403   0]]\n",
            "[[ 71   5 390 117   1]]\n",
            "[[  6  18 206 206   0]]\n",
            "epoch:12 step:   48/60, lr:0.000035, giou_loss:   1.29, conf_loss:  20.90, prob_loss:   1.40, total_loss:  23.59\n",
            "[[ 57  38 719 741   2]]\n",
            "[[ 52   7 174 130   2]\n",
            " [139   5 275 149   2]]\n",
            "[[ 70 322 972 800   1]]\n",
            "[[159   2 391 172   1]\n",
            " [139  33 324 206   1]\n",
            " [109  46 259 236   1]\n",
            " [ 55  65 141 280   1]]\n",
            "epoch:12 step:   49/60, lr:0.000035, giou_loss:   2.87, conf_loss:  23.05, prob_loss:   2.11, total_loss:  28.03\n",
            "[[   6  102 1186  568    1]]\n",
            "[[109  48 633 406   1]]\n",
            "[[428 195 807 544   0]]\n",
            "[[ 13 161 439 375   1]]\n",
            "epoch:12 step:   50/60, lr:0.000035, giou_loss:   1.31, conf_loss:  20.56, prob_loss:   0.61, total_loss:  22.48\n",
            "[[205 196 375 374   0]\n",
            " [137 144 303 328   0]]\n",
            "[[ 15  87 255 291   0]]\n",
            "[[ 178  126 1157 1121    0]]\n",
            "[[ 55  77 238 267   2]]\n",
            "epoch:12 step:   51/60, lr:0.000035, giou_loss:   1.37, conf_loss:  21.94, prob_loss:   3.02, total_loss:  26.33\n",
            "[[ 453  222 1293 1058    2]]\n",
            "[[ 912  314 1529  934    2]\n",
            " [ 366  402  954 1006    2]]\n",
            "[[  7  20 325 324   1]]\n",
            "[[ 84  75 308 317   2]]\n",
            "epoch:12 step:   52/60, lr:0.000035, giou_loss:   1.13, conf_loss:  21.41, prob_loss:   2.71, total_loss:  25.25\n",
            "[[ 16  80 354 441   2]\n",
            " [312  40 664 403   2]]\n",
            "[[ 59 109 543 399   1]]\n",
            "[[239 140 448 361   2]\n",
            " [ 41 102 246 354   2]\n",
            " [151   4 370 174   2]]\n",
            "[[ 30  67 207 234   0]]\n",
            "epoch:12 step:   53/60, lr:0.000035, giou_loss:   1.51, conf_loss:  21.29, prob_loss:   2.66, total_loss:  25.46\n",
            "[[  4  33 409 375   1]]\n",
            "[[ 57  93 194 252   2]\n",
            " [ 48  18 184 157   2]\n",
            " [391  88 523 233   2]\n",
            " [416  23 565 153   2]\n",
            " [284  45 427 189   2]\n",
            " [209  97 360 239   2]\n",
            " [145   2 278 128   2]]\n",
            "[[100  11 368 288   0]]\n",
            "[[ 104  391  738 1391    1]\n",
            " [ 520  212 1045 1270    1]]\n",
            "epoch:12 step:   54/60, lr:0.000034, giou_loss:   5.79, conf_loss:  27.76, prob_loss:   8.73, total_loss:  42.29\n",
            "[[465 391 890 800   2]]\n",
            "[[ 97  47 366 311   0]]\n",
            "[[159 213 455 531   0]]\n",
            "[[299 292 578 573   2]\n",
            " [459 135 769 393   2]\n",
            " [483 382 816 619   2]]\n",
            "epoch:12 step:   55/60, lr:0.000034, giou_loss:   2.73, conf_loss:  23.03, prob_loss:   3.54, total_loss:  29.31\n",
            "[[ 366  395 1173 1334    1]\n",
            " [  46  344 1011 1022    1]\n",
            " [   1  219  899  709    1]\n",
            " [ 164   32  945  611    1]]\n",
            "[[ 45  44 303 292   2]\n",
            " [346   6 645 305   2]]\n",
            "[[ 45  38 499 494   2]]\n",
            "[[ 25  15 357 344   2]]\n",
            "epoch:12 step:   56/60, lr:0.000034, giou_loss:   2.00, conf_loss:  22.81, prob_loss:   7.82, total_loss:  32.63\n",
            "[[ 39  39 235 222   0]]\n",
            "[[ 203   86 1174  870    1]\n",
            " [ 237  145  861  744    0]]\n",
            "[[ 49  56 813 398   1]\n",
            " [335  37 985 580   1]\n",
            " [  9  13 765 311   1]]\n",
            "[[342 228 565 442   2]\n",
            " [137 220 364 431   0]\n",
            " [317 255 673 452   1]]\n",
            "epoch:12 step:   57/60, lr:0.000034, giou_loss:   1.73, conf_loss:  22.02, prob_loss:   6.17, total_loss:  29.92\n",
            "[[ 311  373 1073 1108    2]]\n",
            "[[116 103 413 390   0]]\n",
            "[[ 56  15 276 216   0]\n",
            " [ 21 207 239 443   0]\n",
            " [169 167 368 401   0]\n",
            " [591 288 773 503   0]\n",
            " [484 360 661 557   0]\n",
            " [319 229 560 453   0]\n",
            " [177 340 359 533   0]\n",
            " [429 415 641 588   0]]\n",
            "[[ 44  33 589 550   2]]\n",
            "epoch:12 step:   58/60, lr:0.000034, giou_loss:   5.27, conf_loss:  27.06, prob_loss:   3.96, total_loss:  36.28\n",
            "[[ 51 215 233 426   0]]\n",
            "[[ 17   6 482 462   2]]\n",
            "[[118 101 476 459   2]\n",
            " [ 54  79 651 536   1]]\n",
            "[[  3  21 285 266   0]]\n",
            "epoch:12 step:   59/60, lr:0.000034, giou_loss:   0.73, conf_loss:  19.97, prob_loss:   1.95, total_loss:  22.66\n",
            "[[ 62   8 217 155   0]]\n",
            "[[ 54  68 245 257   2]\n",
            " [167  60 327 238   2]]\n",
            "[[ 520   35 1199  783    0]]\n",
            "[[ 26  59 224 250   2]\n",
            " [190  36 359 209   2]]\n",
            "epoch:12 step:    0/60, lr:0.000034, giou_loss:   0.94, conf_loss:  20.58, prob_loss:   3.55, total_loss:  25.08\n",
            "[[ 18   1 325 299   2]]\n",
            "[[ 16  33 212 278   1]]\n",
            "[[260 104 509 356   0]\n",
            " [ 12  89 292 362   0]]\n",
            "[[101  22 429 324   1]\n",
            " [147  99 545 356   1]\n",
            " [161  16 473 211   1]]\n",
            "epoch:12 step:    1/60, lr:0.000033, giou_loss:   1.59, conf_loss:  21.53, prob_loss:   2.14, total_loss:  25.26\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[279  14 562 295   2]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "\n",
            "\n",
            "giou_val_loss:   2.78, conf_val_loss:  23.72, prob_val_loss:   5.93, total_val_loss:  32.43\n",
            "\n",
            "\n",
            "[[137  24 799 727   2]]\n",
            "[[ 53 107 244 296   2]\n",
            " [166  99 326 277   2]]\n",
            "[[ 132  388 1103 1172    1]\n",
            " [ 445  447 1069 1046    0]]\n",
            "[[ 60  44 392 373   2]]\n",
            "epoch:13 step:    2/60, lr:0.000033, giou_loss:   1.16, conf_loss:  20.92, prob_loss:   4.73, total_loss:  26.81\n",
            "[[ 47  25 299 284   2]]\n",
            "[[168 277 350 488   0]]\n",
            "[[ 16  10 193 177   0]]\n",
            "[[  2  15 202 203   0]]\n",
            "epoch:13 step:    3/60, lr:0.000033, giou_loss:   0.89, conf_loss:  19.90, prob_loss:   2.47, total_loss:  23.26\n",
            "[[ 54  51 351 338   0]]\n",
            "[[100 107 584 397   1]]\n",
            "[[ 66   7 301 251   0]]\n",
            "[[ 17  99 121 206   2]]\n",
            "epoch:13 step:    4/60, lr:0.000033, giou_loss:   0.87, conf_loss:  19.33, prob_loss:   0.40, total_loss:  20.59\n",
            "[[336  64 792 433   2]]\n",
            "[[ 12  49 252 253   0]]\n",
            "[[  19  300 2751 2783    1]]\n",
            "[[ 66  44 262 289   1]]\n",
            "epoch:13 step:    5/60, lr:0.000033, giou_loss:   0.57, conf_loss:  19.85, prob_loss:   1.34, total_loss:  21.76\n",
            "[[145 210 697 484   1]]\n",
            "[[204  63 647 458   1]]\n",
            "[[ 59  56 228 164   1]]\n",
            "[[ 75   5 318 228   2]]\n",
            "epoch:13 step:    6/60, lr:0.000033, giou_loss:   0.83, conf_loss:  20.12, prob_loss:   0.73, total_loss:  21.69\n",
            "[[ 25  42 275 297   0]]\n",
            "[[ 25   8 326 328   2]]\n",
            "[[  8 113 539 618   2]]\n",
            "[[ 56  56 476 498   0]]\n",
            "epoch:13 step:    7/60, lr:0.000033, giou_loss:   0.62, conf_loss:  19.80, prob_loss:   0.71, total_loss:  21.13\n",
            "[[226 125 562 495   2]\n",
            " [580 114 909 436   2]]\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[ 45  52 213 222   0]]\n",
            "[[138 250 402 563   2]\n",
            " [129  98 449 353   0]\n",
            " [204  34 753 336   1]]\n",
            "epoch:13 step:    8/60, lr:0.000032, giou_loss:   4.22, conf_loss:  26.44, prob_loss:   8.24, total_loss:  38.89\n",
            "[[ 349  229 1111  964    2]]\n",
            "[[  9   5 163 150   2]]\n",
            "[[ 84  76 443 409   1]\n",
            " [171  32 609 375   1]\n",
            " [190   1 655 219   1]]\n",
            "[[ 66  23 662 690   1]]\n",
            "epoch:13 step:    9/60, lr:0.000032, giou_loss:   1.33, conf_loss:  21.02, prob_loss:   2.37, total_loss:  24.71\n",
            "[[  1   1 340 203   1]]\n",
            "[[ 19  48 226 256   0]]\n",
            "[[140 300 489 668   2]\n",
            " [389 337 818 688   2]\n",
            " [621 277 965 620   2]\n",
            " [365  61 805 419   2]]\n",
            "[[196  54 381 146   1]\n",
            " [  9  53 193 147   1]]\n",
            "epoch:13 step:   10/60, lr:0.000032, giou_loss:   3.60, conf_loss:  25.12, prob_loss:   4.28, total_loss:  33.00\n",
            "[[307  20 549 275   2]\n",
            " [104  85 330 341   0]\n",
            " [143 165 716 465   1]]\n",
            "[[ 461   13 1774 1080    1]]\n",
            "[[570  10 993 417   2]\n",
            " [142 107 526 534   2]\n",
            " [102 493 582 925   2]]\n",
            "[[ 446    1 1251  214    1]]\n",
            "epoch:13 step:   11/60, lr:0.000032, giou_loss:   2.35, conf_loss:  24.04, prob_loss:   3.57, total_loss:  29.97\n",
            "[[ 22   4 415 406   2]]\n",
            "[[113  17 254 174   0]\n",
            " [ 12  12 114 121   0]\n",
            " [ 52  80 163 189   0]]\n",
            "[[ 14   3 262 259   2]]\n",
            "[[ 19  98 690 355   1]]\n",
            "epoch:13 step:   12/60, lr:0.000032, giou_loss:   1.27, conf_loss:  20.53, prob_loss:   1.36, total_loss:  23.15\n",
            "[[106   7 228 130   2]\n",
            " [  5   5 141 149   2]]\n",
            "[[103 104 224 247   2]\n",
            " [ 97   1 203 115   2]\n",
            " [  1  62 131 187   2]\n",
            " [  1   2 111  70   2]\n",
            " [ 30 201 152 250   2]]\n",
            "[[ 14   1 169 148   0]]\n",
            "[[ 93  48 519 379   1]]\n",
            "epoch:13 step:   13/60, lr:0.000032, giou_loss:   2.77, conf_loss:  22.05, prob_loss:   5.21, total_loss:  30.03\n",
            "[[ 25 200 144 315   0]\n",
            " [165 220 296 345   0]\n",
            " [221 103 327 198   0]\n",
            " [288  40 423 144   0]\n",
            " [377  85 498 201   0]\n",
            " [281 143 395 250   0]]\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "[[214  72 437 286   2]\n",
            " [415  64 642 275   0]\n",
            " [106  99 462 296   1]]\n",
            "[[393 186 957 766   0]\n",
            " [ 74 149 586 638   0]]\n",
            "epoch:13 step:   14/60, lr:0.000032, giou_loss:   6.41, conf_loss:  29.89, prob_loss:   9.55, total_loss:  45.86\n",
            "[[  5  10 328 344   0]]\n",
            "[[  4   9 233 233   2]]\n",
            "[[ 37   4 293 260   0]]\n",
            "[[ 26  13 461 455   0]]\n",
            "epoch:13 step:   15/60, lr:0.000032, giou_loss:   0.39, conf_loss:  19.60, prob_loss:   0.68, total_loss:  20.66\n",
            "[[109  36 306 806   1]]\n",
            "[[ 581   71 1230  775    0]]\n",
            "[[465 391 890 800   2]]\n",
            "[[ 35  58 642 661   0]]\n",
            "epoch:13 step:   16/60, lr:0.000031, giou_loss:   1.04, conf_loss:  20.29, prob_loss:   0.87, total_loss:  22.20\n",
            "[[  7  31 294 317   0]]\n",
            "[[ 46  21 540 268   1]\n",
            " [291  29 517 255   1]]\n",
            "[[522   8 742 209   0]\n",
            " [559 200 777 436   0]\n",
            " [430 160 629 394   0]\n",
            " [ 25 281 207 496   0]\n",
            " [137 353 314 550   0]\n",
            " [238 222 479 446   0]\n",
            " [439 333 621 526   0]\n",
            " [157 408 369 581   0]]\n",
            "[[ 25  52 527 255   1]]\n",
            "epoch:13 step:   17/60, lr:0.000031, giou_loss:   5.15, conf_loss:  26.83, prob_loss:   8.58, total_loss:  40.57\n",
            "[[ 724  338 1350 1476    1]]\n",
            "[[  3  22 365 349   2]]\n",
            "[[ 889  147 1461 1147    1]]\n",
            "[[500 101 874 479   2]\n",
            " [ 75  72 732 286   1]\n",
            " [ 92 205 678 489   1]]\n",
            "epoch:13 step:   18/60, lr:0.000031, giou_loss:   2.73, conf_loss:  22.38, prob_loss:   7.40, total_loss:  32.51\n",
            "[[399 238 678 519   2]\n",
            " [559  81 869 339   2]\n",
            " [583 328 916 565   2]]\n",
            "[[ 63  13 682 627   0]]\n",
            "[[125 133 772 497   1]]\n",
            "[[  0  76 296 394   0]]\n",
            "epoch:13 step:   19/60, lr:0.000031, giou_loss:   2.23, conf_loss:  23.00, prob_loss:   2.83, total_loss:  28.06\n",
            "[[ 55  77 238 267   2]]\n",
            "[[ 33 160 325 276   1]]\n",
            "[[ 37  23 353 316   1]\n",
            " [130  15 502 190   1]\n",
            " [117  11 483 270   1]\n",
            " [149  17 492 221   1]]\n",
            "[[ 71  13 248 176   0]]\n",
            "epoch:13 step:   20/60, lr:0.000031, giou_loss:   1.61, conf_loss:  20.71, prob_loss:   2.10, total_loss:  24.42\n",
            "[[261  33 842 438   1]\n",
            " [254 164 829 647   1]]\n",
            "[[ 70  31 298 264   2]]\n",
            "[[ 240  170 1219 1165    0]]\n",
            "[[ 34 246 204 534   1]\n",
            " [248 269 360 585   1]\n",
            " [280 229 431 486   1]\n",
            " [152 282 263 599   1]]\n",
            "epoch:13 step:   21/60, lr:0.000031, giou_loss:   3.84, conf_loss:  24.44, prob_loss:   4.30, total_loss:  32.59\n",
            "[[297 202 716 600   2]\n",
            " [ 41 128 296 369   2]]\n",
            "[[ 31   7 227 190   0]]\n",
            "[[110  68 569 318   1]]\n",
            "[[ 15 137 224 358   2]\n",
            " [217  99 422 351   2]\n",
            " [ 93   1 312 171   2]]\n",
            "epoch:13 step:   22/60, lr:0.000031, giou_loss:   1.56, conf_loss:  20.92, prob_loss:   2.91, total_loss:  25.39\n",
            "[[ 89  26 329 270   2]\n",
            " [338  21 592 288   2]]\n",
            "[[ 296  325 1049 1007    0]]\n",
            "[[  18   26 1198  492    1]]\n",
            "[[515 257 748 524   0]\n",
            " [339 345 578 569   0]\n",
            " [ 10 239 214 471   0]\n",
            " [193 191 423 406   0]\n",
            " [442 176 635 327   0]\n",
            " [301  22 533 216   0]\n",
            " [535  55 700 220   0]]\n",
            "epoch:13 step:   23/60, lr:0.000030, giou_loss:   3.51, conf_loss:  25.20, prob_loss:   4.79, total_loss:  33.49\n",
            "[[1633  394 3098 1968    2]]\n",
            "[[  52  481  430  892    2]\n",
            " [ 356  160 1078  588    1]\n",
            " [ 386  292 1056  910    1]]\n",
            "[[ 41  12 506 468   2]]\n",
            "[[ 98 151 610 708   0]]\n",
            "epoch:13 step:   24/60, lr:0.000030, giou_loss:   1.11, conf_loss:  20.03, prob_loss:   1.47, total_loss:  22.61\n",
            "[[ 22   8 296 275   2]]\n",
            "[[ 74  75 541 350   1]\n",
            " [ 98  14 531 244   1]]\n",
            "[[  6 114 342 477   2]]\n",
            "[[  17    1 1590  624    1]]\n",
            "epoch:13 step:   25/60, lr:0.000030, giou_loss:   0.97, conf_loss:  20.17, prob_loss:   2.53, total_loss:  23.68\n",
            "[[253 136 581 460   0]\n",
            " [216 421 534 686   0]\n",
            " [602 443 799 689   0]\n",
            " [467 152 726 440   0]\n",
            " [  0  36 307 387   0]]\n",
            "[[144 136 470 411   0]]\n",
            "[[ 336  116 1442 1143    0]]\n",
            "[[324 291 692 680   2]]\n",
            "epoch:13 step:   26/60, lr:0.000030, giou_loss:   2.42, conf_loss:  21.93, prob_loss:   3.37, total_loss:  27.73\n",
            "[[ 553    6 1253  713    0]]\n",
            "[[167 334 651 810   0]\n",
            " [  1 132 368 605   0]]\n",
            "[[ 11 123 184 295   2]\n",
            " [127 129 412 412   1]\n",
            " [170  41 334 202   0]]\n",
            "[[579 100 973 481   2]\n",
            " [ 96  86 497 472   0]\n",
            " [200 526 881 888   1]]\n",
            "epoch:13 step:   27/60, lr:0.000030, giou_loss:   2.40, conf_loss:  22.98, prob_loss:   2.60, total_loss:  27.98\n",
            "[[105  28 507 117   1]\n",
            " [104  36 500 188   1]\n",
            " [ 94  72 491 281   1]\n",
            " [ 17  92 368 363   1]]\n",
            "[[ 14  61 200 243   0]]\n",
            "[[155  52 575 428   2]\n",
            " [ 28 305 975 607   1]\n",
            " [531  93 900 405   0]]\n",
            "[[149  26 629 230   1]]\n",
            "epoch:13 step:   28/60, lr:0.000030, giou_loss:   3.43, conf_loss:  22.82, prob_loss:   5.28, total_loss:  31.53\n",
            "[[ 35  96 268 315   2]]\n",
            "[[ 349  176 1456  931    1]\n",
            " [  52  595 1323 1276    1]\n",
            " [ 650    9 1625  619    1]\n",
            " [ 905    9 1769  558    1]]\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[119 158 365 419   2]]\n",
            "epoch:13 step:   29/60, lr:0.000030, giou_loss:   4.89, conf_loss:  25.57, prob_loss:  13.92, total_loss:  44.38\n",
            "[[ 45   1 130  95   1]\n",
            " [ 62  30 195 110   1]\n",
            " [  1  27  47  99   1]\n",
            " [ 17   7  77  91   1]]\n",
            "[[  76  225 1477 1616    2]]\n",
            "[[ 334  212 1213 1098    2]]\n",
            "[[ 17  18 421 162   1]]\n",
            "epoch:13 step:   30/60, lr:0.000030, giou_loss:   1.93, conf_loss:  21.97, prob_loss:   3.81, total_loss:  27.71\n",
            "[[225  46 913 566   1]\n",
            " [ 58  46 487 566   1]]\n",
            "[[ 14  62 527 574   2]]\n",
            "[[ 94  53 773 801   0]]\n",
            "[[129 109 632 355   1]]\n",
            "epoch:13 step:   31/60, lr:0.000029, giou_loss:   0.68, conf_loss:  19.34, prob_loss:   0.66, total_loss:  20.68\n",
            "[[387  99 633 324   0]\n",
            " [175  96 362 346   0]\n",
            " [290  71 511 286   0]]\n",
            "[[ 19  49 220 254   2]]\n",
            "[[ 163  294 1003 1130    2]]\n",
            "[[375  70 726 443   0]\n",
            " [  2  94 409 525   0]]\n",
            "epoch:13 step:   32/60, lr:0.000029, giou_loss:   2.00, conf_loss:  21.87, prob_loss:   3.13, total_loss:  26.99\n",
            "[[179  26 490 297   1]\n",
            " [153  86 414 374   1]]\n",
            "[[ 389  821 1196 1760    1]\n",
            " [  69  770 1034 1448    1]\n",
            " [  24  645  922 1135    1]\n",
            " [ 187  458  968 1037    1]]\n",
            "[[367  34 917 586   0]\n",
            " [ 84  40 525 508   0]\n",
            " [ 11  50 288 449   0]]\n",
            "[[ 22 114 108 202   2]\n",
            " [ 54 101 132 192   2]]\n",
            "epoch:13 step:   33/60, lr:0.000029, giou_loss:   3.24, conf_loss:  23.12, prob_loss:   3.07, total_loss:  29.42\n",
            "[[ 10  15 157 159   0]]\n",
            "[[ 255   13 1213  753    2]\n",
            " [ 583  655 1381 1078    2]]\n",
            "[[  79  112  843  454    1]\n",
            " [ 365   93 1015  636    1]\n",
            " [  39   69  795  367    1]]\n",
            "[[164   2 433 266   0]]\n",
            "epoch:13 step:   34/60, lr:0.000029, giou_loss:   1.26, conf_loss:  20.74, prob_loss:   3.49, total_loss:  25.48\n",
            "[[ 75  18 262 220   2]]\n",
            "[[447 136 584 295   2]\n",
            " [457  61 593 200   2]\n",
            " [118 131 250 276   2]\n",
            " [ 76  66 225 196   2]\n",
            " [214  88 357 232   2]\n",
            " [281 140 432 282   2]\n",
            " [363  45 496 171   2]]\n",
            "[[ 88  10 267 180   2]]\n",
            "[[ 83 112 272 306   0]\n",
            " [ 35  25 200 210   0]\n",
            " [171  36 340 218   0]]\n",
            "epoch:13 step:   35/60, lr:0.000029, giou_loss:   5.25, conf_loss:  28.14, prob_loss:   8.32, total_loss:  41.70\n",
            "[[   4   46 1361 1366    0]]\n",
            "[[  29  135  293  387    2]\n",
            " [ 735  156 1006  423    2]\n",
            " [ 545  101  798  328    2]\n",
            " [ 285  135  519  343    2]]\n",
            "[[ 82  37 410 339   1]\n",
            " [128 114 526 371   1]\n",
            " [142  31 454 226   1]]\n",
            "[[373 181 685 469   2]\n",
            " [105 333 930 529   1]\n",
            " [115 452 958 660   1]]\n",
            "epoch:13 step:   36/60, lr:0.000029, giou_loss:   5.00, conf_loss:  25.62, prob_loss:   7.67, total_loss:  38.28\n",
            "[[270   3 657 196   1]\n",
            " [ 37  75 186 237   1]\n",
            " [124 122 666 311   1]]\n",
            "[[345 137 583 415   2]\n",
            " [ 67 127 323 398   2]]\n",
            "[[ 118  176 1625  952    1]]\n",
            "[[ 11 129 430 323   1]\n",
            " [102  66 424 203   1]\n",
            " [108  11 383 146   1]]\n",
            "epoch:13 step:   37/60, lr:0.000029, giou_loss:   2.95, conf_loss:  23.72, prob_loss:   4.25, total_loss:  30.91\n",
            "[[209  48 572 537   1]]\n",
            "[[ 485   27  908  453    2]\n",
            " [ 173  111  653  595    0]\n",
            " [ 283  199 1172  748    1]]\n",
            "[[ 43  65 441 480   0]]\n",
            "[[145  14 242 119   2]]\n",
            "epoch:13 step:   38/60, lr:0.000029, giou_loss:   1.83, conf_loss:  20.75, prob_loss:   1.74, total_loss:  24.32\n",
            "[[ 360  147 1214 1025    0]]\n",
            "[[  57  158 1711 1055    1]\n",
            " [ 478  207 1991 1275    1]\n",
            " [   1  132 1594  711    1]]\n",
            "[[158  54 488 386   2]]\n",
            "[[  1 257 306 563   0]\n",
            " [328 422 616 687   0]\n",
            " [244 286 527 541   0]]\n",
            "epoch:13 step:   39/60, lr:0.000028, giou_loss:   2.40, conf_loss:  21.76, prob_loss:   2.96, total_loss:  27.13\n",
            "[[  4   5 409 347   1]]\n",
            "[[178  93 400 312   2]\n",
            " [ 43  78 243 300   2]]\n",
            "[[ 30  46 554 404   1]]\n",
            "[[ 70  20 698 194   1]\n",
            " [ 56 108 643 418   1]\n",
            " [ 43  16 484 310   1]]\n",
            "epoch:13 step:   40/60, lr:0.000028, giou_loss:   1.58, conf_loss:  21.19, prob_loss:   3.23, total_loss:  26.00\n",
            "[[  7 105 476 439   0]\n",
            " [305  40 777 439   0]]\n",
            "[[506 262 670 412   2]\n",
            " [453  44 644 240   0]\n",
            " [337  39 463 426   1]\n",
            " [157 157 421 485   1]\n",
            " [256  38 410 415   1]]\n",
            "[[ 52   7 359 305   2]]\n",
            "[[ 51  72 521 514   0]]\n",
            "epoch:13 step:   41/60, lr:0.000028, giou_loss:   4.61, conf_loss:  22.88, prob_loss:   6.91, total_loss:  34.39\n",
            "[[ 53  25 655 478   1]\n",
            " [ 77   1 648 298   1]\n",
            " [114   5 625 214   1]\n",
            " [ 23 145 222 478   1]]\n",
            "[[  44  581 2500 4471    1]]\n",
            "[[ 706  257 1440  978    2]\n",
            " [ 172  181  860  843    2]]\n",
            "[[105 134 463 492   2]\n",
            " [ 41 112 638 569   1]]\n",
            "epoch:13 step:   42/60, lr:0.000028, giou_loss:   2.26, conf_loss:  21.95, prob_loss:   3.58, total_loss:  27.80\n",
            "[[ 11  16 137 156   0]]\n",
            "[[ 79  37 533 493   2]]\n",
            "[[ 23  30 133 140   0]\n",
            " [100   3 201  98   0]\n",
            " [205  16 309 127   0]]\n",
            "[[222  61 400 239   2]\n",
            " [ 29  75 197 218   0]\n",
            " [ 88 292 400 416   1]]\n",
            "epoch:13 step:   43/60, lr:0.000028, giou_loss:   2.40, conf_loss:  21.82, prob_loss:   3.38, total_loss:  27.59\n",
            "[[ 16  47 404 222   1]]\n",
            "[[203 126 285 214   2]\n",
            " [145 123 218 198   2]\n",
            " [ 15   9 245 105   1]\n",
            " [  4 144  98 235   0]]\n",
            "[[509  30 811 344   0]\n",
            " [112 116 391 369   0]\n",
            " [421 177 698 419   0]\n",
            " [ 11  90 251 358   0]]\n",
            "[[ 901  279 1518  899    2]\n",
            " [ 355  367  943  971    2]]\n",
            "epoch:13 step:   44/60, lr:0.000028, giou_loss:   3.20, conf_loss:  23.65, prob_loss:   4.68, total_loss:  31.53\n",
            "[[ 35 235 937 713   1]]\n",
            "[[ 54  63 312 311   2]\n",
            " [355  25 654 324   2]]\n",
            "[[364  43 702 404   2]\n",
            " [ 54   3 406 366   2]]\n",
            "[[ 23  14 233 276   1]]\n",
            "epoch:13 step:   45/60, lr:0.000028, giou_loss:   1.16, conf_loss:  19.83, prob_loss:   2.50, total_loss:  23.49\n",
            "[[273  94 522 346   0]\n",
            " [ 25  79 305 352   0]]\n",
            "[[164  36 595 477   2]]\n",
            "[[121  60 554 385   1]\n",
            " [269  75 643 437   1]\n",
            " [ 63  46 502 291   1]]\n",
            "[[276  76 539 364   0]\n",
            " [ 36  43 295 295   0]]\n",
            "epoch:13 step:   46/60, lr:0.000028, giou_loss:   1.59, conf_loss:  20.34, prob_loss:   1.72, total_loss:  23.64\n",
            "[[ 21  17 339 321   1]]\n",
            "[[ 82  43 231 258   1]]\n",
            "[[231  58 495 330   2]]\n",
            "[[ 46 314 161 413   2]\n",
            " [456 292 536 367   2]\n",
            " [430 235 528 312   2]\n",
            " [ 60 202 317 302   1]\n",
            " [ 98 244 332 339   1]\n",
            " [234 201 391 346   1]\n",
            " [262 251 398 380   1]\n",
            " [239 126 348 229   0]\n",
            " [349 159 463 264   0]]\n",
            "epoch:13 step:   47/60, lr:0.000027, giou_loss:   8.05, conf_loss:  30.75, prob_loss:  10.66, total_loss:  49.46\n",
            "[[ 72  18 391 130   1]]\n",
            "[[ 36   6 397 297   2]]\n",
            "[[177 124 610 553   0]]\n",
            "[[219 148 384 343   2]\n",
            " [377 143 570 366   0]\n",
            " [ 79 361 624 614   1]]\n",
            "epoch:13 step:   48/60, lr:0.000027, giou_loss:   1.61, conf_loss:  20.14, prob_loss:   2.10, total_loss:  23.86\n",
            "[[175   3 407 173   1]\n",
            " [155  34 340 207   1]\n",
            " [125  47 275 237   1]\n",
            " [ 71  66 157 281   1]]\n",
            "[[  69   83 1936 1903    2]]\n",
            "[[ 49   3 553 530   0]]\n",
            "[[ 38   9 184 152   2]\n",
            " [ 27 151 333 233   1]\n",
            " [188   4 325 149   0]]\n",
            "epoch:13 step:   49/60, lr:0.000027, giou_loss:   2.48, conf_loss:  21.21, prob_loss:   1.60, total_loss:  25.29\n",
            "[[173  64 629 550   2]]\n",
            "[[  1  11 283 256   0]]\n",
            "[[  2  45 364 410   0]]\n",
            "[[ 219  730 1022 1551    0]\n",
            " [ 725    1 1131  617    0]\n",
            " [ 508    4 1028  557    0]]\n",
            "epoch:13 step:   50/60, lr:0.000027, giou_loss:   1.77, conf_loss:  20.47, prob_loss:   8.93, total_loss:  31.17\n",
            "[[141  35 315 210   0]\n",
            " [ 18  22 168 190   0]]\n",
            "[[  1  16 294 132   1]]\n",
            "[[ 17 103 342 432   0]\n",
            " [287  70 558 361   0]]\n",
            "[[ 94  47 517 376   1]]\n",
            "epoch:13 step:   51/60, lr:0.000027, giou_loss:   1.05, conf_loss:  19.66, prob_loss:   3.07, total_loss:  23.78\n",
            "[[ 28  33 277 265   2]]\n",
            "[[177   1 540 348   0]]\n",
            "[[ 79 135 255 324   0]]\n",
            "[[ 184  221 1226  712    1]\n",
            " [  68  224 1011  751    1]]\n",
            "epoch:13 step:   52/60, lr:0.000027, giou_loss:   0.75, conf_loss:  18.99, prob_loss:   0.55, total_loss:  20.29\n",
            "[[327  92 503 262   0]\n",
            " [168  99 335 251   0]\n",
            " [406  87 560 227   0]\n",
            " [  2  42 136 190   0]]\n",
            "[[500  31 796 303   1]\n",
            " [ 39  61 307 404   1]\n",
            " [122  79 411 423   1]\n",
            " [151 159 411 553   1]\n",
            " [365 146 535 572   1]\n",
            " [431 145 722 480   1]\n",
            " [385  60 758 341   1]]\n",
            "[[ 708   81 1253  598    2]]\n",
            "[[ 79  30 392 156   1]\n",
            " [ 17  49 240 264   1]\n",
            " [ 63  58 355 207   1]]\n",
            "epoch:13 step:   53/60, lr:0.000027, giou_loss:   7.20, conf_loss:  28.53, prob_loss:   7.34, total_loss:  43.07\n",
            "[[106 104 247 345   1]\n",
            " [238  93 322 354   1]\n",
            " [328 110 401 349   1]\n",
            " [404 117 499 354   1]]\n",
            "[[129  10 271 155   0]\n",
            " [219 133 341 254   0]\n",
            " [182 249 334 373   0]\n",
            " [  1 119 167 276   0]\n",
            " [309  39 408 129   0]\n",
            " [377 186 451 261   0]\n",
            " [402  15 463  76   0]\n",
            " [395  90 460 157   0]]\n",
            "[[ 10   5 290 306   2]]\n",
            "[[212  57 381 212   2]\n",
            " [102  49 262 212   2]\n",
            " [ 58   2 200 143   2]]\n",
            "epoch:13 step:   54/60, lr:0.000027, giou_loss:   9.13, conf_loss:  33.57, prob_loss:  15.02, total_loss:  57.72\n",
            "[[ 36  38 442 457   0]]\n",
            "[[232  87 443 283   2]\n",
            " [281 326 490 544   2]\n",
            " [101 406 313 605   2]\n",
            " [176 491 378 661   2]]\n",
            "[[  13  179  746  954    2]\n",
            " [ 585  142 1278  874    2]]\n",
            "[[238 227 405 404   0]\n",
            " [ 94 219 271 376   0]\n",
            " [152 128 331 297   0]]\n",
            "epoch:13 step:   55/60, lr:0.000026, giou_loss:   3.17, conf_loss:  23.92, prob_loss:   5.73, total_loss:  32.82\n",
            "[[231 101 499 378   0]]\n",
            "[[ 69  65 472 473   2]]\n",
            "[[229 112 652 534   0]\n",
            " [497  54 821 380   0]]\n",
            "[[   0  456  955 1092    1]\n",
            " [   0  660  781 1168    1]\n",
            " [ 319  171 1499 1044    1]]\n",
            "epoch:13 step:   56/60, lr:0.000026, giou_loss:   1.89, conf_loss:  20.73, prob_loss:   1.54, total_loss:  24.16\n",
            "[[ 21  27 319 315   0]]\n",
            "[[ 76 151 679 762   2]]\n",
            "[[ 71  21 559 328   1]]\n",
            "[[ 596   69 1174  581    2]]\n",
            "epoch:13 step:   57/60, lr:0.000026, giou_loss:   0.48, conf_loss:  18.99, prob_loss:   0.50, total_loss:  19.97\n",
            "[[160  76 372 281   2]]\n",
            "[[  2  60 559 294   1]]\n",
            "[[ 791  317 1170  666    0]]\n",
            "[[152  98 350 289   2]\n",
            " [ 17  75 186 248   2]]\n",
            "epoch:13 step:   58/60, lr:0.000026, giou_loss:   1.53, conf_loss:  20.05, prob_loss:   4.80, total_loss:  26.38\n",
            "[[ 70 224 240 402   0]\n",
            " [  2 172 168 356   0]]\n",
            "[[ 33  34 212 206   0]]\n",
            "[[ 17  10 909 497   1]]\n",
            "[[144  55 337 257   0]]\n",
            "epoch:13 step:   59/60, lr:0.000026, giou_loss:   1.47, conf_loss:  19.99, prob_loss:   2.56, total_loss:  24.02\n",
            "[[  92    3 1906  926    1]]\n",
            "[[ 596  800 1230 1800    1]\n",
            " [ 289  621  814 1679    1]]\n",
            "[[121  26 428 358   0]]\n",
            "[[ 45  27 481 264   1]]\n",
            "epoch:13 step:    0/60, lr:0.000026, giou_loss:   1.83, conf_loss:  20.10, prob_loss:   4.39, total_loss:  26.33\n",
            "[[ 26  64 452 278   1]]\n",
            "[[133 438 416 708   0]\n",
            " [260 141 508 394   0]\n",
            " [510 199 824 466   0]\n",
            " [381  17 633 240   0]\n",
            " [ 93  35 358 269   0]]\n",
            "[[317 156 541 387   1]\n",
            " [ 48 182 421 368   1]\n",
            " [ 81 107 456 255   1]]\n",
            "[[199 162 423 404   2]]\n",
            "epoch:13 step:    1/60, lr:0.000026, giou_loss:   4.09, conf_loss:  25.00, prob_loss:   3.84, total_loss:  32.93\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[143  40 415 346   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "\n",
            "\n",
            "giou_val_loss:   2.86, conf_val_loss:  22.65, prob_val_loss:   4.73, total_val_loss:  30.25\n",
            "\n",
            "\n",
            "[[  1  48 340 250   1]]\n",
            "[[192  61 302 171   0]\n",
            " [124  34 225 129   0]\n",
            " [ 16  47 120 158   0]]\n",
            "[[   1  778  804 1599    0]\n",
            " [ 507   49  913  665    0]\n",
            " [ 290   52  810  605    0]]\n",
            "[[  4  38 200 221   0]]\n",
            "epoch:14 step:    2/60, lr:0.000026, giou_loss:   2.56, conf_loss:  22.07, prob_loss:   7.70, total_loss:  32.34\n",
            "[[271  32 849 544   2]]\n",
            "[[ 18  21 336 325   1]]\n",
            "[[ 34   2 488 458   2]]\n",
            "[[111 117 505 498   2]\n",
            " [587 103 988 489   0]\n",
            " [203 543 884 905   1]]\n",
            "epoch:14 step:    3/60, lr:0.000025, giou_loss:   1.15, conf_loss:  19.71, prob_loss:   3.14, total_loss:  23.99\n",
            "[[ 504  208 1266  943    2]]\n",
            "[[ 24  57 193 212   2]\n",
            " [143  49 303 212   2]\n",
            " [205   2 347 143   2]]\n",
            "[[183 230 947 572   1]\n",
            " [ 11 211 661 754   1]\n",
            " [231 187 987 485   1]]\n",
            "[[  5 154 536 659   2]]\n",
            "epoch:14 step:    4/60, lr:0.000025, giou_loss:   2.12, conf_loss:  20.87, prob_loss:   6.18, total_loss:  29.17\n",
            "[[108 103 229 246   2]\n",
            " [102   0 208 114   2]\n",
            " [  6  61 136 186   2]\n",
            " [  6   1 116  69   2]\n",
            " [ 35 200 157 249   2]]\n",
            "[[ 48  36 441 438   2]]\n",
            "[[ 56 123 476 565   0]]\n",
            "[[  7  22 255 278   2]]\n",
            "epoch:14 step:    5/60, lr:0.000025, giou_loss:   2.22, conf_loss:  22.44, prob_loss:   5.52, total_loss:  30.18\n",
            "[[251  54 494 277   2]]\n",
            "[[ 36  66 227 255   2]\n",
            " [149  58 309 236   2]]\n",
            "[[125  19 432 317   2]]\n",
            "[[177  52 374 822   1]]\n",
            "epoch:14 step:    6/60, lr:0.000025, giou_loss:   1.48, conf_loss:  19.77, prob_loss:   5.57, total_loss:  26.82\n",
            "[[ 553  120 1232  868    0]]\n",
            "[[  5  55 182 222   0]]\n",
            "[[ 42   6 225 196   2]]\n",
            "[[ 486  655 1120 1655    1]\n",
            " [ 179  476  704 1534    1]]\n",
            "epoch:14 step:    7/60, lr:0.000025, giou_loss:   1.33, conf_loss:  19.76, prob_loss:   1.56, total_loss:  22.65\n",
            "[[ 75  18 262 220   2]]\n",
            "[[192  40 414 259   2]\n",
            " [ 57  25 257 247   2]]\n",
            "[[ 15   6 112 111   2]]\n",
            "[[ 22  59 329 391   0]]\n",
            "epoch:14 step:    8/60, lr:0.000025, giou_loss:   1.15, conf_loss:  19.29, prob_loss:   5.32, total_loss:  25.76\n",
            "[[ 884  166 2349 1740    2]]\n",
            "[[106   7 228 130   2]\n",
            " [  5   5 141 149   2]]\n",
            "[[207   4 711 531   0]]\n",
            "[[316 203 695 552   0]]\n",
            "epoch:14 step:    9/60, lr:0.000025, giou_loss:   0.78, conf_loss:  18.45, prob_loss:   0.97, total_loss:  20.20\n",
            "[[ 34  19 422 194   1]]\n",
            "[[ 29  15 433 159   1]]\n",
            "[[   7    1 1580  624    1]]\n",
            "[[  2  26 284 271   0]]\n",
            "epoch:14 step:   10/60, lr:0.000025, giou_loss:   1.02, conf_loss:  18.45, prob_loss:   0.97, total_loss:  20.44\n",
            "[[ 14  18 214 206   0]]\n",
            "[[ 81  63 524 458   1]]\n",
            "[[183  42 616 367   1]\n",
            " [ 94  57 468 419   1]\n",
            " [235  28 674 273   1]]\n",
            "[[ 49  48 375 323   0]]\n",
            "epoch:14 step:   11/60, lr:0.000024, giou_loss:   1.76, conf_loss:  19.65, prob_loss:   3.44, total_loss:  24.85\n",
            "[[ 39 131 658 745   0]]\n",
            "[[ 27  34 634 637   0]]\n",
            "[[329  65 571 320   2]\n",
            " [126 130 352 386   0]\n",
            " [165 210 738 510   1]]\n",
            "[[ 90   5 291 210   2]]\n",
            "epoch:14 step:   12/60, lr:0.000024, giou_loss:   1.66, conf_loss:  20.01, prob_loss:   2.10, total_loss:  23.77\n",
            "[[ 36 158 492 644   2]]\n",
            "[[140 300 489 668   2]\n",
            " [389 337 818 688   2]\n",
            " [621 277 965 620   2]\n",
            " [365  61 805 419   2]]\n",
            "[[140  72 368 305   2]]\n",
            "[[ 39  16 326 302   0]]\n",
            "epoch:14 step:   13/60, lr:0.000024, giou_loss:   1.85, conf_loss:  21.47, prob_loss:   5.25, total_loss:  28.57\n",
            "[[ 86  42 265 212   2]]\n",
            "[[ 14  23 559 540   2]]\n",
            "[[ 100   31 1457 1351    0]]\n",
            "[[  9  62 177 232   0]]\n",
            "epoch:14 step:   14/60, lr:0.000024, giou_loss:   0.52, conf_loss:  19.06, prob_loss:   1.32, total_loss:  20.90\n",
            "[[ 75   5 355 306   2]]\n",
            "[[ 56  41 235 213   0]]\n",
            "[[106 293 531 702   2]]\n",
            "[[458 304 768 620   2]\n",
            " [  1 167 607 384   1]\n",
            " [  7 225 657 480   1]\n",
            " [ 55   2 317 295   0]]\n",
            "epoch:14 step:   15/60, lr:0.000024, giou_loss:   1.79, conf_loss:  20.41, prob_loss:   1.95, total_loss:  24.15\n",
            "[[ 248  368 1649 1759    2]]\n",
            "[[ 23  33 272 265   2]]\n",
            "[[261  72 949 592   1]\n",
            " [ 94  72 523 592   1]]\n",
            "[[509 125 811 439   0]\n",
            " [112 211 391 464   0]\n",
            " [421 272 698 514   0]\n",
            " [ 11 185 251 453   0]]\n",
            "epoch:14 step:   16/60, lr:0.000024, giou_loss:   2.12, conf_loss:  21.03, prob_loss:   2.14, total_loss:  25.29\n",
            "[[399 238 678 519   2]\n",
            " [559  81 869 339   2]\n",
            " [583 328 916 565   2]]\n",
            "[[218 207 546 531   0]\n",
            " [265 492 583 757   0]\n",
            " [  0 514 197 760   0]\n",
            " [ 73 223 332 511   0]\n",
            " [492 107 799 458   0]]\n",
            "[[ 38  31 248 293   1]]\n",
            "[[ 36  35 210 210   0]\n",
            " [183  22 333 190   0]]\n",
            "epoch:14 step:   17/60, lr:0.000024, giou_loss:   3.91, conf_loss:  24.13, prob_loss:   4.94, total_loss:  32.98\n",
            "[[  75  124  647 1124    1]]\n",
            "[[ 16   8 171 155   0]]\n",
            "[[ 23  47 507 337   1]]\n",
            "[[ 697  362 1075  773    2]\n",
            " [  49   41  771  469    1]\n",
            " [  71  173  741  791    1]]\n",
            "epoch:14 step:   18/60, lr:0.000024, giou_loss:   1.68, conf_loss:  19.02, prob_loss:   3.21, total_loss:  23.91\n",
            "[[ 77 140 310 359   2]]\n",
            "[[117 258 587 700   0]]\n",
            "[[125  58 302 221   0]]\n",
            "[[202  37 470 314   0]]\n",
            "epoch:14 step:   19/60, lr:0.000023, giou_loss:   0.95, conf_loss:  18.34, prob_loss:   1.07, total_loss:  20.36\n",
            "[[ 55  55 461 474   0]]\n",
            "[[376 129 513 288   2]\n",
            " [386  54 522 193   2]\n",
            " [ 47 124 179 269   2]\n",
            " [  5  59 154 189   2]\n",
            " [143  81 286 225   2]\n",
            " [210 133 361 275   2]\n",
            " [292  38 425 164   2]]\n",
            "[[  7  19 281 286   2]]\n",
            "[[300  81 659 414   1]\n",
            " [134  37 572 380   1]\n",
            " [ 88   6 553 224   1]]\n",
            "epoch:14 step:   20/60, lr:0.000023, giou_loss:   4.74, conf_loss:  27.74, prob_loss:   7.79, total_loss:  40.27\n",
            "[[241  23 542 343   2]]\n",
            "[[214 159 296 247   2]\n",
            " [156 156 229 231   2]\n",
            " [ 26  42 256 138   1]\n",
            " [ 15 177 109 268   0]]\n",
            "[[579   2 875 274   1]\n",
            " [118  32 386 375   1]\n",
            " [201  50 490 394   1]\n",
            " [230 130 490 524   1]\n",
            " [444 117 614 543   1]\n",
            " [510 116 801 451   1]\n",
            " [464  31 837 312   1]]\n",
            "[[ 31  11 659 185   1]\n",
            " [ 86  99 673 409   1]\n",
            " [245   7 686 301   1]]\n",
            "epoch:14 step:   21/60, lr:0.000023, giou_loss:   7.02, conf_loss:  31.70, prob_loss:   8.53, total_loss:  47.25\n",
            "[[118 101 307 295   0]\n",
            " [ 70  14 235 199   0]\n",
            " [206  25 375 207   0]]\n",
            "[[356  72 906 624   0]\n",
            " [ 73  78 514 546   0]\n",
            " [  0  88 277 487   0]]\n",
            "[[ 67 163 441 541   2]\n",
            " [209 134 866 348   1]\n",
            " [263 267 849 551   1]]\n",
            "[[147  45 288 202   0]\n",
            " [ 46  40 148 149   0]\n",
            " [ 86 108 197 217   0]]\n",
            "epoch:14 step:   22/60, lr:0.000023, giou_loss:   4.47, conf_loss:  24.91, prob_loss:   5.13, total_loss:  34.52\n",
            "[[ 14  66 140 206   0]]\n",
            "[[ 38 161 157 276   0]\n",
            " [178 181 309 306   0]\n",
            " [234  64 340 159   0]\n",
            " [301   1 436 105   0]\n",
            " [390  46 511 162   0]\n",
            " [294 104 408 211   0]]\n",
            "[[ 18  71 920 549   1]]\n",
            "[[  7  67 520 579   2]]\n",
            "epoch:14 step:   23/60, lr:0.000023, giou_loss:   4.63, conf_loss:  26.03, prob_loss:   5.26, total_loss:  35.91\n",
            "[[ 155  578 1197 1069    1]\n",
            " [  39  581  982 1108    1]]\n",
            "[[ 76  29 287 225   2]\n",
            " [ 29 268 238 486   2]\n",
            " [206 348 418 547   2]\n",
            " [141 433 343 603   2]]\n",
            "[[ 97  62 366 326   0]]\n",
            "[[ 84  71 446 398   2]]\n",
            "epoch:14 step:   24/60, lr:0.000023, giou_loss:   2.53, conf_loss:  21.41, prob_loss:   4.87, total_loss:  28.81\n",
            "[[ 864  393 1513 1097    0]]\n",
            "[[269  94 692 516   0]\n",
            " [100  36 424 362   0]]\n",
            "[[ 21  28 452 469   2]]\n",
            "[[415 261 720 567   0]\n",
            " [105 426 393 691   0]\n",
            " [194 290 477 545   0]]\n",
            "epoch:14 step:   25/60, lr:0.000023, giou_loss:   1.66, conf_loss:  20.20, prob_loss:   1.60, total_loss:  23.45\n",
            "[[  14  403  821 1342    1]\n",
            " [ 176  352 1141 1030    1]\n",
            " [ 288  227 1186  717    1]\n",
            " [ 242   40 1023  619    1]]\n",
            "[[  18   43 2750 2526    1]]\n",
            "[[124 239 288 389   2]\n",
            " [150  21 341 217   0]\n",
            " [331  16 457 403   1]\n",
            " [373 134 637 462   1]\n",
            " [384  15 538 392   1]]\n",
            "[[ 437    1 1750 1068    1]]\n",
            "epoch:14 step:   26/60, lr:0.000023, giou_loss:   4.68, conf_loss:  24.50, prob_loss:  10.59, total_loss:  39.77\n",
            "[[ 96  40 426 372   2]]\n",
            "[[349 227 861 784   0]]\n",
            "[[345 137 583 415   2]\n",
            " [ 67 127 323 398   2]]\n",
            "[[ 54  18 513 268   1]]\n",
            "epoch:14 step:   27/60, lr:0.000022, giou_loss:   1.24, conf_loss:  19.48, prob_loss:   1.57, total_loss:  22.29\n",
            "[[  53  103 1159 1130    0]]\n",
            "[[  4  26 340 389   2]]\n",
            "[[310 216 477 393   0]\n",
            " [166 208 343 365   0]\n",
            " [224 117 403 286   0]]\n",
            "[[  48  174 2504 4064    1]]\n",
            "epoch:14 step:   28/60, lr:0.000022, giou_loss:   1.73, conf_loss:  20.64, prob_loss:   3.07, total_loss:  25.44\n",
            "[[503   3 723 204   0]\n",
            " [540 195 758 431   0]\n",
            " [411 155 610 389   0]\n",
            " [  6 276 188 491   0]\n",
            " [118 348 295 545   0]\n",
            " [219 217 460 441   0]\n",
            " [420 328 602 521   0]\n",
            " [138 403 350 576   0]]\n",
            "[[ 45 202 215 490   1]\n",
            " [259 225 371 541   1]\n",
            " [291 185 442 442   1]\n",
            " [163 238 274 555   1]]\n",
            "[[ 51  68 220 176   1]]\n",
            "[[ 937   99 1360  506    2]\n",
            " [ 509  196  893  623    2]\n",
            " [ 469  582  949 1014    2]]\n",
            "epoch:14 step:   29/60, lr:0.000022, giou_loss:   9.52, conf_loss:  32.33, prob_loss:   9.54, total_loss:  51.39\n",
            "[[ 412  284 1165  966    0]]\n",
            "[[129 101 562 530   0]]\n",
            "[[ 14   8 278 280   2]]\n",
            "[[ 31  66 217 248   0]]\n",
            "epoch:14 step:   30/60, lr:0.000022, giou_loss:   0.58, conf_loss:  18.18, prob_loss:   0.59, total_loss:  19.35\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[205 196 375 374   0]\n",
            " [137 144 303 328   0]]\n",
            "[[267   2 630 349   0]]\n",
            "[[387  89 738 462   0]\n",
            " [ 14 113 421 544   0]]\n",
            "epoch:14 step:   31/60, lr:0.000022, giou_loss:   4.30, conf_loss:  23.15, prob_loss:  12.31, total_loss:  39.76\n",
            "[[249 100 422 272   2]\n",
            " [ 21 106 306 389   1]\n",
            " [ 99  18 263 179   0]]\n",
            "[[392  58 730 419   2]\n",
            " [ 82  18 434 381   2]]\n",
            "[[130  29 342 234   2]]\n",
            "[[ 88 211 451 700   1]]\n",
            "epoch:14 step:   32/60, lr:0.000022, giou_loss:   1.78, conf_loss:  20.25, prob_loss:   1.52, total_loss:  23.55\n",
            "[[100 142 349 394   0]\n",
            " [317 127 597 400   0]]\n",
            "[[303  68 772 402   0]\n",
            " [  2   3 474 402   0]]\n",
            "[[ 317  168 1424  923    1]\n",
            " [ 450  587 1721 1268    1]\n",
            " [ 148    1 1123  611    1]\n",
            " [   4    1  868  550    1]]\n",
            "[[153  98 409 328   2]\n",
            " [ 22   0 237 186   2]\n",
            " [399  46 598 296   2]\n",
            " [203  24 415 208   2]\n",
            " [300 271 564 397   2]]\n",
            "epoch:14 step:   33/60, lr:0.000022, giou_loss:   4.39, conf_loss:  23.74, prob_loss:   4.12, total_loss:  32.24\n",
            "[[600 423 883 693   0]\n",
            " [508 126 756 379   0]\n",
            " [192 184 506 451   0]\n",
            " [383   2 635 225   0]\n",
            " [658  20 923 254   0]]\n",
            "[[137  60 400 348   0]\n",
            " [381  27 640 279   0]]\n",
            "[[308  43 889 448   1]\n",
            " [301 174 876 657   1]]\n",
            "[[160  99 562 188   1]\n",
            " [159 107 555 259   1]\n",
            " [149 143 546 352   1]\n",
            " [ 72 163 423 434   1]]\n",
            "epoch:14 step:   34/60, lr:0.000022, giou_loss:   5.12, conf_loss:  25.88, prob_loss:   3.92, total_loss:  34.92\n",
            "[[ 83 189 550 464   1]\n",
            " [ 93 128 526 358   1]]\n",
            "[[ 462    1 1420  741    2]\n",
            " [ 790  643 1588 1066    2]]\n",
            "[[ 37  22 244 230   0]]\n",
            "[[ 30  38 286 294   0]]\n",
            "epoch:14 step:   35/60, lr:0.000022, giou_loss:   1.65, conf_loss:  19.85, prob_loss:   1.40, total_loss:  22.90\n",
            "[[275 100 521 325   0]\n",
            " [ 63  97 250 347   0]\n",
            " [178  72 399 287   0]]\n",
            "[[112 154 448 524   2]\n",
            " [466 143 795 465   2]]\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[  63   51 1717  948    1]\n",
            " [ 484  100 1997 1168    1]\n",
            " [   7   25 1600  604    1]]\n",
            "epoch:14 step:   36/60, lr:0.000021, giou_loss:   2.72, conf_loss:  22.85, prob_loss:   2.75, total_loss:  28.31\n",
            "[[138  20 466 322   1]\n",
            " [ 22  97 420 354   1]\n",
            " [ 94  14 406 209   1]]\n",
            "[[ 31  27 633 480   1]\n",
            " [ 55   3 626 300   1]\n",
            " [ 92   7 603 216   1]\n",
            " [  1 147 200 480   1]]\n",
            "[[397 137 709 425   2]\n",
            " [152 289 977 485   1]\n",
            " [124 408 967 616   1]]\n",
            "[[336 367 704 756   2]]\n",
            "epoch:14 step:   37/60, lr:0.000021, giou_loss:   3.63, conf_loss:  23.20, prob_loss:   8.40, total_loss:  35.23\n",
            "[[ 48 108 551 354   1]]\n",
            "[[ 11  49 568 283   1]]\n",
            "[[ 24  18 276 277   2]]\n",
            "[[  2  13 149 157   0]]\n",
            "epoch:14 step:   38/60, lr:0.000021, giou_loss:   0.67, conf_loss:  19.02, prob_loss:   1.79, total_loss:  21.48\n",
            "[[113  69 615 272   1]]\n",
            "[[ 50  25 228 203   2]\n",
            " [253  39 421 182   0]\n",
            " [ 50 256 362 380   1]]\n",
            "[[ 98   1 586 308   1]]\n",
            "[[ 11  37 160 252   1]]\n",
            "epoch:14 step:   39/60, lr:0.000021, giou_loss:   1.57, conf_loss:  19.97, prob_loss:   0.87, total_loss:  22.41\n",
            "[[  3   9 882 895   2]]\n",
            "[[137   6 369 176   1]\n",
            " [117  37 302 210   1]\n",
            " [ 87  50 237 240   1]\n",
            " [ 33  69 119 284   1]]\n",
            "[[ 44   9 744 716   0]]\n",
            "[[ 58 137 267 358   2]\n",
            " [260  99 465 351   2]\n",
            " [136   1 355 171   2]]\n",
            "epoch:14 step:   40/60, lr:0.000021, giou_loss:   2.70, conf_loss:  21.96, prob_loss:   3.25, total_loss:  27.90\n",
            "[[125 133 772 497   1]]\n",
            "[[169   1 831 704   2]]\n",
            "[[ 148  302  882 1023    2]\n",
            " [ 728  226 1416  888    2]]\n",
            "[[   4    9 1184  475    1]]\n",
            "epoch:14 step:   41/60, lr:0.000021, giou_loss:   1.06, conf_loss:  18.68, prob_loss:   1.48, total_loss:  21.22\n",
            "[[ 24  20 178 165   2]]\n",
            "[[  1 159 672 416   1]]\n",
            "[[129  19 364 263   0]]\n",
            "[[  7 251 240 518   0]\n",
            " [177 339 416 563   0]\n",
            " [541 233 745 465   0]\n",
            " [332 185 562 400   0]\n",
            " [120 170 313 321   0]\n",
            " [222  16 454 210   0]\n",
            " [ 55  49 220 214   0]]\n",
            "epoch:14 step:   42/60, lr:0.000021, giou_loss:   3.46, conf_loss:  23.99, prob_loss:   3.54, total_loss:  31.00\n",
            "[[ 287  233 1141 1111    0]]\n",
            "[[144  55 337 257   0]]\n",
            "[[ 57 120 143 208   2]\n",
            " [ 89 107 167 198   2]]\n",
            "[[ 193  207 1700  983    1]]\n",
            "epoch:14 step:   43/60, lr:0.000021, giou_loss:   1.61, conf_loss:  20.37, prob_loss:   2.91, total_loss:  24.88\n",
            "[[  1  36 424 365   1]]\n",
            "[[ 46 241 270 483   2]]\n",
            "[[146  22 507 313   2]]\n",
            "[[ 42  54 300 302   2]\n",
            " [343  16 642 315   2]]\n",
            "epoch:14 step:   44/60, lr:0.000020, giou_loss:   0.72, conf_loss:  17.78, prob_loss:   1.24, total_loss:  19.74\n",
            "[[114 289 290 459   0]\n",
            " [282 296 449 448   0]\n",
            " [ 57 284 211 424   0]\n",
            " [481 239 615 387   0]]\n",
            "[[ 250  109 1090  945    2]]\n",
            "[[369 236 633 549   2]\n",
            " [322  84 642 339   0]\n",
            " [ 18  20 567 322   1]]\n",
            "[[ 15 273 130 372   2]\n",
            " [425 251 505 326   2]\n",
            " [399 194 497 271   2]\n",
            " [ 29 161 286 261   1]\n",
            " [ 67 203 301 298   1]\n",
            " [203 160 360 305   1]\n",
            " [231 210 367 339   1]\n",
            " [208  85 317 188   0]\n",
            " [318 118 432 223   0]]\n",
            "epoch:14 step:   45/60, lr:0.000020, giou_loss:   9.72, conf_loss:  30.02, prob_loss:  10.87, total_loss:  50.62\n",
            "[[   3   33 1870 1853    2]]\n",
            "[[449 183 868 581   2]\n",
            " [193 109 448 350   2]]\n",
            "[[ 73   5 177 112   2]]\n",
            "[[ 10  62 504 309   1]\n",
            " [ 33  70 259 296   1]]\n",
            "epoch:14 step:   46/60, lr:0.000020, giou_loss:   1.61, conf_loss:  19.61, prob_loss:   9.25, total_loss:  30.47\n",
            "[[211  60 667 429   2]]\n",
            "[[ 20  33 446 247   1]]\n",
            "[[ 66   1 151  95   1]\n",
            " [  1  30 134 110   1]\n",
            " [149  27 195  99   1]\n",
            " [119   7 179  91   1]]\n",
            "[[ 47  52 379 381   2]]\n",
            "epoch:14 step:   47/60, lr:0.000020, giou_loss:   1.43, conf_loss:  20.48, prob_loss:   2.00, total_loss:  23.91\n",
            "[[ 24  11 253 235   2]]\n",
            "[[292 217 457 412   2]\n",
            " [106 212 299 435   0]\n",
            " [ 52 430 597 683   1]]\n",
            "[[106 156 586 360   1]]\n",
            "[[194  23 336 168   0]\n",
            " [124 146 246 267   0]\n",
            " [131 262 283 386   0]\n",
            " [298 132 464 289   0]\n",
            " [ 57  52 156 142   0]\n",
            " [ 14 199  88 274   0]\n",
            " [  2  28  63  89   0]\n",
            " [  5 103  70 170   0]]\n",
            "epoch:14 step:   48/60, lr:0.000020, giou_loss:   6.87, conf_loss:  27.37, prob_loss:   7.17, total_loss:  41.41\n",
            "[[319  21 915 688   1]]\n",
            "[[ 58  28 199 269   1]\n",
            " [190  17 274 278   1]\n",
            " [280  34 353 273   1]\n",
            " [356  41 451 278   1]]\n",
            "[[ 388 1125 1014 2263    1]]\n",
            "[[ 43 135 219 324   0]]\n",
            "epoch:14 step:   49/60, lr:0.000020, giou_loss:   4.92, conf_loss:  22.11, prob_loss:   9.39, total_loss:  36.43\n",
            "[[112 137 515 545   2]]\n",
            "[[254 114 551 401   0]]\n",
            "[[  6  55 331 384   0]\n",
            " [276  22 547 313   0]]\n",
            "[[239  45 424 137   1]\n",
            " [ 52  44 236 138   1]]\n",
            "epoch:14 step:   50/60, lr:0.000020, giou_loss:   2.58, conf_loss:  20.14, prob_loss:   2.88, total_loss:  25.59\n",
            "[[106 126 352 387   2]]\n",
            "[[ 68 110 292 341   1]\n",
            " [188 136 561 322   1]\n",
            " [153  61 528 209   1]]\n",
            "[[  9  75 273 327   2]\n",
            " [715  96 986 363   2]\n",
            " [525  41 778 268   2]\n",
            " [265  75 499 283   2]]\n",
            "[[ 22  38 335 164   1]\n",
            " [174  57 397 272   1]\n",
            " [ 59  66 351 215   1]]\n",
            "epoch:14 step:   51/60, lr:0.000020, giou_loss:   3.93, conf_loss:  23.10, prob_loss:   6.90, total_loss:  33.93\n",
            "[[   1    1 1815  924    1]]\n",
            "[[125  90 483 448   2]\n",
            " [ 61  68 658 525   1]]\n",
            "[[ 210   28 1189 1023    0]]\n",
            "[[ 22   7 262 211   0]]\n",
            "epoch:14 step:   52/60, lr:0.000020, giou_loss:   0.82, conf_loss:  18.46, prob_loss:   2.90, total_loss:  22.18\n",
            "[[ 17 154 436 348   1]\n",
            " [108  91 430 228   1]\n",
            " [114  36 389 171   1]]\n",
            "[[ 22 299 506 775   0]\n",
            " [305  97 672 570   0]]\n",
            "[[197 121 393 366   1]]\n",
            "[[  3 133 299 451   0]]\n",
            "epoch:14 step:   53/60, lr:0.000019, giou_loss:   1.70, conf_loss:  19.80, prob_loss:   3.59, total_loss:  25.09\n",
            "[[ 19  51 201 262   0]]\n",
            "[[167  83 603 320   1]]\n",
            "[[  0  45 405 387   1]]\n",
            "[[408  29 828 405   2]\n",
            " [  8 282 955 584   1]\n",
            " [ 83  70 452 382   0]]\n",
            "epoch:14 step:   54/60, lr:0.000019, giou_loss:   1.46, conf_loss:  19.15, prob_loss:   1.63, total_loss:  22.23\n",
            "[[ 86  19 402 312   1]\n",
            " [179  11 551 186   1]\n",
            " [166   7 532 266   1]\n",
            " [198  13 541 217   1]]\n",
            "[[ 551   58 1284  833    2]\n",
            " [  19   21  712  753    2]]\n",
            "[[ 502    8  925  434    2]\n",
            " [ 190   92  670  576    0]\n",
            " [ 300  180 1189  729    1]]\n",
            "[[   0  456  955 1092    1]\n",
            " [   0  660  781 1168    1]\n",
            " [ 319  171 1499 1044    1]]\n",
            "epoch:14 step:   55/60, lr:0.000019, giou_loss:   3.50, conf_loss:  22.08, prob_loss:   3.04, total_loss:  28.62\n",
            "[[127  54 679 328   1]]\n",
            "[[380  51 944 631   0]\n",
            " [ 61  14 573 503   0]]\n",
            "[[ 67  48 493 379   1]]\n",
            "[[ 65 265 668 876   2]]\n",
            "epoch:14 step:   56/60, lr:0.000019, giou_loss:   1.05, conf_loss:  19.23, prob_loss:   1.18, total_loss:  21.46\n",
            "[[  6 110 298 226   1]]\n",
            "[[  1  60 294 176   1]]\n",
            "[[  3  23 895 510   1]]\n",
            "[[318 146 680 511   0]]\n",
            "epoch:14 step:   57/60, lr:0.000019, giou_loss:   0.81, conf_loss:  17.87, prob_loss:   0.33, total_loss:  19.01\n",
            "[[179   5 490 276   1]\n",
            " [153  65 414 353   1]]\n",
            "[[160  10 558 425   0]]\n",
            "[[268  12 508 256   2]\n",
            " [  5   7 259 274   2]]\n",
            "[[  8  12 327 124   1]]\n",
            "epoch:14 step:   58/60, lr:0.000019, giou_loss:   0.96, conf_loss:  18.17, prob_loss:   0.80, total_loss:  19.93\n",
            "[[ 41  41 239 232   2]\n",
            " [205  18 374 191   2]]\n",
            "[[ 257  388 1228 1172    1]\n",
            " [ 291  447  915 1046    0]]\n",
            "[[180   7 704 365   1]]\n",
            "[[361  49 826 505   2]]\n",
            "epoch:14 step:   59/60, lr:0.000019, giou_loss:   1.49, conf_loss:  18.53, prob_loss:   2.13, total_loss:  22.15\n",
            "[[ 42  55 477 497   0]]\n",
            "[[  3  27 253 282   0]]\n",
            "[[ 36   7 182 150   2]\n",
            " [ 25 149 331 231   1]\n",
            " [186   2 323 147   0]]\n",
            "[[ 599  346 1216  966    2]\n",
            " [  53  434  641 1038    2]]\n",
            "epoch:14 step:    0/60, lr:0.000019, giou_loss:   1.22, conf_loss:  18.36, prob_loss:   1.02, total_loss:  20.60\n",
            "[[ 18  15 341 349   0]]\n",
            "[[ 31  17 329 305   0]]\n",
            "[[315 231 538 445   2]\n",
            " [110 223 337 434   0]\n",
            " [290 258 646 455   1]]\n",
            "[[245   1 632 194   1]\n",
            " [ 12  73 161 235   1]\n",
            " [ 99 120 641 309   1]]\n",
            "epoch:14 step:    1/60, lr:0.000019, giou_loss:   3.13, conf_loss:  22.82, prob_loss:   6.78, total_loss:  32.73\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[143  40 415 346   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[145  36 421 286   2]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  21.82, prob_val_loss:   4.11, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[532  42 926 423   2]\n",
            " [ 49  28 450 414   0]\n",
            " [153 468 834 830   1]]\n",
            "[[ 53  10 281 243   2]]\n",
            "[[ 20  14 318 302   0]]\n",
            "[[132  98 388 328   2]\n",
            " [  1   0 216 186   2]\n",
            " [378  46 577 296   2]\n",
            " [182  24 394 208   2]\n",
            " [279 271 543 397   2]]\n",
            "epoch:15 step:    2/60, lr:0.000018, giou_loss:   2.62, conf_loss:  21.15, prob_loss:   6.10, total_loss:  29.86\n",
            "[[  43   31 1149 1058    0]]\n",
            "[[255   1 562 299   2]]\n",
            "[[254 231 617 720   1]]\n",
            "[[149  27 477 329   1]\n",
            " [195 104 593 361   1]\n",
            " [209  21 521 216   1]]\n",
            "epoch:15 step:    3/60, lr:0.000018, giou_loss:   1.28, conf_loss:  18.81, prob_loss:   1.97, total_loss:  22.06\n",
            "[[ 41 260 943 738   1]]\n",
            "[[169 128 772 739   2]]\n",
            "[[   3   59 2459 3949    1]]\n",
            "[[373 104 514 345   1]\n",
            " [298  93 382 354   1]\n",
            " [219 110 292 349   1]\n",
            " [121 117 216 354   1]]\n",
            "epoch:15 step:    4/60, lr:0.000018, giou_loss:   3.80, conf_loss:  21.85, prob_loss:   3.60, total_loss:  29.25\n",
            "[[  23  316 2755 2799    1]]\n",
            "[[ 37  35 344 367   0]]\n",
            "[[416 217 728 505   2]\n",
            " [171 369 996 565   1]\n",
            " [143 488 986 696   1]]\n",
            "[[  5   8 287 253   0]]\n",
            "epoch:15 step:    5/60, lr:0.000018, giou_loss:   1.97, conf_loss:  19.55, prob_loss:   1.12, total_loss:  22.65\n",
            "[[ 58   4 377 116   1]]\n",
            "[[ 57  73 225 243   0]]\n",
            "[[ 59  79 418 412   1]\n",
            " [146  35 584 378   1]\n",
            " [165   4 630 222   1]]\n",
            "[[129  26 303 201   0]\n",
            " [  6  13 156 181   0]]\n",
            "epoch:15 step:    6/60, lr:0.000018, giou_loss:   1.24, conf_loss:  18.51, prob_loss:   1.96, total_loss:  21.71\n",
            "[[124 199 557 628   0]]\n",
            "[[137  77 525 252   1]]\n",
            "[[171 236 859 756   1]\n",
            " [  4 236 433 756   1]]\n",
            "[[ 63  48 273 310   1]]\n",
            "epoch:15 step:    7/60, lr:0.000018, giou_loss:   1.08, conf_loss:  18.12, prob_loss:   1.87, total_loss:  21.07\n",
            "[[ 20  52 197 215   0]]\n",
            "[[ 14  18 210 201   0]]\n",
            "[[110 120 292 331   0]]\n",
            "[[368 109 706 470   2]\n",
            " [ 58  69 410 432   2]]\n",
            "epoch:15 step:    8/60, lr:0.000018, giou_loss:   0.63, conf_loss:  17.55, prob_loss:   1.77, total_loss:  19.94\n",
            "[[112  25 288 214   0]]\n",
            "[[ 863  178 1512  882    0]]\n",
            "[[ 78  49 481 457   2]]\n",
            "[[  3  49 342 251   1]]\n",
            "epoch:15 step:    9/60, lr:0.000018, giou_loss:   0.80, conf_loss:  18.03, prob_loss:   0.35, total_loss:  19.18\n",
            "[[ 93  79 272 249   2]]\n",
            "[[ 26 340 318 456   1]]\n",
            "[[ 146   13 1459 1080    1]]\n",
            "[[329 265 936 868   0]]\n",
            "epoch:15 step:   10/60, lr:0.000018, giou_loss:   1.15, conf_loss:  19.47, prob_loss:   0.47, total_loss:  21.08\n",
            "[[202  11 783 416   1]\n",
            " [195 142 770 625   1]]\n",
            "[[ 64  51 168 158   2]]\n",
            "[[ 14  49 272 297   2]\n",
            " [315  11 614 310   2]]\n",
            "[[  7 105 476 439   0]\n",
            " [305  40 777 439   0]]\n",
            "epoch:15 step:   11/60, lr:0.000017, giou_loss:   2.15, conf_loss:  19.49, prob_loss:   2.36, total_loss:  24.01\n",
            "[[137  67 306 175   1]]\n",
            "[[  42   66 1909 1886    2]]\n",
            "[[129  69 271 214   0]\n",
            " [219 192 341 313   0]\n",
            " [182 308 334 432   0]\n",
            " [  1 178 167 335   0]\n",
            " [309  98 408 188   0]\n",
            " [377 245 451 320   0]\n",
            " [402  74 463 135   0]\n",
            " [395 149 460 216   0]]\n",
            "[[ 56 113 278 332   2]\n",
            " [213  98 413 320   2]]\n",
            "epoch:15 step:   12/60, lr:0.000017, giou_loss:   5.45, conf_loss:  27.55, prob_loss:   7.83, total_loss:  40.83\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[ 317  168 1424  923    1]\n",
            " [ 450  587 1721 1268    1]\n",
            " [ 148    1 1123  611    1]\n",
            " [   4    1  868  550    1]]\n",
            "[[191 268 675 744   0]\n",
            " [ 25  66 392 539   0]]\n",
            "[[196  29 792 696   1]]\n",
            "epoch:15 step:   13/60, lr:0.000017, giou_loss:   2.22, conf_loss:  21.07, prob_loss:   3.71, total_loss:  27.00\n",
            "[[  96  217 1075 1212    0]]\n",
            "[[  2 118  84 206   2]\n",
            " [ 69 115 142 190   2]\n",
            " [ 42   1 272  97   1]\n",
            " [189 136 283 227   0]]\n",
            "[[ 45   1 130  95   1]\n",
            " [ 62  30 195 110   1]\n",
            " [  1  27  47  99   1]\n",
            " [ 17   7  77  91   1]]\n",
            "[[ 75  81 271 326   1]]\n",
            "epoch:15 step:   14/60, lr:0.000017, giou_loss:   2.81, conf_loss:  21.79, prob_loss:   3.97, total_loss:  28.56\n",
            "[[ 35  46 161 186   0]]\n",
            "[[ 15  24 265 279   0]]\n",
            "[[ 27  62 197 240   0]\n",
            " [ 99  10 265 194   0]]\n",
            "[[222  61 665 456   1]]\n",
            "epoch:15 step:   15/60, lr:0.000017, giou_loss:   0.97, conf_loss:  18.22, prob_loss:   1.80, total_loss:  20.99\n",
            "[[ 13  87 186 259   2]\n",
            " [129  93 414 376   1]\n",
            " [172   5 336 166   0]]\n",
            "[[202  25 635 350   1]\n",
            " [113  40 487 402   1]\n",
            " [254  11 693 256   1]]\n",
            "[[584 438 867 708   0]\n",
            " [492 141 740 394   0]\n",
            " [176 199 490 466   0]\n",
            " [367  17 619 240   0]\n",
            " [642  35 907 269   0]]\n",
            "[[283 100 532 352   0]\n",
            " [ 35  85 315 358   0]]\n",
            "epoch:15 step:   16/60, lr:0.000017, giou_loss:   4.41, conf_loss:  24.35, prob_loss:   5.03, total_loss:  33.79\n",
            "[[ 74  16 480 435   0]]\n",
            "[[488 159 767 440   2]\n",
            " [297   2 607 260   2]\n",
            " [250 249 583 486   2]]\n",
            "[[   7   20 1187  486    1]]\n",
            "[[274 114 693 512   2]\n",
            " [ 18  40 273 281   2]]\n",
            "epoch:15 step:   17/60, lr:0.000017, giou_loss:   2.58, conf_loss:  20.84, prob_loss:   4.33, total_loss:  27.74\n",
            "[[ 93 100 495 189   1]\n",
            " [ 92 108 488 260   1]\n",
            " [ 82 144 479 353   1]\n",
            " [  5 164 356 435   1]]\n",
            "[[  4  29 183 201   0]]\n",
            "[[ 69  43 218 258   1]]\n",
            "[[ 10 223 681 480   1]]\n",
            "epoch:15 step:   18/60, lr:0.000017, giou_loss:   2.30, conf_loss:  20.75, prob_loss:   5.48, total_loss:  28.53\n",
            "[[ 36 158 492 644   2]]\n",
            "[[ 51  58 137 146   2]\n",
            " [ 27  45 105 136   2]]\n",
            "[[ 88  19 271 209   2]]\n",
            "[[ 75  18 262 220   2]]\n",
            "epoch:15 step:   19/60, lr:0.000017, giou_loss:   1.12, conf_loss:  17.42, prob_loss:   9.61, total_loss:  28.14\n",
            "[[179   5 490 276   1]\n",
            " [153  65 414 353   1]]\n",
            "[[  8 154 427 348   1]\n",
            " [ 14  91 336 228   1]\n",
            " [ 55  36 330 171   1]]\n",
            "[[138 250 402 563   2]\n",
            " [129  98 449 353   0]\n",
            " [204  34 753 336   1]]\n",
            "[[ 87 137 325 415   2]\n",
            " [347 127 603 398   2]]\n",
            "epoch:15 step:   20/60, lr:0.000017, giou_loss:   2.82, conf_loss:  21.76, prob_loss:   6.50, total_loss:  31.09\n",
            "[[ 455  220 1089 1220    1]\n",
            " [ 148   41  673 1099    1]]\n",
            "[[346 106 993 470   1]]\n",
            "[[182   5 328 148   2]\n",
            " [ 33 147 339 229   1]\n",
            " [ 41   0 178 145   0]]\n",
            "[[ 13  11 262 243   2]]\n",
            "epoch:15 step:   21/60, lr:0.000016, giou_loss:   1.64, conf_loss:  18.20, prob_loss:   1.63, total_loss:  21.48\n",
            "[[  4  15 252 271   2]]\n",
            "[[ 46  55 343 342   0]]\n",
            "[[ 15  61 201 243   0]]\n",
            "[[137  36 234 141   2]]\n",
            "epoch:15 step:   22/60, lr:0.000016, giou_loss:   0.65, conf_loss:  17.74, prob_loss:   0.89, total_loss:  19.29\n",
            "[[ 96 107 580 397   1]]\n",
            "[[   0  456  955 1092    1]\n",
            " [   0  660  781 1168    1]\n",
            " [ 319  171 1499 1044    1]]\n",
            "[[  87   99 1444 1419    0]]\n",
            "[[ 90  92 709 706   0]]\n",
            "epoch:15 step:   23/60, lr:0.000016, giou_loss:   1.25, conf_loss:  18.52, prob_loss:   1.01, total_loss:  20.78\n",
            "[[ 31  11 283 270   2]]\n",
            "[[  3  13 203 201   0]]\n",
            "[[135 123 440 429   0]\n",
            " [462 288 750 553   0]\n",
            " [378 152 661 407   0]]\n",
            "[[434  36 899 492   2]]\n",
            "epoch:15 step:   24/60, lr:0.000016, giou_loss:   1.44, conf_loss:  19.63, prob_loss:   3.10, total_loss:  24.18\n",
            "[[171  43 833 746   2]]\n",
            "[[433 161 552 276   0]\n",
            " [281 181 412 306   0]\n",
            " [250  64 356 159   0]\n",
            " [154   1 289 105   0]\n",
            " [ 79  46 200 162   0]\n",
            " [182 104 296 211   0]]\n",
            "[[151  74 397 335   2]]\n",
            "[[ 39  17 236 787   1]]\n",
            "epoch:15 step:   25/60, lr:0.000016, giou_loss:   5.09, conf_loss:  25.20, prob_loss:   4.99, total_loss:  35.28\n",
            "[[118 110 516 525   0]]\n",
            "[[144 136 470 411   0]]\n",
            "[[209  25 400 214   2]\n",
            " [127  17 287 195   2]]\n",
            "[[ 83  40 975 527   1]]\n",
            "epoch:15 step:   26/60, lr:0.000016, giou_loss:   1.10, conf_loss:  17.99, prob_loss:   1.51, total_loss:  20.60\n",
            "[[ 470  161  992  495    1]\n",
            " [ 628    1 1169  298    1]\n",
            " [   1    3  412  344    1]\n",
            " [   1  249  260  669    1]\n",
            " [ 229  449  710  674    1]\n",
            " [ 822  480 1198  674    1]]\n",
            "[[144  27 309 222   2]\n",
            " [302  22 495 245   0]\n",
            " [  4 240 549 493   1]]\n",
            "[[ 211  546 1612 1937    2]]\n",
            "[[113  99 569 468   2]]\n",
            "epoch:15 step:   27/60, lr:0.000016, giou_loss:   4.98, conf_loss:  25.72, prob_loss:   9.31, total_loss:  40.02\n",
            "[[ 63  52 274 248   2]\n",
            " [ 16 291 225 509   2]\n",
            " [193 371 405 570   2]\n",
            " [128 456 330 626   2]]\n",
            "[[  9   6 156 150   0]]\n",
            "[[ 86   1 599 513   2]]\n",
            "[[ 576  193 1310  914    2]\n",
            " [  42  117  730  779    2]]\n",
            "epoch:15 step:   28/60, lr:0.000016, giou_loss:   2.72, conf_loss:  22.34, prob_loss:   8.21, total_loss:  33.28\n",
            "[[175 177 939 519   1]\n",
            " [  3 158 653 701   1]\n",
            " [223 134 979 432   1]]\n",
            "[[ 17   9 194 176   0]]\n",
            "[[315 231 538 445   2]\n",
            " [110 223 337 434   0]\n",
            " [290 258 646 455   1]]\n",
            "[[  6  60 299 176   1]]\n",
            "epoch:15 step:   29/60, lr:0.000016, giou_loss:   2.46, conf_loss:  19.65, prob_loss:   4.50, total_loss:  26.61\n",
            "[[535 248 871 618   2]\n",
            " [188 237 517 559   2]]\n",
            "[[ 26   7 233 215   0]]\n",
            "[[126 223 596 665   0]]\n",
            "[[ 67   8 222 155   0]]\n",
            "epoch:15 step:   30/60, lr:0.000015, giou_loss:   1.29, conf_loss:  19.17, prob_loss:   1.66, total_loss:  22.12\n",
            "[[217  33 395 211   2]\n",
            " [ 24  47 192 190   0]\n",
            " [ 83 264 395 388   1]]\n",
            "[[ 163  294 1003 1130    2]]\n",
            "[[ 34  31 528 278   1]\n",
            " [279  39 505 265   1]]\n",
            "[[ 52  54 287 298   0]]\n",
            "epoch:15 step:   31/60, lr:0.000015, giou_loss:   1.92, conf_loss:  19.09, prob_loss:   4.83, total_loss:  25.84\n",
            "[[ 36  18 265 242   2]]\n",
            "[[  7 129 433 343   1]]\n",
            "[[ 18  30 128 140   0]\n",
            " [ 95   3 196  98   0]\n",
            " [200  16 304 127   0]]\n",
            "[[ 64 136 288 378   2]]\n",
            "epoch:15 step:   32/60, lr:0.000015, giou_loss:   1.56, conf_loss:  18.94, prob_loss:   1.54, total_loss:  22.04\n",
            "[[349 227 861 784   0]]\n",
            "[[ 44  17 568 375   1]]\n",
            "[[ 76 199 252 369   0]\n",
            " [244 206 411 358   0]\n",
            " [ 19 194 173 334   0]\n",
            " [443 149 577 297   0]]\n",
            "[[120  45 481 336   2]]\n",
            "epoch:15 step:   33/60, lr:0.000015, giou_loss:   2.86, conf_loss:  20.41, prob_loss:   4.07, total_loss:  27.33\n",
            "[[ 97  68 533 305   1]]\n",
            "[[ 37   6 460 335   1]]\n",
            "[[ 141   20  713 1020    1]]\n",
            "[[114  47 430 340   1]\n",
            " [207  39 579 214   1]\n",
            " [194  35 560 294   1]\n",
            " [226  41 569 245   1]]\n",
            "epoch:15 step:   34/60, lr:0.000015, giou_loss:   1.58, conf_loss:  18.91, prob_loss:   3.23, total_loss:  23.72\n",
            "[[ 27  18 655 192   1]\n",
            " [ 13 106 600 416   1]\n",
            " [  0  14 441 308   1]]\n",
            "[[ 572   27 1325  709    0]]\n",
            "[[134  13 256 136   2]\n",
            " [ 33  11 169 155   2]]\n",
            "[[ 52   3 483 444   2]]\n",
            "epoch:15 step:   35/60, lr:0.000015, giou_loss:   2.13, conf_loss:  18.93, prob_loss:   3.90, total_loss:  24.96\n",
            "[[215  50 448 269   2]]\n",
            "[[222   8 486 280   2]]\n",
            "[[  25  245  651 1383    1]]\n",
            "[[193   8 378 100   1]\n",
            " [  6   7 190 101   1]]\n",
            "epoch:15 step:   36/60, lr:0.000015, giou_loss:   2.46, conf_loss:  22.09, prob_loss:   3.86, total_loss:  28.42\n",
            "[[ 551   58 1284  833    2]\n",
            " [  19   21  712  753    2]]\n",
            "[[134  14 275 171   0]\n",
            " [ 33   9 135 118   0]\n",
            " [ 73  77 184 186   0]]\n",
            "[[ 350    1 1923  624    1]]\n",
            "[[ 40   6 260 207   0]\n",
            " [  5 198 223 434   0]\n",
            " [153 158 352 392   0]\n",
            " [575 279 757 494   0]\n",
            " [468 351 645 548   0]\n",
            " [303 220 544 444   0]\n",
            " [161 331 343 524   0]\n",
            " [413 406 625 579   0]]\n",
            "epoch:15 step:   37/60, lr:0.000015, giou_loss:   5.58, conf_loss:  25.66, prob_loss:   5.48, total_loss:  36.71\n",
            "[[ 909  247 1332  654    2]\n",
            " [1376  344 1760  771    2]\n",
            " [1320  730 1800 1162    2]]\n",
            "[[108 277 223 376   2]\n",
            " [518 255 598 330   2]\n",
            " [492 198 590 275   2]\n",
            " [122 165 379 265   1]\n",
            " [160 207 394 302   1]\n",
            " [296 164 453 309   1]\n",
            " [324 214 460 343   1]\n",
            " [301  89 410 192   0]\n",
            " [411 122 525 227   0]]\n",
            "[[218 162 546 486   0]\n",
            " [265 447 583 712   0]\n",
            " [  0 469 197 715   0]\n",
            " [ 73 178 332 466   0]\n",
            " [492  62 799 413   0]]\n",
            "[[ 25   6 343 310   1]]\n",
            "epoch:15 step:   38/60, lr:0.000015, giou_loss:  11.08, conf_loss:  32.99, prob_loss:  14.75, total_loss:  58.83\n",
            "[[620  23 916 295   1]\n",
            " [159  53 427 396   1]\n",
            " [242  71 531 415   1]\n",
            " [271 151 531 545   1]\n",
            " [485 138 655 564   1]\n",
            " [551 137 842 472   1]\n",
            " [505  52 878 333   1]]\n",
            "[[467 341 777 657   2]\n",
            " [ 10 204 616 421   1]\n",
            " [ 16 262 666 517   1]\n",
            " [ 64  39 326 332   0]]\n",
            "[[150  37 418 314   0]]\n",
            "[[  23  390  830 1329    1]\n",
            " [ 185  339 1150 1017    1]\n",
            " [ 297  214 1195  704    1]\n",
            " [ 251   27 1032  606    1]]\n",
            "epoch:15 step:   39/60, lr:0.000015, giou_loss:   6.58, conf_loss:  26.99, prob_loss:   7.39, total_loss:  40.97\n",
            "[[133  58 376 281   2]]\n",
            "[[ 75  73 407 402   2]]\n",
            "[[415 123 552 282   2]\n",
            " [425  48 561 187   2]\n",
            " [ 86 118 218 263   2]\n",
            " [ 44  53 193 183   2]\n",
            " [182  75 325 219   2]\n",
            " [249 127 400 269   2]\n",
            " [331  32 464 158   2]]\n",
            "[[165  57 334 212   2]\n",
            " [ 55  49 215 212   2]\n",
            " [ 11   2 153 143   2]]\n",
            "epoch:15 step:   40/60, lr:0.000014, giou_loss:   5.19, conf_loss:  26.14, prob_loss:  12.33, total_loss:  43.66\n",
            "[[725  49 989 301   2]\n",
            " [ 12  70 283 337   2]\n",
            " [220  15 473 242   2]\n",
            " [499  49 733 257   2]]\n",
            "[[259  20 646 213   1]\n",
            " [ 26  92 175 254   1]\n",
            " [113 139 655 328   1]]\n",
            "[[ 425    6 1383  746    2]\n",
            " [ 753  648 1551 1071    2]]\n",
            "[[  71   91 1578  867    1]]\n",
            "epoch:15 step:   41/60, lr:0.000014, giou_loss:   4.03, conf_loss:  24.58, prob_loss:   8.70, total_loss:  37.31\n",
            "[[ 42  86 282 330   2]\n",
            " [291  81 545 348   2]]\n",
            "[[111 150 300 344   0]\n",
            " [ 63  63 228 248   0]\n",
            " [199  74 368 256   0]]\n",
            "[[ 21  53 456 495   0]]\n",
            "[[ 13 163 565 437   1]]\n",
            "epoch:15 step:   42/60, lr:0.000014, giou_loss:   1.30, conf_loss:  18.40, prob_loss:   1.03, total_loss:  20.72\n",
            "[[ 38  25 640 478   1]\n",
            " [ 45   1 616 298   1]\n",
            " [ 68   5 579 214   1]\n",
            " [471 145 670 478   1]]\n",
            "[[178 271 536 629   2]\n",
            " [  3 249 600 706   1]]\n",
            "[[1411  232 2876 1806    2]]\n",
            "[[129 109 632 355   1]]\n",
            "epoch:15 step:   43/60, lr:0.000014, giou_loss:   1.95, conf_loss:  19.62, prob_loss:   2.63, total_loss:  24.20\n",
            "[[ 40  55 494 511   2]]\n",
            "[[361 262 525 412   2]\n",
            " [308  44 499 240   0]\n",
            " [192  39 318 426   1]\n",
            " [ 12 157 276 485   1]\n",
            " [111  38 265 415   1]]\n",
            "[[101  45 402 365   2]]\n",
            "[[  12   91 1054  582    1]\n",
            " [ 227   94 1170  621    1]]\n",
            "epoch:15 step:   44/60, lr:0.000014, giou_loss:   3.54, conf_loss:  20.00, prob_loss:   5.37, total_loss:  28.92\n",
            "[[ 629   54 1054  463    2]]\n",
            "[[404 173 827 595   0]\n",
            " [235 115 559 441   0]]\n",
            "[[123  12 459 375   2]]\n",
            "[[317 156 541 387   1]\n",
            " [ 48 182 421 368   1]\n",
            " [ 81 107 456 255   1]]\n",
            "epoch:15 step:   45/60, lr:0.000014, giou_loss:   2.18, conf_loss:  19.56, prob_loss:   4.62, total_loss:  26.35\n",
            "[[ 75  21 563 328   1]]\n",
            "[[ 408   41  831  467    2]\n",
            " [  96  125  576  609    0]\n",
            " [ 206  213 1095  762    1]]\n",
            "[[153  19 573 395   2]\n",
            " [ 26 272 973 574   1]\n",
            " [529  60 898 372   0]]\n",
            "[[ 13  54 183 342   1]\n",
            " [227  77 339 393   1]\n",
            " [259  37 410 294   1]\n",
            " [131  90 242 407   1]]\n",
            "epoch:15 step:   46/60, lr:0.000014, giou_loss:   4.65, conf_loss:  22.91, prob_loss:   4.71, total_loss:  32.27\n",
            "[[  3   3 326 337   0]]\n",
            "[[ 89 107 451 472   0]]\n",
            "[[126 120 585 370   1]]\n",
            "[[ 13  28 287 295   2]]\n",
            "epoch:15 step:   47/60, lr:0.000014, giou_loss:   0.41, conf_loss:  17.42, prob_loss:   0.50, total_loss:  18.33\n",
            "[[106 110 608 313   1]]\n",
            "[[150   6 654 533   0]]\n",
            "[[  0  76 296 394   0]]\n",
            "[[ 63  44 319 300   0]]\n",
            "epoch:15 step:   48/60, lr:0.000014, giou_loss:   0.70, conf_loss:  18.76, prob_loss:   0.75, total_loss:  20.21\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "[[  5  80 330 409   0]\n",
            " [275  47 546 338   0]]\n",
            "[[ 52 257 285 524   0]\n",
            " [222 345 461 569   0]\n",
            " [586 239 790 471   0]\n",
            " [377 191 607 406   0]\n",
            " [165 176 358 327   0]\n",
            " [267  22 499 216   0]\n",
            " [100  55 265 220   0]]\n",
            "[[582 163 956 541   2]\n",
            " [157 134 814 348   1]\n",
            " [174 267 760 551   1]]\n",
            "epoch:15 step:   49/60, lr:0.000014, giou_loss:   5.89, conf_loss:  27.50, prob_loss:   8.71, total_loss:  42.11\n",
            "[[127 103 248 246   2]\n",
            " [121   0 227 114   2]\n",
            " [ 25  61 155 186   2]\n",
            " [ 25   1 135  69   2]\n",
            " [ 54 200 176 249   2]]\n",
            "[[  1 135 532 640   2]]\n",
            "[[ 17  57 421 201   1]]\n",
            "[[ 434   80 1113  828    0]]\n",
            "epoch:15 step:   50/60, lr:0.000014, giou_loss:   2.42, conf_loss:  20.79, prob_loss:   5.61, total_loss:  28.82\n",
            "[[  2 105 214 310   2]]\n",
            "[[232  46 658 377   1]]\n",
            "[[384 102 948 682   0]\n",
            " [ 65  65 577 554   0]]\n",
            "[[ 225  240 1196 1024    1]\n",
            " [ 259  299  883  898    0]]\n",
            "epoch:15 step:   51/60, lr:0.000013, giou_loss:   1.13, conf_loss:  18.43, prob_loss:   1.94, total_loss:  21.50\n",
            "[[187 149 388 354   2]]\n",
            "[[327  71 569 326   2]\n",
            " [124 136 350 392   0]\n",
            " [163 216 736 516   1]]\n",
            "[[ 68   4 447 353   0]]\n",
            "[[   3    1 1817  924    1]]\n",
            "epoch:15 step:   52/60, lr:0.000013, giou_loss:   2.08, conf_loss:  19.20, prob_loss:   2.29, total_loss:  23.57\n",
            "[[144  10 537 412   2]]\n",
            "[[ 47 149 256 370   2]\n",
            " [249 111 454 363   2]\n",
            " [125  13 344 183   2]]\n",
            "[[  7  81 552 598   2]]\n",
            "[[174  95 594 537   0]]\n",
            "epoch:15 step:   53/60, lr:0.000013, giou_loss:   1.38, conf_loss:  18.45, prob_loss:   2.98, total_loss:  22.81\n",
            "[[  5  34 292 320   0]]\n",
            "[[ 20  48 333 174   1]\n",
            " [172  67 395 282   1]\n",
            " [ 57  76 349 225   1]]\n",
            "[[ 19 100 299 401   2]]\n",
            "[[  10  730  813 1551    0]\n",
            " [ 516    1  922  617    0]\n",
            " [ 299    4  819  557    0]]\n",
            "epoch:15 step:   54/60, lr:0.000013, giou_loss:   2.38, conf_loss:  18.69, prob_loss:   2.20, total_loss:  23.27\n",
            "[[176  46 445 310   0]]\n",
            "[[190   4 890 711   0]]\n",
            "[[213  30 459 255   0]\n",
            " [  1  27 188 277   0]\n",
            " [116   2 337 217   0]]\n",
            "[[ 36 199 203 376   0]\n",
            " [170 191 347 348   0]\n",
            " [110 100 289 269   0]]\n",
            "epoch:15 step:   55/60, lr:0.000013, giou_loss:   2.86, conf_loss:  21.49, prob_loss:   6.64, total_loss:  31.00\n",
            "[[149 213 517 602   2]]\n",
            "[[269 222 736 497   1]\n",
            " [279 161 712 391   1]]\n",
            "[[ 222   69 1076  947    0]]\n",
            "[[ 24  20 178 165   2]]\n",
            "epoch:15 step:   56/60, lr:0.000013, giou_loss:   1.04, conf_loss:  18.08, prob_loss:   2.05, total_loss:  21.17\n",
            "[[ 82   2 445 349   0]]\n",
            "[[140 300 489 668   2]\n",
            " [389 337 818 688   2]\n",
            " [621 277 965 620   2]\n",
            " [365  61 805 419   2]]\n",
            "[[152  67 350 258   2]\n",
            " [ 17  44 186 217   2]]\n",
            "[[  1  56 406 398   1]]\n",
            "epoch:15 step:   57/60, lr:0.000013, giou_loss:   2.28, conf_loss:  20.92, prob_loss:   3.56, total_loss:  26.76\n",
            "[[ 568  142 1330  877    2]]\n",
            "[[ 15  12 247 182   1]\n",
            " [ 82  43 267 216   1]\n",
            " [147  56 297 246   1]\n",
            " [265  75 351 290   1]]\n",
            "[[  1  98 558 332   1]]\n",
            "[[ 263  316 1142 1202    2]]\n",
            "epoch:15 step:   58/60, lr:0.000013, giou_loss:   2.08, conf_loss:  19.03, prob_loss:   2.19, total_loss:  23.30\n",
            "[[  1  11 194 213   0]]\n",
            "[[ 858  489 1236  900    2]\n",
            " [ 210  168  932  596    1]\n",
            " [ 232  300  902  918    1]]\n",
            "[[ 73  89 403 421   2]]\n",
            "[[ 415  282 1032  902    2]\n",
            " [ 990  370 1578  974    2]]\n",
            "epoch:15 step:   59/60, lr:0.000013, giou_loss:   1.50, conf_loss:  18.34, prob_loss:   1.79, total_loss:  21.63\n",
            "[[ 596   69 1174  581    2]]\n",
            "[[  4  71 366 398   2]]\n",
            "[[  57  191 1711 1088    1]\n",
            " [ 478  240 1991 1308    1]\n",
            " [   1  165 1594  744    1]]\n",
            "[[ 16 156 496 360   1]]\n",
            "epoch:15 step:    0/60, lr:0.000013, giou_loss:   1.22, conf_loss:  19.02, prob_loss:   1.26, total_loss:  21.50\n",
            "[[ 11   8 251 212   0]]\n",
            "[[ 22  59 285 347   0]\n",
            " [266  26 525 278   0]]\n",
            "[[ 26  89 377 462   0]\n",
            " [343 113 750 544   0]]\n",
            "[[ 43  33 593 585   0]\n",
            " [435  39 876 507   0]\n",
            " [672  49 949 448   0]]\n",
            "epoch:15 step:    1/60, lr:0.000012, giou_loss:   1.97, conf_loss:  20.31, prob_loss:   6.17, total_loss:  28.45\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[174  20 364 199   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[155 105 453 436   0]]\n",
            "[[111  51 372 277   2]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 63  17 560 323   1]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  20.87, prob_val_loss:   3.97, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[  53    1 1867  924    1]]\n",
            "[[ 45  52 194 267   1]]\n",
            "[[202  37 470 314   0]]\n",
            "[[ 84  43 403 155   1]]\n",
            "epoch:16 step:    2/60, lr:0.000012, giou_loss:   1.34, conf_loss:  18.66, prob_loss:   1.73, total_loss:  21.72\n",
            "[[104   9 226 132   2]\n",
            " [  3   7 139 151   2]]\n",
            "[[ 30  21 156 161   0]]\n",
            "[[ 22   3 320 291   0]]\n",
            "[[  3  38 895 525   1]]\n",
            "epoch:16 step:    3/60, lr:0.000012, giou_loss:   0.99, conf_loss:  17.21, prob_loss:   0.69, total_loss:  18.89\n",
            "[[ 32  12 324 128   1]]\n",
            "[[ 110  730  913 1551    0]\n",
            " [   1    1  407  617    0]\n",
            " [ 104    4  624  557    0]]\n",
            "[[ 27   3 256 227   2]]\n",
            "[[ 18  49 264 310   2]]\n",
            "epoch:16 step:    4/60, lr:0.000012, giou_loss:   1.53, conf_loss:  18.96, prob_loss:   1.35, total_loss:  21.83\n",
            "[[  24  188 2480 4078    1]]\n",
            "[[158  55 617 305   1]]\n",
            "[[152  98 350 289   2]\n",
            " [ 17  75 186 248   2]]\n",
            "[[ 87  35 590 281   1]]\n",
            "epoch:16 step:    5/60, lr:0.000012, giou_loss:   1.07, conf_loss:  17.84, prob_loss:   0.77, total_loss:  19.68\n",
            "[[106   2 537 443   2]]\n",
            "[[136 117 240 224   2]]\n",
            "[[  4  92 409 434   1]]\n",
            "[[353 221 617 534   2]\n",
            " [306  69 626 324   0]\n",
            " [  2   5 551 307   1]]\n",
            "epoch:16 step:    6/60, lr:0.000012, giou_loss:   1.50, conf_loss:  18.55, prob_loss:   2.76, total_loss:  22.81\n",
            "[[204 246 716 803   0]]\n",
            "[[  3  28 342 230   1]]\n",
            "[[154 111 573 509   2]\n",
            " [574  37 829 278   2]]\n",
            "[[ 42  73 670 247   1]\n",
            " [ 28 161 615 471   1]\n",
            " [ 15  69 456 363   1]]\n",
            "epoch:16 step:    7/60, lr:0.000012, giou_loss:   1.75, conf_loss:  18.69, prob_loss:   3.22, total_loss:  23.65\n",
            "[[ 31  21 457 352   1]]\n",
            "[[ 52 257 285 524   0]\n",
            " [222 345 461 569   0]\n",
            " [586 239 790 471   0]\n",
            " [377 191 607 406   0]\n",
            " [165 176 358 327   0]\n",
            " [267  22 499 216   0]\n",
            " [100  55 265 220   0]]\n",
            "[[120  38 553 467   0]]\n",
            "[[173 111 384 307   2]\n",
            " [126 350 335 568   2]\n",
            " [303 430 515 629   2]\n",
            " [238 515 440 685   2]]\n",
            "epoch:16 step:    8/60, lr:0.000012, giou_loss:   4.87, conf_loss:  25.37, prob_loss:   6.98, total_loss:  37.21\n",
            "[[ 16  33 170 178   2]]\n",
            "[[ 25 123 538 635   2]]\n",
            "[[ 85  44 704 658   0]]\n",
            "[[ 43  13 184 170   0]\n",
            " [183   8 285 117   0]\n",
            " [134  76 245 185   0]]\n",
            "epoch:16 step:    9/60, lr:0.000012, giou_loss:   1.24, conf_loss:  18.14, prob_loss:   1.64, total_loss:  21.02\n",
            "[[ 42  60 235 262   0]]\n",
            "[[ 168    1 1126  741    2]\n",
            " [   0  643  798 1066    2]]\n",
            "[[  23   43 2755 2526    1]]\n",
            "[[ 14  10 346 339   2]]\n",
            "epoch:16 step:   10/60, lr:0.000012, giou_loss:   0.99, conf_loss:  18.80, prob_loss:   1.21, total_loss:  21.01\n",
            "[[359 161 478 276   0]\n",
            " [207 181 338 306   0]\n",
            " [176  64 282 159   0]\n",
            " [ 80   1 215 105   0]\n",
            " [  5  46 126 162   0]\n",
            " [108 104 222 211   0]]\n",
            "[[  5  39 253 295   2]]\n",
            "[[121 161 588 436   1]\n",
            " [145 100 578 330   1]]\n",
            "[[134 126 301 303   0]\n",
            " [268 118 445 275   0]\n",
            " [208  27 387 196   0]]\n",
            "epoch:16 step:   11/60, lr:0.000012, giou_loss:   5.44, conf_loss:  25.75, prob_loss:   8.91, total_loss:  40.09\n",
            "[[  5  18 152 162   0]]\n",
            "[[ 39  68 222 258   2]]\n",
            "[[1633  394 3098 1968    2]]\n",
            "[[ 25  46 194 154   1]]\n",
            "epoch:16 step:   12/60, lr:0.000011, giou_loss:   0.59, conf_loss:  17.77, prob_loss:   1.26, total_loss:  19.63\n",
            "[[ 28  74 125 179   2]]\n",
            "[[275 125 521 350   0]\n",
            " [ 63 122 250 372   0]\n",
            " [178  97 399 312   0]]\n",
            "[[242  14 930 534   1]\n",
            " [ 75  14 504 534   1]]\n",
            "[[ 412  161 1291 1047    2]]\n",
            "epoch:16 step:   13/60, lr:0.000011, giou_loss:   1.98, conf_loss:  19.73, prob_loss:   1.60, total_loss:  23.31\n",
            "[[ 75  28 245 316   1]\n",
            " [289  51 401 367   1]\n",
            " [321  11 472 268   1]\n",
            " [193  64 304 381   1]]\n",
            "[[154  99 410 329   2]\n",
            " [ 23   1 238 187   2]\n",
            " [400  47 599 297   2]\n",
            " [204  25 416 209   2]\n",
            " [301 272 565 398   2]]\n",
            "[[218 163 546 487   0]\n",
            " [265 448 583 713   0]\n",
            " [  0 470 197 716   0]\n",
            " [ 73 179 332 467   0]\n",
            " [492  63 799 414   0]]\n",
            "[[167   7 468 327   2]]\n",
            "epoch:16 step:   14/60, lr:0.000011, giou_loss:   7.11, conf_loss:  28.25, prob_loss:   7.96, total_loss:  43.32\n",
            "[[  1 171 532 676   2]]\n",
            "[[138 166 540 255   1]\n",
            " [145 174 541 326   1]\n",
            " [154 210 551 419   1]\n",
            " [277 230 628 501   1]]\n",
            "[[105  17 708 628   2]]\n",
            "[[  27  575  834 1514    1]\n",
            " [ 189  524 1154 1202    1]\n",
            " [ 301  399 1199  889    1]\n",
            " [ 255  212 1036  791    1]]\n",
            "epoch:16 step:   15/60, lr:0.000011, giou_loss:   3.23, conf_loss:  21.99, prob_loss:  11.07, total_loss:  36.28\n",
            "[[355 289 531 459   0]\n",
            " [196 296 363 448   0]\n",
            " [434 284 588 424   0]\n",
            " [ 30 239 164 387   0]]\n",
            "[[209   3 572 350   0]]\n",
            "[[130 262 294 412   2]\n",
            " [156  44 347 240   0]\n",
            " [337  39 463 426   1]\n",
            " [379 157 643 485   1]\n",
            " [390  38 544 415   1]]\n",
            "[[538  41 932 422   2]\n",
            " [ 55  27 456 413   0]\n",
            " [159 467 840 829   1]]\n",
            "epoch:16 step:   16/60, lr:0.000011, giou_loss:   5.72, conf_loss:  23.59, prob_loss:   9.81, total_loss:  39.12\n",
            "[[  52  153 1409 1473    0]]\n",
            "[[ 23  90 511 397   1]]\n",
            "[[ 84 132 266 343   0]]\n",
            "[[ 57 120 143 208   2]\n",
            " [ 89 107 167 198   2]]\n",
            "epoch:16 step:   17/60, lr:0.000011, giou_loss:   1.11, conf_loss:  18.89, prob_loss:   1.83, total_loss:  21.82\n",
            "[[258   1 645 194   1]\n",
            " [ 25  73 174 235   1]\n",
            " [112 120 654 309   1]]\n",
            "[[150  50 329 222   0]]\n",
            "[[148  31 322 206   0]\n",
            " [ 25  18 175 186   0]]\n",
            "[[ 31   4 280 236   2]]\n",
            "epoch:16 step:   18/60, lr:0.000011, giou_loss:   1.95, conf_loss:  19.09, prob_loss:   2.32, total_loss:  23.36\n",
            "[[ 21   4 344 338   0]]\n",
            "[[   5   38  738  813    2]\n",
            " [ 577    1 1270  733    2]]\n",
            "[[ 82  64 418 427   2]]\n",
            "[[ 79  97 255 286   0]]\n",
            "epoch:16 step:   19/60, lr:0.000011, giou_loss:   0.88, conf_loss:  17.38, prob_loss:   3.09, total_loss:  21.36\n",
            "[[  2  65 673 322   1]]\n",
            "[[ 23 139 160 298   2]\n",
            " [ 14  64 150 203   2]\n",
            " [357 134 489 279   2]\n",
            " [382  69 531 199   2]\n",
            " [250  91 393 235   2]\n",
            " [175 143 326 285   2]\n",
            " [111  48 244 174   2]]\n",
            "[[160 151 913 833   0]]\n",
            "[[166  36 586 412   2]\n",
            " [ 39 289 986 591   1]\n",
            " [542  77 911 389   0]]\n",
            "epoch:16 step:   20/60, lr:0.000011, giou_loss:   5.17, conf_loss:  25.49, prob_loss:   6.82, total_loss:  37.48\n",
            "[[141 155 499 513   2]\n",
            " [ 77 133 674 590   1]]\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "[[ 75  64 315 308   2]\n",
            " [324  59 578 326   2]]\n",
            "[[153 171 318 366   2]\n",
            " [311 166 504 389   0]\n",
            " [ 13 384 558 637   1]]\n",
            "epoch:16 step:   21/60, lr:0.000011, giou_loss:   4.08, conf_loss:  21.21, prob_loss:   4.24, total_loss:  29.53\n",
            "[[  83  148  817  869    2]\n",
            " [ 663   72 1351  734    2]]\n",
            "[[ 410   11 1110  718    0]]\n",
            "[[ 485   43  908  469    2]\n",
            " [ 173  127  653  611    0]\n",
            " [ 283  215 1172  764    1]]\n",
            "[[ 65 426 348 696   0]\n",
            " [192 129 440 382   0]\n",
            " [442 187 756 454   0]\n",
            " [313   5 565 228   0]\n",
            " [ 25  23 290 257   0]]\n",
            "epoch:16 step:   22/60, lr:0.000011, giou_loss:   3.28, conf_loss:  22.47, prob_loss:   6.63, total_loss:  32.37\n",
            "[[ 11   3 322 274   1]\n",
            " [ 87  63 348 351   1]]\n",
            "[[242 102 415 274   2]\n",
            " [ 14 108 299 391   1]\n",
            " [ 92  20 256 181   0]]\n",
            "[[115   7 639 365   1]]\n",
            "[[467 341 777 657   2]\n",
            " [ 10 204 616 421   1]\n",
            " [ 16 262 666 517   1]\n",
            " [ 64  39 326 332   0]]\n",
            "epoch:16 step:   23/60, lr:0.000011, giou_loss:   2.35, conf_loss:  19.36, prob_loss:   3.01, total_loss:  24.72\n",
            "[[  9  39 272 327   0]\n",
            " [253   6 512 258   0]]\n",
            "[[196 317 575 666   0]]\n",
            "[[ 31 138 240 359   2]\n",
            " [233 100 438 352   2]\n",
            " [109   2 328 172   2]]\n",
            "[[ 795  369 1173  780    2]\n",
            " [ 147   48  869  476    1]\n",
            " [ 169  180  839  798    1]]\n",
            "epoch:16 step:   24/60, lr:0.000010, giou_loss:   2.12, conf_loss:  19.31, prob_loss:   4.97, total_loss:  26.40\n",
            "[[582 163 956 541   2]\n",
            " [157 134 814 348   1]\n",
            " [174 267 760 551   1]]\n",
            "[[  1  27 294 143   1]]\n",
            "[[140   8 317 171   0]]\n",
            "[[ 30  50 692 753   2]]\n",
            "epoch:16 step:   25/60, lr:0.000010, giou_loss:   1.98, conf_loss:  17.72, prob_loss:   1.13, total_loss:  20.82\n",
            "[[ 748  252 1012  504    2]\n",
            " [  35  273  306  540    2]\n",
            " [ 243  218  496  445    2]\n",
            " [ 522  252  756  460    2]]\n",
            "[[  5  33 279 300   2]]\n",
            "[[ 17  49 421 193   1]]\n",
            "[[218  66 487 330   0]]\n",
            "epoch:16 step:   26/60, lr:0.000010, giou_loss:   2.41, conf_loss:  19.87, prob_loss:   5.40, total_loss:  27.68\n",
            "[[  7  77 369 442   0]]\n",
            "[[ 21  44 523 247   1]]\n",
            "[[ 17  32 245 265   2]]\n",
            "[[ 476    6 1123  370    1]]\n",
            "epoch:16 step:   27/60, lr:0.000010, giou_loss:   0.84, conf_loss:  16.94, prob_loss:   0.48, total_loss:  18.25\n",
            "[[  13    1 1586  624    1]]\n",
            "[[306  86 985 834   0]]\n",
            "[[  5 156 424 350   1]\n",
            " [ 96  93 418 230   1]\n",
            " [102  38 377 173   1]]\n",
            "[[170  11 568 426   0]]\n",
            "epoch:16 step:   28/60, lr:0.000010, giou_loss:   1.55, conf_loss:  18.72, prob_loss:   3.58, total_loss:  23.84\n",
            "[[ 202  253 1173 1037    1]\n",
            " [ 236  312  860  911    0]]\n",
            "[[150 115 346 360   1]]\n",
            "[[ 98  99 287 293   0]\n",
            " [ 50  12 215 197   0]\n",
            " [186  23 355 205   0]]\n",
            "[[ 21  13 231 275   1]]\n",
            "epoch:16 step:   29/60, lr:0.000010, giou_loss:   1.53, conf_loss:  18.72, prob_loss:   3.32, total_loss:  23.57\n",
            "[[415 261 720 567   0]\n",
            " [105 426 393 691   0]\n",
            " [194 290 477 545   0]]\n",
            "[[404 173 827 595   0]\n",
            " [235 115 559 441   0]]\n",
            "[[202  57 783 462   1]\n",
            " [195 188 770 671   1]]\n",
            "[[ 87   8 274 210   2]]\n",
            "epoch:16 step:   30/60, lr:0.000010, giou_loss:   2.02, conf_loss:  19.96, prob_loss:   1.88, total_loss:  23.86\n",
            "[[ 15  12 247 182   1]\n",
            " [ 82  43 267 216   1]\n",
            " [147  56 297 246   1]\n",
            " [265  75 351 290   1]]\n",
            "[[ 17  51 196 221   2]]\n",
            "[[ 86  26 540 482   2]]\n",
            "[[ 36 351 938 829   1]]\n",
            "epoch:16 step:   31/60, lr:0.000010, giou_loss:   2.05, conf_loss:  18.95, prob_loss:   1.81, total_loss:  22.81\n",
            "[[ 89 251 438 619   2]\n",
            " [338 288 767 639   2]\n",
            " [570 228 914 571   2]\n",
            " [314  12 754 370   2]]\n",
            "[[ 141   11 1454 1078    1]]\n",
            "[[ 63  12 275 217   2]]\n",
            "[[ 569  252 1195 1390    1]]\n",
            "epoch:16 step:   32/60, lr:0.000010, giou_loss:   2.77, conf_loss:  22.34, prob_loss:   4.34, total_loss:  29.45\n",
            "[[ 46  55 343 342   0]]\n",
            "[[240  40 565 369   0]\n",
            " [ 24   7 295 298   0]]\n",
            "[[185  73 354 228   2]\n",
            " [ 75  65 235 228   2]\n",
            " [ 31  18 173 159   2]]\n",
            "[[ 18  42 196 220   2]\n",
            " [221  56 389 199   0]\n",
            " [ 18 273 330 397   1]]\n",
            "epoch:16 step:   33/60, lr:0.000010, giou_loss:   2.42, conf_loss:  19.49, prob_loss:   3.52, total_loss:  25.43\n",
            "[[ 32   4 393 295   2]]\n",
            "[[  69  297 1024  933    1]\n",
            " [  69  501  850 1009    1]\n",
            " [ 388   12 1568  885    1]]\n",
            "[[100 107 584 397   1]]\n",
            "[[166  45 631 501   2]]\n",
            "epoch:16 step:   34/60, lr:0.000010, giou_loss:   1.25, conf_loss:  17.40, prob_loss:   2.61, total_loss:  21.26\n",
            "[[345 137 583 415   2]\n",
            " [ 67 127 323 398   2]]\n",
            "[[  6 212 121 311   2]\n",
            " [416 190 496 265   2]\n",
            " [390 133 488 210   2]\n",
            " [ 20 100 277 200   1]\n",
            " [ 58 142 292 237   1]\n",
            " [194  99 351 244   1]\n",
            " [222 149 358 278   1]\n",
            " [199  24 308 127   0]\n",
            " [309  57 423 162   0]]\n",
            "[[192   2 377  94   1]\n",
            " [  5   1 189  95   1]]\n",
            "[[ 18  21 336 325   1]]\n",
            "epoch:16 step:   35/60, lr:0.000010, giou_loss:   8.57, conf_loss:  29.21, prob_loss:  12.12, total_loss:  49.91\n",
            "[[  5  13 287 258   0]]\n",
            "[[  18  114 1198  580    1]]\n",
            "[[ 65  36 352 322   0]]\n",
            "[[ 336  116 1442 1143    0]]\n",
            "epoch:16 step:   36/60, lr:0.000009, giou_loss:   0.65, conf_loss:  17.11, prob_loss:   0.77, total_loss:  18.53\n",
            "[[  4  45 181 212   0]]\n",
            "[[ 11  25 613 478   1]\n",
            " [ 18   1 589 298   1]\n",
            " [ 41   5 552 214   1]\n",
            " [444 145 643 478   1]]\n",
            "[[ 15  26 267 285   2]]\n",
            "[[  2  13 237 257   0]]\n",
            "epoch:16 step:   37/60, lr:0.000009, giou_loss:   1.66, conf_loss:  19.07, prob_loss:   1.75, total_loss:  22.48\n",
            "[[  2   1 198 184   0]]\n",
            "[[ 99 156 323 387   1]\n",
            " [219 182 592 368   1]\n",
            " [184 107 559 255   1]]\n",
            "[[ 566   24 1183  644    2]\n",
            " [  20  112  608  716    2]]\n",
            "[[ 45  28 130 122   1]\n",
            " [ 62  57 195 137   1]\n",
            " [  1  54  47 126   1]\n",
            " [ 17  34  77 118   1]]\n",
            "epoch:16 step:   38/60, lr:0.000009, giou_loss:   2.75, conf_loss:  20.22, prob_loss:   5.13, total_loss:  28.10\n",
            "[[  23  185  863 1021    2]]\n",
            "[[215  41 325 151   0]\n",
            " [147  14 248 109   0]\n",
            " [ 39  27 143 138   0]]\n",
            "[[  28  484  662 1484    1]\n",
            " [ 444  305  969 1363    1]]\n",
            "[[340  70 885 587   2]]\n",
            "epoch:16 step:   39/60, lr:0.000009, giou_loss:   1.97, conf_loss:  19.55, prob_loss:   2.35, total_loss:  23.86\n",
            "[[ 29  73 226 843   1]]\n",
            "[[  1  98 427 312   1]]\n",
            "[[ 37   9 257 210   0]\n",
            " [  2 201 220 437   0]\n",
            " [150 161 349 395   0]\n",
            " [572 282 754 497   0]\n",
            " [465 354 642 551   0]\n",
            " [300 223 541 447   0]\n",
            " [158 334 340 527   0]\n",
            " [410 409 622 582   0]]\n",
            "[[ 73  61 399 336   0]]\n",
            "epoch:16 step:   40/60, lr:0.000009, giou_loss:   4.57, conf_loss:  23.19, prob_loss:   4.16, total_loss:  31.92\n",
            "[[128  30 456 332   1]\n",
            " [ 12 107 410 364   1]\n",
            " [ 84  24 396 219   1]]\n",
            "[[  5 141 356 514   0]\n",
            " [322 165 729 596   0]]\n",
            "[[ 27  72 521 319   1]\n",
            " [272  80 498 306   1]]\n",
            "[[ 639   11 1288  715    0]]\n",
            "epoch:16 step:   41/60, lr:0.000009, giou_loss:   1.85, conf_loss:  18.78, prob_loss:   7.56, total_loss:  28.19\n",
            "[[283 106 703 548   0]]\n",
            "[[339 181 651 469   2]\n",
            " [ 94 333 919 529   1]\n",
            " [ 66 452 909 660   1]]\n",
            "[[ 11  10 467 379   2]]\n",
            "[[181  20 584 428   2]]\n",
            "epoch:16 step:   42/60, lr:0.000009, giou_loss:   1.79, conf_loss:  18.62, prob_loss:   3.23, total_loss:  23.63\n",
            "[[103   5 399 277   1]\n",
            " [592  35 860 378   1]\n",
            " [488  53 777 397   1]\n",
            " [488 133 748 527   1]\n",
            " [364 120 534 546   1]\n",
            " [177 119 468 454   1]\n",
            " [141  34 514 315   1]]\n",
            "[[ 31  68 217 250   0]]\n",
            "[[ 12  27 212 215   0]]\n",
            "[[ 24  65 574 617   0]\n",
            " [416  71 857 539   0]\n",
            " [653  81 930 480   0]]\n",
            "epoch:16 step:   43/60, lr:0.000009, giou_loss:   4.50, conf_loss:  23.89, prob_loss:  12.46, total_loss:  40.84\n",
            "[[  46  225 1088  716    1]\n",
            " [ 261  228 1204  755    1]]\n",
            "[[114  46 315 251   2]]\n",
            "[[267 322 635 711   2]]\n",
            "[[548  69 884 439   2]\n",
            " [201  58 530 380   2]]\n",
            "epoch:16 step:   44/60, lr:0.000009, giou_loss:   1.34, conf_loss:  18.29, prob_loss:   1.94, total_loss:  21.57\n",
            "[[ 175  368 1576 1759    2]]\n",
            "[[194  45 336 190   0]\n",
            " [124 168 246 289   0]\n",
            " [131 284 283 408   0]\n",
            " [298 154 464 311   0]\n",
            " [ 57  74 156 164   0]\n",
            " [ 14 221  88 296   0]\n",
            " [  2  50  63 111   0]\n",
            " [  5 125  70 192   0]]\n",
            "[[ 74  82 638 662   0]\n",
            " [445  45 957 534   0]]\n",
            "[[ 86  11 474 186   1]]\n",
            "epoch:16 step:   45/60, lr:0.000009, giou_loss:   6.01, conf_loss:  25.23, prob_loss:   6.45, total_loss:  37.68\n",
            "[[100  14 493 416   2]]\n",
            "[[ 86  42 293 250   0]]\n",
            "[[ 21  26 189 196   0]]\n",
            "[[204  63 647 458   1]]\n",
            "epoch:16 step:   46/60, lr:0.000009, giou_loss:   0.90, conf_loss:  17.89, prob_loss:   1.18, total_loss:  19.96\n",
            "[[ 70  45 677 648   0]]\n",
            "[[  18  122  997 1117    0]]\n",
            "[[ 21 116 191 294   0]\n",
            " [ 93  64 259 248   0]]\n",
            "[[ 28  13 183 160   0]]\n",
            "epoch:16 step:   47/60, lr:0.000009, giou_loss:   0.99, conf_loss:  17.61, prob_loss:   3.98, total_loss:  22.58\n",
            "[[ 287  233 1141 1111    0]]\n",
            "[[ 41 118 497 604   2]]\n",
            "[[427 194 852 603   2]]\n",
            "[[123  73 356 292   2]]\n",
            "epoch:16 step:   48/60, lr:0.000009, giou_loss:   0.66, conf_loss:  17.33, prob_loss:   1.68, total_loss:  19.67\n",
            "[[ 11  37 251 241   0]]\n",
            "[[111  21 544 346   1]\n",
            " [ 22  36 396 398   1]\n",
            " [163   7 602 252   1]]\n",
            "[[  1  65 470 399   0]\n",
            " [299   0 771 399   0]]\n",
            "[[  77  230  841  572    1]\n",
            " [ 363  211 1013  754    1]\n",
            " [  37  187  793  485    1]]\n",
            "epoch:16 step:   49/60, lr:0.000008, giou_loss:   2.03, conf_loss:  17.88, prob_loss:   1.28, total_loss:  21.19\n",
            "[[357  38 599 293   2]\n",
            " [154 103 380 359   0]\n",
            " [193 183 766 483   1]]\n",
            "[[ 94  75 358 347   2]]\n",
            "[[ 14  44 270 300   0]]\n",
            "[[171 105 393 324   2]\n",
            " [ 36  90 236 312   2]]\n",
            "epoch:16 step:   50/60, lr:0.000008, giou_loss:   1.43, conf_loss:  18.44, prob_loss:   3.15, total_loss:  23.02\n",
            "[[ 93  11 423 343   2]]\n",
            "[[ 64  48 534 490   0]]\n",
            "[[  7 125  89 213   2]\n",
            " [ 74 122 147 197   2]\n",
            " [ 47   8 277 104   1]\n",
            " [194 143 288 234   0]]\n",
            "[[ 57  53 420 542   1]]\n",
            "epoch:16 step:   51/60, lr:0.000008, giou_loss:   2.31, conf_loss:  19.90, prob_loss:   5.17, total_loss:  27.38\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[  57  112 1711 1009    1]\n",
            " [ 478  161 1991 1229    1]\n",
            " [   1   86 1594  665    1]]\n",
            "[[ 38  47 444 466   0]]\n",
            "[[ 70  36 383 162   1]\n",
            " [  8  55 231 270   1]\n",
            " [ 54  64 346 213   1]]\n",
            "epoch:16 step:   52/60, lr:0.000008, giou_loss:   4.59, conf_loss:  22.63, prob_loss:   9.37, total_loss:  36.58\n",
            "[[ 27  39 462 481   0]]\n",
            "[[ 27  26 463 263   1]]\n",
            "[[193  74 417 316   2]]\n",
            "[[ 99  83 458 416   1]\n",
            " [186  39 624 382   1]\n",
            " [205   8 670 226   1]]\n",
            "epoch:16 step:   53/60, lr:0.000008, giou_loss:   1.13, conf_loss:  17.18, prob_loss:   0.65, total_loss:  18.96\n",
            "[[  3  93 310 425   0]]\n",
            "[[ 86   4 590 531   0]]\n",
            "[[ 426  168 1533  923    1]\n",
            " [ 129  587 1400 1268    1]\n",
            " [ 727    1 1702  611    1]\n",
            " [ 982    1 1846  550    1]]\n",
            "[[ 26 104 147 247   2]\n",
            " [ 47   1 153 115   2]\n",
            " [119  62 249 187   2]\n",
            " [139   2 249  70   2]\n",
            " [ 98 201 220 250   2]]\n",
            "epoch:16 step:   54/60, lr:0.000008, giou_loss:   3.25, conf_loss:  21.82, prob_loss:   2.82, total_loss:  27.90\n",
            "[[ 52  15 648 682   1]]\n",
            "[[  43   47 1910 1867    2]]\n",
            "[[ 45 196 597 470   1]]\n",
            "[[215 112 977 847   2]]\n",
            "epoch:16 step:   55/60, lr:0.000008, giou_loss:   0.65, conf_loss:  17.93, prob_loss:   0.67, total_loss:  19.25\n",
            "[[344  76 640 394   0]]\n",
            "[[  8  48 288 349   2]]\n",
            "[[ 19   4 576 238   1]]\n",
            "[[ 11   7 261 262   0]]\n",
            "epoch:16 step:   56/60, lr:0.000008, giou_loss:   0.80, conf_loss:  17.80, prob_loss:   1.04, total_loss:  19.64\n",
            "[[602 238 881 519   2]\n",
            " [411  81 721 339   2]\n",
            " [364 328 697 565   2]]\n",
            "[[  4  71 366 398   2]]\n",
            "[[231  57 547 350   1]\n",
            " [ 82  49 454 224   1]\n",
            " [101  45 467 304   1]\n",
            " [ 92  51 435 255   1]]\n",
            "[[ 12   1 817 214   1]]\n",
            "epoch:16 step:   57/60, lr:0.000008, giou_loss:   3.09, conf_loss:  20.99, prob_loss:   4.25, total_loss:  28.34\n",
            "[[111 141 360 393   0]\n",
            " [328 126 608 399   0]]\n",
            "[[ 11  89 152 330   1]\n",
            " [143  78 227 339   1]\n",
            " [233  95 306 334   1]\n",
            " [309 102 404 339   1]]\n",
            "[[102   1 409 299   2]]\n",
            "[[ 69 334 553 810   0]\n",
            " [352 132 719 605   0]]\n",
            "epoch:16 step:   58/60, lr:0.000008, giou_loss:   4.35, conf_loss:  21.03, prob_loss:   3.84, total_loss:  29.22\n",
            "[[  4   6 484 210   1]]\n",
            "[[166   9 312 152   2]\n",
            " [ 17 151 323 233   1]\n",
            " [ 25   4 162 149   0]]\n",
            "[[ 630  147 1202 1147    1]]\n",
            "[[308 132 531 346   2]\n",
            " [103 124 330 335   0]\n",
            " [283 159 639 356   1]]\n",
            "epoch:16 step:   59/60, lr:0.000008, giou_loss:   2.94, conf_loss:  19.04, prob_loss:   6.07, total_loss:  28.05\n",
            "[[149  41 392 264   2]]\n",
            "[[ 37  36 615 548   2]]\n",
            "[[189 296 380 485   2]\n",
            " [107 288 267 466   2]]\n",
            "[[ 46  42 469 449   2]\n",
            " [513 139 897 566   2]\n",
            " [457 525 937 957   2]]\n",
            "epoch:16 step:    0/60, lr:0.000008, giou_loss:   2.15, conf_loss:  21.02, prob_loss:   9.92, total_loss:  33.09\n",
            "[[100  10 523 339   1]]\n",
            "[[ 193  207 1700  983    1]]\n",
            "[[ 22  54 280 302   2]\n",
            " [323  16 622 315   2]]\n",
            "[[ 85 109 423 470   2]\n",
            " [381  69 733 432   2]]\n",
            "epoch:16 step:    1/60, lr:0.000008, giou_loss:   1.31, conf_loss:  17.83, prob_loss:   2.68, total_loss:  21.82\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[174  20 364 199   2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[145  36 421 286   2]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[166  92 638 559   2]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  20.29, prob_val_loss:   3.71, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[ 38   9 184 152   2]\n",
            " [ 27 151 333 233   1]\n",
            " [188   4 325 149   0]]\n",
            "[[  30   17 1897 1837    2]]\n",
            "[[ 359    8  782  434    2]\n",
            " [ 614   92 1094  576    0]\n",
            " [  95  180  984  729    1]]\n",
            "[[ 660  330 1394 1051    2]\n",
            " [ 126  254  814  916    2]]\n",
            "epoch:17 step:    2/60, lr:0.000007, giou_loss:   1.63, conf_loss:  18.19, prob_loss:   3.36, total_loss:  23.18\n",
            "[[ 47  65 217 353   1]\n",
            " [261  88 373 404   1]\n",
            " [293  48 444 305   1]\n",
            " [165 101 276 418   1]]\n",
            "[[271 190 567 508   0]]\n",
            "[[214 159 296 247   2]\n",
            " [156 156 229 231   2]\n",
            " [ 26  42 256 138   1]\n",
            " [ 15 177 109 268   0]]\n",
            "[[ 63  63 565 266   1]]\n",
            "epoch:17 step:    3/60, lr:0.000007, giou_loss:   4.44, conf_loss:  21.88, prob_loss:   4.26, total_loss:  30.59\n",
            "[[156 178 519 667   1]]\n",
            "[[196  37 512 330   1]\n",
            " [ 47  29 419 204   1]\n",
            " [ 66  25 432 284   1]\n",
            " [ 57  31 400 235   1]]\n",
            "[[ 596  800 1230 1800    1]\n",
            " [ 289  621  814 1679    1]]\n",
            "[[ 33   2 211 180   2]\n",
            " [236  16 404 159   0]\n",
            " [ 33 233 345 357   1]]\n",
            "epoch:17 step:    4/60, lr:0.000007, giou_loss:   2.69, conf_loss:  19.01, prob_loss:   4.38, total_loss:  26.08\n",
            "[[ 39  11 287 267   2]]\n",
            "[[173   3 405 173   1]\n",
            " [153  34 338 207   1]\n",
            " [123  47 273 237   1]\n",
            " [ 69  66 155 281   1]]\n",
            "[[ 16  41 418 130   1]\n",
            " [ 23  49 419 201   1]\n",
            " [ 32  85 429 294   1]\n",
            " [155 105 506 376   1]]\n",
            "[[337  60 675 421   2]\n",
            " [ 27  20 379 383   2]]\n",
            "epoch:17 step:    5/60, lr:0.000007, giou_loss:   4.29, conf_loss:  22.91, prob_loss:   6.49, total_loss:  33.69\n",
            "[[167  29 346 201   0]]\n",
            "[[  57  215 1711 1112    1]\n",
            " [ 478  264 1991 1332    1]\n",
            " [   1  189 1594  768    1]]\n",
            "[[478 121 852 499   2]\n",
            " [ 53  92 710 306   1]\n",
            " [ 70 225 656 509   1]]\n",
            "[[ 18  27 316 315   0]]\n",
            "epoch:17 step:    6/60, lr:0.000007, giou_loss:   1.46, conf_loss:  17.48, prob_loss:   0.76, total_loss:  19.69\n",
            "[[168  15 604 252   1]]\n",
            "[[339 227 851 784   0]]\n",
            "[[356  51 906 603   0]\n",
            " [ 73  57 514 525   0]\n",
            " [  0  67 277 466   0]]\n",
            "[[100 422 383 692   0]\n",
            " [227 125 475 378   0]\n",
            " [477 183 791 450   0]\n",
            " [348   1 600 224   0]\n",
            " [ 60  19 325 253   0]]\n",
            "epoch:17 step:    7/60, lr:0.000007, giou_loss:   3.07, conf_loss:  21.74, prob_loss:   8.86, total_loss:  33.67\n",
            "[[ 328  135  954 1273    1]]\n",
            "[[ 78  79 257 249   2]]\n",
            "[[ 19  38 473 494   2]]\n",
            "[[369  96 825 465   2]]\n",
            "epoch:17 step:    8/60, lr:0.000007, giou_loss:   1.15, conf_loss:  18.12, prob_loss:   2.86, total_loss:  22.13\n",
            "[[  9  10 202 212   0]]\n",
            "[[281 112 519 390   2]\n",
            " [  3 102 259 373   2]]\n",
            "[[ 35  14 461 345   1]]\n",
            "[[103  57 699 724   1]]\n",
            "epoch:17 step:    9/60, lr:0.000007, giou_loss:   0.92, conf_loss:  17.55, prob_loss:   0.59, total_loss:  19.06\n",
            "[[ 33  10 243 272   1]]\n",
            "[[226 194 459 413   2]]\n",
            "[[142  21 804 724   2]]\n",
            "[[ 336  178 1443  933    1]\n",
            " [  39  597 1310 1278    1]\n",
            " [ 637   11 1612  621    1]\n",
            " [ 892   11 1756  560    1]]\n",
            "epoch:17 step:   10/60, lr:0.000007, giou_loss:   1.78, conf_loss:  19.60, prob_loss:   5.32, total_loss:  26.70\n",
            "[[  4 154 340 524   2]\n",
            " [358 143 687 465   2]]\n",
            "[[ 85  53 276 242   2]\n",
            " [  3  45 163 223   2]]\n",
            "[[324  41 566 296   2]\n",
            " [543 106 769 362   0]\n",
            " [157 186 730 486   1]]\n",
            "[[ 36  70 234 261   2]\n",
            " [200  47 369 220   2]]\n",
            "epoch:17 step:   11/60, lr:0.000007, giou_loss:   2.32, conf_loss:  20.09, prob_loss:   6.04, total_loss:  28.44\n",
            "[[ 38   1 345 299   2]]\n",
            "[[ 163  294 1003 1130    2]]\n",
            "[[ 26  28 300 295   2]]\n",
            "[[ 40  35 932 522   1]]\n",
            "epoch:17 step:   12/60, lr:0.000007, giou_loss:   0.64, conf_loss:  17.03, prob_loss:   1.97, total_loss:  19.63\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[ 33  10 285 269   2]]\n",
            "[[  7 321 317 637   2]\n",
            " [168 184 774 401   1]\n",
            " [118 242 768 497   1]\n",
            " [458  19 720 312   0]]\n",
            "[[135  27 463 329   1]\n",
            " [181 104 579 361   1]\n",
            " [195  21 507 216   1]]\n",
            "epoch:17 step:   13/60, lr:0.000007, giou_loss:   5.08, conf_loss:  23.70, prob_loss:  10.48, total_loss:  39.26\n",
            "[[ 16  87 256 291   0]]\n",
            "[[500  10 720 211   0]\n",
            " [537 202 755 438   0]\n",
            " [408 162 607 396   0]\n",
            " [  3 283 185 498   0]\n",
            " [115 355 292 552   0]\n",
            " [216 224 457 448   0]\n",
            " [417 335 599 528   0]\n",
            " [135 410 347 583   0]]\n",
            "[[ 48 157 651 768   2]]\n",
            "[[ 12  40 342 372   2]]\n",
            "epoch:17 step:   14/60, lr:0.000007, giou_loss:   4.76, conf_loss:  23.53, prob_loss:   4.17, total_loss:  32.46\n",
            "[[ 45   6 130 100   1]\n",
            " [ 62  35 195 115   1]\n",
            " [  1  32  47 104   1]\n",
            " [ 17  12  77  96   1]]\n",
            "[[ 43   1 362 113   1]]\n",
            "[[  2   4 407 346   1]]\n",
            "[[ 191  863  994 1684    0]\n",
            " [  82  134  488  750    0]\n",
            " [ 185  137  705  690    0]]\n",
            "epoch:17 step:   15/60, lr:0.000007, giou_loss:   2.63, conf_loss:  19.77, prob_loss:   5.14, total_loss:  27.53\n",
            "[[  85   27 1191 1054    0]]\n",
            "[[ 567  161 1184  781    2]\n",
            " [  21  249  609  853    2]]\n",
            "[[  7 107 183 296   0]]\n",
            "[[ 18  46 267 278   2]]\n",
            "epoch:17 step:   16/60, lr:0.000007, giou_loss:   0.75, conf_loss:  16.71, prob_loss:   1.32, total_loss:  18.78\n",
            "[[ 55   2 406 375   0]\n",
            " [372  26 779 457   0]]\n",
            "[[ 66  75 371 381   0]\n",
            " [393 240 681 505   0]\n",
            " [309 104 592 359   0]]\n",
            "[[ 31  96 583 370   1]]\n",
            "[[515 257 748 524   0]\n",
            " [339 345 578 569   0]\n",
            " [ 10 239 214 471   0]\n",
            " [193 191 423 406   0]\n",
            " [442 176 635 327   0]\n",
            " [301  22 533 216   0]\n",
            " [535  55 700 220   0]]\n",
            "epoch:17 step:   17/60, lr:0.000006, giou_loss:   3.82, conf_loss:  23.48, prob_loss:   6.09, total_loss:  33.39\n",
            "[[ 146   13 1459 1080    1]]\n",
            "[[109  39 195 127   2]\n",
            " [ 85  26 163 117   2]]\n",
            "[[ 122  173 1479 1493    0]]\n",
            "[[129 164 532 572   2]]\n",
            "epoch:17 step:   18/60, lr:0.000006, giou_loss:   1.17, conf_loss:  18.06, prob_loss:   2.20, total_loss:  21.43\n",
            "[[ 67   8 222 155   0]]\n",
            "[[  1  14 324 348   0]]\n",
            "[[ 29 137 238 358   2]\n",
            " [231  99 436 351   2]\n",
            " [107   1 326 171   2]]\n",
            "[[  7   2 538 507   2]]\n",
            "epoch:17 step:   19/60, lr:0.000006, giou_loss:   0.90, conf_loss:  17.46, prob_loss:   1.45, total_loss:  19.82\n",
            "[[ 17  57 421 201   1]]\n",
            "[[245  32 710 488   2]]\n",
            "[[601 355 950 723   2]\n",
            " [272 392 701 743   2]\n",
            " [125 332 469 675   2]\n",
            " [285 116 725 474   2]]\n",
            "[[204  63 647 458   1]]\n",
            "epoch:17 step:   20/60, lr:0.000006, giou_loss:   1.95, conf_loss:  20.02, prob_loss:   2.62, total_loss:  24.59\n",
            "[[   7  358 2739 2841    1]]\n",
            "[[ 12 132 431 326   1]\n",
            " [103  69 425 206   1]\n",
            " [109  14 384 149   1]]\n",
            "[[ 57 225 321 538   2]\n",
            " [ 48  73 368 328   0]\n",
            " [123   9 672 311   1]]\n",
            "[[208  98 464 328   2]\n",
            " [380   0 595 186   2]\n",
            " [ 19  46 218 296   2]\n",
            " [202  24 414 208   2]\n",
            " [ 53 271 317 397   2]]\n",
            "epoch:17 step:   21/60, lr:0.000006, giou_loss:   3.31, conf_loss:  22.99, prob_loss:   9.35, total_loss:  35.66\n",
            "[[ 28  56 224 239   0]]\n",
            "[[450 212 869 610   2]\n",
            " [194 138 449 379   2]]\n",
            "[[397 187 516 302   0]\n",
            " [245 207 376 332   0]\n",
            " [214  90 320 185   0]\n",
            " [118  27 253 131   0]\n",
            " [ 43  72 164 188   0]\n",
            " [146 130 260 237   0]]\n",
            "[[331 277 643 565   2]\n",
            " [ 86 429 911 625   1]\n",
            " [ 58 548 901 756   1]]\n",
            "epoch:17 step:   22/60, lr:0.000006, giou_loss:   6.12, conf_loss:  25.49, prob_loss:   8.81, total_loss:  40.42\n",
            "[[129  40 271 185   0]\n",
            " [219 163 341 284   0]\n",
            " [182 279 334 403   0]\n",
            " [  1 149 167 306   0]\n",
            " [309  69 408 159   0]\n",
            " [377 216 451 291   0]\n",
            " [402  45 463 106   0]\n",
            " [395 120 460 187   0]]\n",
            "[[126 149 745 763   0]]\n",
            "[[149 138 537 313   1]]\n",
            "[[ 31  27 633 480   1]\n",
            " [ 55   3 626 300   1]\n",
            " [ 92   7 603 216   1]\n",
            " [  1 147 200 480   1]]\n",
            "epoch:17 step:   23/60, lr:0.000006, giou_loss:   6.16, conf_loss:  26.02, prob_loss:   8.34, total_loss:  40.51\n",
            "[[253  87 426 259   2]\n",
            " [ 25  93 310 376   1]\n",
            " [103   5 267 166   0]]\n",
            "[[144  46 340 291   1]]\n",
            "[[141   5 263 128   2]\n",
            " [ 40   3 176 147   2]]\n",
            "[[  34    6  992  746    2]\n",
            " [ 362  648 1160 1071    2]]\n",
            "epoch:17 step:   24/60, lr:0.000006, giou_loss:   2.01, conf_loss:  18.72, prob_loss:   4.10, total_loss:  24.83\n",
            "[[359 231 638 512   2]\n",
            " [168  74 478 332   2]\n",
            " [121 321 454 558   2]]\n",
            "[[ 16  27 193 194   0]]\n",
            "[[162 153 327 348   2]\n",
            " [320 148 513 371   0]\n",
            " [ 22 366 567 619   1]]\n",
            "[[  73   84 1580  860    1]]\n",
            "epoch:17 step:   25/60, lr:0.000006, giou_loss:   3.50, conf_loss:  21.71, prob_loss:   5.38, total_loss:  30.59\n",
            "[[ 321   37 1200  923    2]]\n",
            "[[ 44   5 251 213   0]]\n",
            "[[ 16  75 256 319   2]\n",
            " [265  70 519 337   2]]\n",
            "[[  2  19 583 424   1]\n",
            " [ 15 150 590 633   1]]\n",
            "epoch:17 step:   26/60, lr:0.000006, giou_loss:   0.88, conf_loss:  17.58, prob_loss:   0.84, total_loss:  19.30\n",
            "[[ 12 114 240 347   2]]\n",
            "[[ 473  130  896  537    2]\n",
            " [ 940  227 1324  654    2]\n",
            " [ 884  613 1364 1045    2]]\n",
            "[[182 156 946 498   1]\n",
            " [ 10 137 660 680   1]\n",
            " [230 113 986 411   1]]\n",
            "[[100   1 411 272   1]\n",
            " [ 74  61 335 349   1]]\n",
            "epoch:17 step:   27/60, lr:0.000006, giou_loss:   3.11, conf_loss:  21.44, prob_loss:   5.46, total_loss:  30.01\n",
            "[[145  14 242 119   2]]\n",
            "[[ 87  47 520 372   1]\n",
            " [235  62 609 424   1]\n",
            " [ 29  33 468 278   1]]\n",
            "[[426 100 563 259   2]\n",
            " [436  25 572 164   2]\n",
            " [ 97  95 229 240   2]\n",
            " [ 55  30 204 160   2]\n",
            " [193  52 336 196   2]\n",
            " [260 104 411 246   2]\n",
            " [342   9 475 135   2]]\n",
            "[[ 62  21 211 236   1]]\n",
            "epoch:17 step:   28/60, lr:0.000006, giou_loss:   5.38, conf_loss:  25.16, prob_loss:   7.23, total_loss:  37.77\n",
            "[[ 33  19 661 193   1]\n",
            " [ 19 107 606 417   1]\n",
            " [  6  15 447 309   1]]\n",
            "[[  14    2 1194  468    1]]\n",
            "[[  4 181 174 359   0]\n",
            " [ 76 129 242 313   0]]\n",
            "[[ 37  30 178 187   0]\n",
            " [177  25 279 134   0]\n",
            " [128  93 239 202   0]]\n",
            "epoch:17 step:   29/60, lr:0.000006, giou_loss:   2.45, conf_loss:  18.88, prob_loss:   2.55, total_loss:  23.87\n",
            "[[294 127 543 379   0]\n",
            " [ 46 112 326 385   0]]\n",
            "[[199 162 423 404   2]]\n",
            "[[454 278 569 377   2]\n",
            " [ 79 256 159 331   2]\n",
            " [ 87 199 185 276   2]\n",
            " [298 166 555 266   1]\n",
            " [283 208 517 303   1]\n",
            " [224 165 381 310   1]\n",
            " [217 215 353 344   1]\n",
            " [267  90 376 193   0]\n",
            " [152 123 266 228   0]]\n",
            "[[  5  21 297 137   1]]\n",
            "epoch:17 step:   30/60, lr:0.000006, giou_loss:   8.09, conf_loss:  25.92, prob_loss:  10.27, total_loss:  44.28\n",
            "[[170 186 858 706   1]\n",
            " [  3 186 432 706   1]]\n",
            "[[ 79 103 592 615   2]]\n",
            "[[125   8 649 366   1]]\n",
            "[[ 23  90 266 313   2]]\n",
            "epoch:17 step:   31/60, lr:0.000006, giou_loss:   1.08, conf_loss:  17.37, prob_loss:   1.06, total_loss:  19.51\n",
            "[[  41  164 1020 1159    0]]\n",
            "[[159 124 348 318   0]\n",
            " [231  37 396 222   0]\n",
            " [ 91  48 260 230   0]]\n",
            "[[ 92  48 405 174   1]\n",
            " [ 30  67 253 282   1]\n",
            " [ 76  76 368 225   1]]\n",
            "[[286   3 649 350   0]]\n",
            "epoch:17 step:   32/60, lr:0.000006, giou_loss:   1.68, conf_loss:  18.32, prob_loss:   3.93, total_loss:  23.93\n",
            "[[226  35 551 364   0]\n",
            " [ 10   2 281 293   0]]\n",
            "[[100  21 407 353   0]]\n",
            "[[ 63  44 319 300   0]]\n",
            "[[  6  18 206 206   0]]\n",
            "epoch:17 step:   33/60, lr:0.000005, giou_loss:   0.67, conf_loss:  17.67, prob_loss:   4.46, total_loss:  22.80\n",
            "[[ 88   4 519 445   2]]\n",
            "[[ 20   6 270 261   0]]\n",
            "[[162 113 384 332   2]\n",
            " [ 27  98 227 320   2]]\n",
            "[[126  16 422 288   1]\n",
            " [615  46 883 389   1]\n",
            " [511  64 800 408   1]\n",
            " [511 144 771 538   1]\n",
            " [387 131 557 557   1]\n",
            " [200 130 491 465   1]\n",
            " [164  45 537 326   1]]\n",
            "epoch:17 step:   34/60, lr:0.000005, giou_loss:   4.43, conf_loss:  23.87, prob_loss:   5.61, total_loss:  33.91\n",
            "[[ 45  28 480 470   0]]\n",
            "[[  20  645  827 1584    1]\n",
            " [ 182  594 1147 1272    1]\n",
            " [ 294  469 1192  959    1]\n",
            " [ 248  282 1029  861    1]]\n",
            "[[   2  145 2458 4035    1]]\n",
            "[[ 64  26 400 389   2]]\n",
            "epoch:17 step:   35/60, lr:0.000005, giou_loss:   1.99, conf_loss:  18.71, prob_loss:   2.44, total_loss:  23.14\n",
            "[[301 155 659 513   2]\n",
            " [126 133 723 590   1]]\n",
            "[[183  92 686 338   1]]\n",
            "[[ 35 197 599 777   0]\n",
            " [406 160 918 649   0]]\n",
            "[[220  42 521 362   2]]\n",
            "epoch:17 step:   36/60, lr:0.000005, giou_loss:   1.04, conf_loss:  17.85, prob_loss:   1.26, total_loss:  20.14\n",
            "[[  2  59 295 175   1]]\n",
            "[[ 25  71 451 285   1]]\n",
            "[[ 84 132 266 343   0]]\n",
            "[[152  84 420 361   0]]\n",
            "epoch:17 step:   37/60, lr:0.000005, giou_loss:   1.08, conf_loss:  17.35, prob_loss:   1.46, total_loss:  19.89\n",
            "[[332 154 508 324   0]\n",
            " [173 161 340 313   0]\n",
            " [411 149 565 289   0]\n",
            " [  7 104 141 252   0]]\n",
            "[[222   8 486 280   2]]\n",
            "[[123  58 546 387   1]]\n",
            "[[218 115 546 439   0]\n",
            " [265 400 583 665   0]\n",
            " [  0 422 197 668   0]\n",
            " [ 73 131 332 419   0]\n",
            " [492  15 799 366   0]]\n",
            "epoch:17 step:   38/60, lr:0.000005, giou_loss:   4.00, conf_loss:  21.68, prob_loss:   4.21, total_loss:  29.89\n",
            "[[ 18 101 451 530   0]]\n",
            "[[ 69  83 238 191   1]]\n",
            "[[152 226 759 829   0]]\n",
            "[[  13  157 1055  648    1]\n",
            " [ 228  160 1171  687    1]]\n",
            "epoch:17 step:   39/60, lr:0.000005, giou_loss:   1.06, conf_loss:  18.31, prob_loss:   1.48, total_loss:  20.84\n",
            "[[294 104 517 318   2]\n",
            " [ 89  96 316 307   0]\n",
            " [269 131 625 328   1]]\n",
            "[[361 169 585 400   1]\n",
            " [ 92 195 465 381   1]\n",
            " [125 120 500 268   1]]\n",
            "[[ 29  30 264 274   0]]\n",
            "[[  8  61 347 263   1]]\n",
            "epoch:17 step:   40/60, lr:0.000005, giou_loss:   3.15, conf_loss:  19.35, prob_loss:   5.36, total_loss:  27.86\n",
            "[[138   3 642 530   0]]\n",
            "[[ 43 128 714 385   1]]\n",
            "[[ 11   9 165 154   2]]\n",
            "[[468 252 632 402   2]\n",
            " [415  34 606 230   0]\n",
            " [299  29 425 416   1]\n",
            " [119 147 383 475   1]\n",
            " [218  28 372 405   1]]\n",
            "epoch:17 step:   41/60, lr:0.000005, giou_loss:   3.65, conf_loss:  19.97, prob_loss:   4.57, total_loss:  28.19\n",
            "[[  28  116  292  368    2]\n",
            " [ 734  137 1005  404    2]\n",
            " [ 544   82  797  309    2]\n",
            " [ 284  116  518  324    2]]\n",
            "[[ 248  368 1649 1759    2]]\n",
            "[[ 20  23 207 225   2]]\n",
            "[[  8  33 134 173   0]]\n",
            "epoch:17 step:   42/60, lr:0.000005, giou_loss:   2.66, conf_loss:  20.64, prob_loss:   6.83, total_loss:  30.13\n",
            "[[  5 142 472 417   1]\n",
            " [ 29  81 462 311   1]]\n",
            "[[318 146 680 511   0]]\n",
            "[[  4  12 286 257   0]]\n",
            "[[ 84  19 267 209   2]]\n",
            "epoch:17 step:   43/60, lr:0.000005, giou_loss:   0.77, conf_loss:  16.91, prob_loss:   0.47, total_loss:  18.14\n",
            "[[ 36  48 323 334   0]]\n",
            "[[ 21   8 318 295   0]]\n",
            "[[100  20 588 327   1]]\n",
            "[[ 73 384 975 862   1]]\n",
            "epoch:17 step:   44/60, lr:0.000005, giou_loss:   0.71, conf_loss:  16.58, prob_loss:   0.34, total_loss:  17.62\n",
            "[[149  77 360 273   2]\n",
            " [102 316 311 534   2]\n",
            " [279 396 491 595   2]\n",
            " [214 481 416 651   2]]\n",
            "[[ 36 119 205 274   2]\n",
            " [155 111 315 274   2]\n",
            " [217  64 359 205   2]]\n",
            "[[ 661  322 1039  733    2]\n",
            " [  13    1  735  429    1]\n",
            " [  35  133  705  751    1]]\n",
            "[[ 257  388 1228 1172    1]\n",
            " [ 291  447  915 1046    0]]\n",
            "epoch:17 step:   45/60, lr:0.000005, giou_loss:   3.74, conf_loss:  21.81, prob_loss:   8.51, total_loss:  34.06\n",
            "[[ 394  223 1041  587    1]]\n",
            "[[ 60  17 447 210   1]\n",
            " [531  89 680 251   1]\n",
            " [ 51 136 593 325   1]]\n",
            "[[158  44 578 420   2]\n",
            " [ 31 297 978 599   1]\n",
            " [534  85 903 397   0]]\n",
            "[[ 29  27 361 356   2]]\n",
            "epoch:17 step:   46/60, lr:0.000005, giou_loss:   2.24, conf_loss:  19.07, prob_loss:   2.82, total_loss:  24.12\n",
            "[[595  84 989 465   2]\n",
            " [112  70 513 456   0]\n",
            " [216 510 897 872   1]]\n",
            "[[ 264  210 1837  833    1]]\n",
            "[[197  94 398 299   2]]\n",
            "[[107 197 530 619   0]\n",
            " [375 139 699 465   0]]\n",
            "epoch:17 step:   47/60, lr:0.000005, giou_loss:   1.22, conf_loss:  17.56, prob_loss:   0.99, total_loss:  19.77\n",
            "[[ 86  84 298 289   2]]\n",
            "[[  7  12 325 316   1]]\n",
            "[[392  85 638 310   0]\n",
            " [180  82 367 332   0]\n",
            " [295  57 516 272   0]]\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "epoch:17 step:   48/60, lr:0.000005, giou_loss:   2.96, conf_loss:  22.01, prob_loss:   2.74, total_loss:  27.71\n",
            "[[ 80 373 625 890   2]]\n",
            "[[134  27 308 202   0]\n",
            " [ 11  14 161 182   0]]\n",
            "[[ 12   4 506 251   1]\n",
            " [ 35  12 261 238   1]]\n",
            "[[ 233  220 1038  433    1]]\n",
            "epoch:17 step:   49/60, lr:0.000005, giou_loss:   1.21, conf_loss:  17.95, prob_loss:   4.29, total_loss:  23.44\n",
            "[[ 12  10 241 234   2]]\n",
            "[[ 22  35 208 217   0]]\n",
            "[[  4  83 473 417   0]\n",
            " [302  18 774 417   0]]\n",
            "[[ 10   5 416 424   0]]\n",
            "epoch:17 step:   50/60, lr:0.000004, giou_loss:   0.84, conf_loss:  17.28, prob_loss:   1.41, total_loss:  19.54\n",
            "[[ 589  474 1544 1110    1]\n",
            " [ 763  678 1544 1186    1]\n",
            " [  45  189 1225 1062    1]]\n",
            "[[ 69  43 430 334   2]]\n",
            "[[  32    5 1846  928    1]]\n",
            "[[ 81  28 479 443   0]]\n",
            "epoch:17 step:   51/60, lr:0.000004, giou_loss:   1.38, conf_loss:  17.68, prob_loss:   1.79, total_loss:  20.85\n",
            "[[113  21 506 423   2]]\n",
            "[[  1  95 111 205   0]\n",
            " [ 78  68 179 163   0]\n",
            " [183  81 287 192   0]]\n",
            "[[224 355 603 704   0]]\n",
            "[[113 258 583 700   0]]\n",
            "epoch:17 step:   52/60, lr:0.000004, giou_loss:   1.74, conf_loss:  18.71, prob_loss:   3.80, total_loss:  24.25\n",
            "[[100 107 584 397   1]]\n",
            "[[141  36 467 311   0]]\n",
            "[[386  63 811 472   2]]\n",
            "[[125  58 302 221   0]]\n",
            "epoch:17 step:   53/60, lr:0.000004, giou_loss:   1.05, conf_loss:  16.20, prob_loss:   0.47, total_loss:  17.72\n",
            "[[ 63   8 522 258   1]]\n",
            "[[134  74 813 822   0]]\n",
            "[[ 541   45 1274  820    2]\n",
            " [   9    8  702  740    2]]\n",
            "[[  1   2 281 303   2]]\n",
            "epoch:17 step:   54/60, lr:0.000004, giou_loss:   0.98, conf_loss:  17.73, prob_loss:   1.38, total_loss:  20.10\n",
            "[[1543  110 3008 1684    2]]\n",
            "[[332 291 700 680   2]]\n",
            "[[ 20  84 500 288   1]]\n",
            "[[167   6 867 713   0]]\n",
            "epoch:17 step:   55/60, lr:0.000004, giou_loss:   1.05, conf_loss:  17.50, prob_loss:   1.78, total_loss:  20.33\n",
            "[[214  66 411 836   1]]\n",
            "[[   1  362  754 1044    0]]\n",
            "[[ 28 217 512 693   0]\n",
            " [311  15 678 488   0]]\n",
            "[[ 386   27 1148  762    2]]\n",
            "epoch:17 step:   56/60, lr:0.000004, giou_loss:   1.12, conf_loss:  17.29, prob_loss:   0.93, total_loss:  19.34\n",
            "[[124  62 393 326   0]]\n",
            "[[ 283   18 1137  896    0]]\n",
            "[[468 146 609 387   1]\n",
            " [393 135 477 396   1]\n",
            " [314 152 387 391   1]\n",
            " [216 159 311 396   1]]\n",
            "[[ 630  147 1202 1147    1]]\n",
            "epoch:17 step:   57/60, lr:0.000004, giou_loss:   3.91, conf_loss:  20.34, prob_loss:   5.14, total_loss:  29.40\n",
            "[[314  45 577 333   0]\n",
            " [ 74  12 333 264   0]]\n",
            "[[117  82 302 174   1]\n",
            " [305  81 489 175   1]]\n",
            "[[421  84 679 332   2]\n",
            " [ 79  46 378 345   2]]\n",
            "[[ 28  17 132 124   2]]\n",
            "epoch:17 step:   58/60, lr:0.000004, giou_loss:   2.46, conf_loss:  19.17, prob_loss:   2.45, total_loss:  24.07\n",
            "[[ 37  52 205 222   0]]\n",
            "[[  8 226 428 668   0]]\n",
            "[[233   4 811 516   2]]\n",
            "[[ 14  24 663 728   0]]\n",
            "epoch:17 step:   59/60, lr:0.000004, giou_loss:   0.71, conf_loss:  16.30, prob_loss:   0.68, total_loss:  17.69\n",
            "[[  4   9 151 153   0]]\n",
            "[[  8 260 565 494   1]]\n",
            "[[ 47  81 293 342   2]]\n",
            "[[105 103 226 246   2]\n",
            " [ 99   0 205 114   2]\n",
            " [  3  61 133 186   2]\n",
            " [  3   1 113  69   2]\n",
            " [ 32 200 154 249   2]]\n",
            "epoch:17 step:    0/60, lr:0.000004, giou_loss:   2.21, conf_loss:  19.41, prob_loss:   5.44, total_loss:  27.06\n",
            "[[  1  44 363 371   2]]\n",
            "[[ 94  42 550 528   2]]\n",
            "[[317  75 676 408   1]\n",
            " [151  31 589 374   1]\n",
            " [105   0 570 218   1]]\n",
            "[[223 275 390 452   0]\n",
            " [ 79 267 256 424   0]\n",
            " [137 176 316 345   0]]\n",
            "epoch:17 step:    1/60, lr:0.000004, giou_loss:   1.97, conf_loss:  18.77, prob_loss:   2.67, total_loss:  23.41\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[155 105 453 436   0]]\n",
            "[[ 85 138 553 352   1]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  20.07, prob_val_loss:   4.00, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[243 171 466 385   2]\n",
            " [ 38 163 265 374   0]\n",
            " [218 198 574 395   1]]\n",
            "[[ 655  246 1389  967    2]\n",
            " [ 121  170  809  832    2]]\n",
            "[[115  19 443 321   1]\n",
            " [161  96 559 353   1]\n",
            " [175  13 487 208   1]]\n",
            "[[126   8 422 280   1]\n",
            " [615  38 883 381   1]\n",
            " [511  56 800 400   1]\n",
            " [511 136 771 530   1]\n",
            " [387 123 557 549   1]\n",
            " [200 122 491 457   1]\n",
            " [164  37 537 318   1]]\n",
            "epoch:18 step:    2/60, lr:0.000004, giou_loss:   5.74, conf_loss:  24.54, prob_loss:  10.61, total_loss:  40.89\n",
            "[[199 162 366 339   0]\n",
            " [ 55 154 232 311   0]\n",
            " [113  63 292 232   0]]\n",
            "[[  9 245 242 512   0]\n",
            " [179 333 418 557   0]\n",
            " [543 227 747 459   0]\n",
            " [334 179 564 394   0]\n",
            " [122 164 315 315   0]\n",
            " [224  10 456 204   0]\n",
            " [ 57  43 222 208   0]]\n",
            "[[214 159 296 247   2]\n",
            " [156 156 229 231   2]\n",
            " [ 26  42 256 138   1]\n",
            " [ 15 177 109 268   0]]\n",
            "[[404  96 541 255   2]\n",
            " [414  21 550 160   2]\n",
            " [ 75  91 207 236   2]\n",
            " [ 33  26 182 156   2]\n",
            " [171  48 314 192   2]\n",
            " [238 100 389 242   2]\n",
            " [320   5 453 131   2]]\n",
            "epoch:18 step:    3/60, lr:0.000004, giou_loss:   9.27, conf_loss:  30.51, prob_loss:  12.11, total_loss:  51.89\n",
            "[[135  29 594 279   1]]\n",
            "[[ 926  421 1205  702    2]\n",
            " [ 735  264 1045  522    2]\n",
            " [ 688  511 1021  748    2]]\n",
            "[[415 261 720 567   0]\n",
            " [105 426 393 691   0]\n",
            " [194 290 477 545   0]]\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "epoch:18 step:    4/60, lr:0.000004, giou_loss:   5.74, conf_loss:  25.41, prob_loss:   9.26, total_loss:  40.41\n",
            "[[  6  22 199 224   0]]\n",
            "[[ 13  82 345 411   2]]\n",
            "[[ 374  170 1481  925    1]\n",
            " [ 507  589 1778 1270    1]\n",
            " [ 205    3 1180  613    1]\n",
            " [  61    3  925  552    1]]\n",
            "[[509 125 811 439   0]\n",
            " [112 211 391 464   0]\n",
            " [421 272 698 514   0]\n",
            " [ 11 185 251 453   0]]\n",
            "epoch:18 step:    5/60, lr:0.000004, giou_loss:   2.61, conf_loss:  20.32, prob_loss:   2.34, total_loss:  25.28\n",
            "[[313 153 478 348   2]\n",
            " [127 148 320 371   0]\n",
            " [ 73 366 618 619   1]]\n",
            "[[ 32  36 924 523   1]]\n",
            "[[123 115 486 604   1]]\n",
            "[[ 60  25 662 478   1]\n",
            " [ 67   1 638 298   1]\n",
            " [ 90   5 601 214   1]\n",
            " [493 145 692 478   1]]\n",
            "epoch:18 step:    6/60, lr:0.000004, giou_loss:   3.29, conf_loss:  20.39, prob_loss:   4.30, total_loss:  27.99\n",
            "[[ 55 125 381 400   0]]\n",
            "[[200  98 456 328   2]\n",
            " [372   0 587 186   2]\n",
            " [ 11  46 210 296   2]\n",
            " [194  24 406 208   2]\n",
            " [ 45 271 309 397   2]]\n",
            "[[ 84  74 253 182   1]]\n",
            "[[148 109 651 355   1]]\n",
            "epoch:18 step:    7/60, lr:0.000004, giou_loss:   1.93, conf_loss:  19.72, prob_loss:   2.41, total_loss:  24.06\n",
            "[[   8   58  741  833    2]\n",
            " [ 580   21 1273  753    2]]\n",
            "[[ 29  88 269 292   0]]\n",
            "[[ 168    1 1126  741    2]\n",
            " [   0  643  798 1066    2]]\n",
            "[[ 18  12 341 346   0]]\n",
            "epoch:18 step:    8/60, lr:0.000004, giou_loss:   1.30, conf_loss:  18.79, prob_loss:   2.56, total_loss:  22.65\n",
            "[[286 132 598 420   2]\n",
            " [ 41 284 866 480   1]\n",
            " [ 13 403 856 611   1]]\n",
            "[[ 37 116 470 545   0]]\n",
            "[[ 97   5 759 708   2]]\n",
            "[[ 89  48 268 220   0]]\n",
            "epoch:18 step:    9/60, lr:0.000004, giou_loss:   1.57, conf_loss:  17.44, prob_loss:   1.46, total_loss:  20.47\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[368  73 626 321   2]\n",
            " [ 26  35 325 334   2]]\n",
            "[[  4 143 216 348   2]]\n",
            "[[259  99 908 803   0]]\n",
            "epoch:18 step:   10/60, lr:0.000004, giou_loss:   0.89, conf_loss:  17.10, prob_loss:   0.72, total_loss:  18.71\n",
            "[[103 117 207 224   2]]\n",
            "[[233 137 442 358   2]\n",
            " [ 35  99 240 351   2]\n",
            " [145   1 364 171   2]]\n",
            "[[448 109 589 350   1]\n",
            " [373  98 457 359   1]\n",
            " [294 115 367 354   1]\n",
            " [196 122 291 359   1]]\n",
            "[[247 436 530 706   0]\n",
            " [374 139 622 392   0]\n",
            " [624 197 938 464   0]\n",
            " [495  15 747 238   0]\n",
            " [207  33 472 267   0]]\n",
            "epoch:18 step:   11/60, lr:0.000003, giou_loss:   6.74, conf_loss:  24.71, prob_loss:   9.25, total_loss:  40.70\n",
            "[[ 25   5 122 110   2]]\n",
            "[[  26  541  833 1480    1]\n",
            " [ 188  490 1153 1168    1]\n",
            " [ 300  365 1198  855    1]\n",
            " [ 254  178 1035  757    1]]\n",
            "[[ 30  23 346 316   1]\n",
            " [123  15 495 190   1]\n",
            " [110  11 476 270   1]\n",
            " [142  17 485 221   1]]\n",
            "[[  1  60 294 176   1]]\n",
            "epoch:18 step:   12/60, lr:0.000003, giou_loss:   1.94, conf_loss:  19.37, prob_loss:   1.81, total_loss:  23.11\n",
            "[[  8 116 434 330   1]]\n",
            "[[221  83 463 338   2]\n",
            " [440 148 666 404   0]\n",
            " [ 54 228 627 528   1]]\n",
            "[[ 65 260 967 738   1]]\n",
            "[[ 22   2 176 147   2]]\n",
            "epoch:18 step:   13/60, lr:0.000003, giou_loss:   1.70, conf_loss:  18.12, prob_loss:   1.28, total_loss:  21.10\n",
            "[[  1  26 299 314   0]]\n",
            "[[  6  15 180 190   0]\n",
            " [153   2 303 170   0]]\n",
            "[[232  27 456 269   2]]\n",
            "[[ 884  466 2349 2040    2]]\n",
            "epoch:18 step:   14/60, lr:0.000003, giou_loss:   0.60, conf_loss:  16.55, prob_loss:   1.07, total_loss:  18.22\n",
            "[[ 205  124 1176  908    1]\n",
            " [ 518  183 1142  782    0]]\n",
            "[[ 30  67 207 234   0]]\n",
            "[[ 60  44 554 291   1]\n",
            " [ 83  52 309 278   1]]\n",
            "[[356  55 906 607   0]\n",
            " [ 73  61 514 529   0]\n",
            " [  0  71 277 470   0]]\n",
            "epoch:18 step:   15/60, lr:0.000003, giou_loss:   1.90, conf_loss:  18.03, prob_loss:   5.75, total_loss:  25.67\n",
            "[[ 21  52 270 284   2]]\n",
            "[[ 50  61 228 239   2]\n",
            " [253  75 421 218   0]\n",
            " [ 50 292 362 416   1]]\n",
            "[[ 56  72 449 474   2]]\n",
            "[[ 49  20 198 235   1]]\n",
            "epoch:18 step:   16/60, lr:0.000003, giou_loss:   1.34, conf_loss:  17.45, prob_loss:   3.12, total_loss:  21.91\n",
            "[[ 43  20 714 277   1]]\n",
            "[[510  15 730 216   0]\n",
            " [547 207 765 443   0]\n",
            " [418 167 617 401   0]\n",
            " [ 13 288 195 503   0]\n",
            " [125 360 302 557   0]\n",
            " [226 229 467 453   0]\n",
            " [427 340 609 533   0]\n",
            " [145 415 357 588   0]]\n",
            "[[ 42 270 526 746   0]\n",
            " [325  68 692 541   0]]\n",
            "[[  23  407  978 1043    1]\n",
            " [  23  611  804 1119    1]\n",
            " [ 342  122 1522  995    1]]\n",
            "epoch:18 step:   17/60, lr:0.000003, giou_loss:   5.71, conf_loss:  23.22, prob_loss:   4.60, total_loss:  33.53\n",
            "[[177  52 374 822   1]]\n",
            "[[ 50  98 248 289   2]\n",
            " [214  75 383 248   2]]\n",
            "[[ 92   3 403 274   1]\n",
            " [ 66  63 327 351   1]]\n",
            "[[  6  29 400 410   2]\n",
            " [482  15 883 401   0]\n",
            " [ 98 455 779 817   1]]\n",
            "epoch:18 step:   18/60, lr:0.000003, giou_loss:   1.98, conf_loss:  18.92, prob_loss:   2.53, total_loss:  23.43\n",
            "[[  62    4 1375 1071    1]]\n",
            "[[  3  58 172 213   2]\n",
            " [122  50 282 213   2]\n",
            " [184   3 326 144   2]]\n",
            "[[278  29 665 222   1]\n",
            " [ 45 101 194 263   1]\n",
            " [132 148 674 337   1]]\n",
            "[[ 16  56 212 239   0]]\n",
            "epoch:18 step:   19/60, lr:0.000003, giou_loss:   1.98, conf_loss:  20.15, prob_loss:   4.43, total_loss:  26.56\n",
            "[[ 270  222 1110 1058    2]]\n",
            "[[356 105 526 393   1]\n",
            " [200 128 312 444   1]\n",
            " [129  88 280 345   1]\n",
            " [297 141 408 458   1]]\n",
            "[[139  42 382 265   2]]\n",
            "[[ 81   7 321 251   2]\n",
            " [330   2 584 269   2]]\n",
            "epoch:18 step:   20/60, lr:0.000003, giou_loss:   3.95, conf_loss:  20.81, prob_loss:   3.74, total_loss:  28.49\n",
            "[[310  78 669 411   1]\n",
            " [144  34 582 377   1]\n",
            " [ 98   3 563 221   1]]\n",
            "[[ 87 265 694 868   0]]\n",
            "[[219  67 389 245   0]\n",
            " [291  15 457 199   0]]\n",
            "[[330  10 626 328   0]]\n",
            "epoch:18 step:   21/60, lr:0.000003, giou_loss:   1.61, conf_loss:  18.55, prob_loss:   2.60, total_loss:  22.77\n",
            "[[140  36 362 255   2]\n",
            " [  5  21 205 243   2]]\n",
            "[[  3  39 407 183   1]]\n",
            "[[  87   62 1954 1882    2]]\n",
            "[[ 642  270 1214 1270    1]]\n",
            "epoch:18 step:   22/60, lr:0.000003, giou_loss:   1.21, conf_loss:  18.00, prob_loss:   1.79, total_loss:  21.01\n",
            "[[319  51 582 339   0]\n",
            " [ 79  18 338 270   0]]\n",
            "[[  7  26 320 152   1]\n",
            " [159  45 382 260   1]\n",
            " [ 44  54 336 203   1]]\n",
            "[[  2  17 203 222   2]]\n",
            "[[ 38   1 345 299   2]]\n",
            "epoch:18 step:   23/60, lr:0.000003, giou_loss:   1.29, conf_loss:  17.66, prob_loss:   0.88, total_loss:  19.83\n",
            "[[ 32   2 411 351   0]]\n",
            "[[196  56 306 166   0]\n",
            " [128  29 229 124   0]\n",
            " [ 20  42 124 153   0]]\n",
            "[[  1 104 122 247   2]\n",
            " [ 22   1 128 115   2]\n",
            " [ 94  62 224 187   2]\n",
            " [114   2 224  70   2]\n",
            " [ 73 201 195 250   2]]\n",
            "[[ 71  18 258 220   2]]\n",
            "epoch:18 step:   24/60, lr:0.000003, giou_loss:   2.80, conf_loss:  21.47, prob_loss:   3.69, total_loss:  27.95\n",
            "[[ 711  300 1060  668    2]\n",
            " [ 382  337  811  688    2]\n",
            " [ 235  277  579  620    2]\n",
            " [ 395   61  835  419    2]]\n",
            "[[ 99  47 334 291   0]]\n",
            "[[ 13  68 632 682   0]]\n",
            "[[ 73  99 557 389   1]]\n",
            "epoch:18 step:   25/60, lr:0.000003, giou_loss:   1.83, conf_loss:  18.91, prob_loss:   2.21, total_loss:  22.95\n",
            "[[  65  141  829  483    1]\n",
            " [ 351  122 1001  665    1]\n",
            " [  25   98  781  396    1]]\n",
            "[[ 480    5 1242  740    2]]\n",
            "[[ 246  217 1753  993    1]]\n",
            "[[ 176 1350  802 2488    1]]\n",
            "epoch:18 step:   26/60, lr:0.000003, giou_loss:   1.74, conf_loss:  19.28, prob_loss:   3.08, total_loss:  24.10\n",
            "[[  6  99 342 462   2]]\n",
            "[[ 58  16 582 374   1]]\n",
            "[[ 11  39 341 371   2]]\n",
            "[[ 59  71 465 490   0]]\n",
            "epoch:18 step:   27/60, lr:0.000003, giou_loss:   0.54, conf_loss:  17.10, prob_loss:   2.64, total_loss:  20.28\n",
            "[[165  91 361 336   1]]\n",
            "[[262  52 508 313   2]]\n",
            "[[195  64 337 209   0]\n",
            " [125 187 247 308   0]\n",
            " [132 303 284 427   0]\n",
            " [299 173 465 330   0]\n",
            " [ 58  93 157 183   0]\n",
            " [ 15 240  89 315   0]\n",
            " [  3  69  64 130   0]\n",
            " [  6 144  71 211   0]]\n",
            "[[ 82 127 261 297   2]]\n",
            "epoch:18 step:   28/60, lr:0.000003, giou_loss:   5.16, conf_loss:  23.56, prob_loss:   5.74, total_loss:  34.46\n",
            "[[ 43  70 497 526   2]]\n",
            "[[114  30 382 307   0]]\n",
            "[[  87   99 1444 1419    0]]\n",
            "[[ 13   4 263 259   0]]\n",
            "epoch:18 step:   29/60, lr:0.000003, giou_loss:   0.55, conf_loss:  17.03, prob_loss:   1.11, total_loss:  18.70\n",
            "[[333 332 936 943   2]]\n",
            "[[258  86 491 305   2]]\n",
            "[[ 37   9 525 316   1]]\n",
            "[[174 101 576 190   1]\n",
            " [173 109 569 261   1]\n",
            " [163 145 560 354   1]\n",
            " [ 86 165 437 436   1]]\n",
            "epoch:18 step:   30/60, lr:0.000003, giou_loss:   1.39, conf_loss:  17.68, prob_loss:   0.65, total_loss:  19.72\n",
            "[[262  86 858 753   1]]\n",
            "[[279   5 580 325   2]]\n",
            "[[ 428  133 1075  497    1]]\n",
            "[[ 51  90 275 321   1]\n",
            " [171 116 544 302   1]\n",
            " [136  41 511 189   1]]\n",
            "epoch:18 step:   31/60, lr:0.000003, giou_loss:   1.51, conf_loss:  18.93, prob_loss:   1.54, total_loss:  21.99\n",
            "[[ 32 249 196 399   2]\n",
            " [ 58  31 249 227   0]\n",
            " [239  26 365 413   1]\n",
            " [281 144 545 472   1]\n",
            " [292  25 446 402   1]]\n",
            "[[165 106 717 380   1]]\n",
            "[[  24  272 2756 2755    1]]\n",
            "[[ 84   1 391 333   0]]\n",
            "epoch:18 step:   32/60, lr:0.000003, giou_loss:   3.44, conf_loss:  19.62, prob_loss:   7.95, total_loss:  31.00\n",
            "[[ 123  305 1165  796    1]\n",
            " [ 338  308 1281  835    1]]\n",
            "[[  7 105 476 439   0]\n",
            " [305  40 777 439   0]]\n",
            "[[ 220   66  837  686    2]\n",
            " [ 795  154 1383  758    2]]\n",
            "[[ 218   24 1197 1019    0]]\n",
            "epoch:18 step:   33/60, lr:0.000003, giou_loss:   1.23, conf_loss:  17.33, prob_loss:   0.81, total_loss:  19.38\n",
            "[[   4   33 1110 1060    0]]\n",
            "[[  1   3 156 150   0]]\n",
            "[[ 77  10 533 379   2]]\n",
            "[[  1 176 265 428   2]\n",
            " [707 197 978 464   2]\n",
            " [517 142 770 369   2]\n",
            " [257 176 491 384   2]]\n",
            "epoch:18 step:   34/60, lr:0.000003, giou_loss:   2.45, conf_loss:  19.72, prob_loss:   6.38, total_loss:  28.56\n",
            "[[138 250 402 563   2]\n",
            " [129  98 449 353   0]\n",
            " [204  34 753 336   1]]\n",
            "[[125   6 357 176   1]\n",
            " [105  37 290 210   1]\n",
            " [ 75  50 225 240   1]\n",
            " [ 21  69 107 284   1]]\n",
            "[[  29  123 1430 1514    2]]\n",
            "[[597 171 971 549   2]\n",
            " [172 142 829 356   1]\n",
            " [189 275 775 559   1]]\n",
            "epoch:18 step:   35/60, lr:0.000003, giou_loss:   3.33, conf_loss:  20.59, prob_loss:   4.87, total_loss:  28.79\n",
            "[[ 444   36  867  462    2]\n",
            " [ 132  120  612  604    0]\n",
            " [ 242  208 1131  757    1]]\n",
            "[[176   9 473 296   0]]\n",
            "[[ 98   8 977 894   2]]\n",
            "[[ 544    8 1223  756    0]]\n",
            "epoch:18 step:   36/60, lr:0.000002, giou_loss:   1.24, conf_loss:  17.42, prob_loss:   1.62, total_loss:  20.28\n",
            "[[ 24   5 311 291   0]]\n",
            "[[ 81  26 292 222   2]\n",
            " [ 34 265 243 483   2]\n",
            " [211 345 423 544   2]\n",
            " [146 430 348 600   2]]\n",
            "[[123  58 546 387   1]]\n",
            "[[297 202 716 600   2]\n",
            " [ 41 128 296 369   2]]\n",
            "epoch:18 step:   37/60, lr:0.000002, giou_loss:   2.99, conf_loss:  20.54, prob_loss:   5.09, total_loss:  28.61\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "[[ 12 158 304 274   1]]\n",
            "[[113 258 583 700   0]]\n",
            "[[104 143 462 501   2]\n",
            " [ 40 121 637 578   1]]\n",
            "epoch:18 step:   38/60, lr:0.000002, giou_loss:   1.54, conf_loss:  17.91, prob_loss:   1.69, total_loss:  21.14\n",
            "[[ 463   32  883  408    2]\n",
            " [  63  285 1010  587    1]\n",
            " [ 138   73  507  385    0]]\n",
            "[[ 807  329 1185  740    2]\n",
            " [ 159    8  881  436    1]\n",
            " [ 181  140  851  758    1]]\n",
            "[[  1   7 208 215   0]]\n",
            "[[  6   2 369 349   0]]\n",
            "epoch:18 step:   39/60, lr:0.000002, giou_loss:   1.76, conf_loss:  18.10, prob_loss:   1.53, total_loss:  21.39\n",
            "[[345 167 521 337   0]\n",
            " [186 174 353 326   0]\n",
            " [424 162 578 302   0]\n",
            " [ 20 117 154 265   0]]\n",
            "[[ 16  13 157 170   0]\n",
            " [156   8 258 117   0]\n",
            " [107  76 218 185   0]]\n",
            "[[ 44  16 672 190   1]\n",
            " [ 30 104 617 414   1]\n",
            " [ 17  12 458 306   1]]\n",
            "[[118  48 295 211   0]]\n",
            "epoch:18 step:   40/60, lr:0.000002, giou_loss:   3.75, conf_loss:  22.06, prob_loss:   5.12, total_loss:  30.93\n",
            "[[  5   7 205 195   0]]\n",
            "[[  19  258 2475 4148    1]]\n",
            "[[465 391 890 800   2]]\n",
            "[[ 31  37 300 301   0]]\n",
            "epoch:18 step:   41/60, lr:0.000002, giou_loss:   0.83, conf_loss:  16.71, prob_loss:   0.59, total_loss:  18.14\n",
            "[[ 34 129 454 571   0]]\n",
            "[[   4    3 1818  926    1]]\n",
            "[[267 125 516 377   0]\n",
            " [ 19 110 299 383   0]]\n",
            "[[125  59 405 360   2]]\n",
            "epoch:18 step:   42/60, lr:0.000002, giou_loss:   0.83, conf_loss:  16.51, prob_loss:   1.01, total_loss:  18.35\n",
            "[[ 45   1 130  95   1]\n",
            " [ 62  30 195 110   1]\n",
            " [  1  27  47  99   1]\n",
            " [ 17   7  77  91   1]]\n",
            "[[  6  36 216 298   1]]\n",
            "[[  1  53 436 495   0]]\n",
            "[[ 407   33 1095  553    1]\n",
            " [ 240   33  669  553    1]]\n",
            "epoch:18 step:   43/60, lr:0.000002, giou_loss:   1.60, conf_loss:  18.74, prob_loss:   3.84, total_loss:  24.17\n",
            "[[ 37   5 737 712   0]]\n",
            "[[ 82 162 201 277   0]\n",
            " [222 182 353 307   0]\n",
            " [278  65 384 160   0]\n",
            " [345   2 480 106   0]\n",
            " [434  47 555 163   0]\n",
            " [338 105 452 212   0]]\n",
            "[[ 39   4 390 377   0]\n",
            " [356  28 763 459   0]]\n",
            "[[   4   24 1184  490    1]]\n",
            "epoch:18 step:   44/60, lr:0.000002, giou_loss:   4.93, conf_loss:  23.91, prob_loss:   8.53, total_loss:  37.38\n",
            "[[ 30   5 176 148   2]\n",
            " [ 19 147 325 229   1]\n",
            " [180   0 317 145   0]]\n",
            "[[ 44  71 467 493   0]\n",
            " [312  13 636 339   0]]\n",
            "[[164 218 353 412   0]\n",
            " [236 131 401 316   0]\n",
            " [ 96 142 265 324   0]]\n",
            "[[ 589   67 1167  579    2]]\n",
            "epoch:18 step:   45/60, lr:0.000002, giou_loss:   2.26, conf_loss:  18.66, prob_loss:   1.51, total_loss:  22.43\n",
            "[[  61  122 1715 1019    1]\n",
            " [ 482  171 1995 1239    1]\n",
            " [   5   96 1598  675    1]]\n",
            "[[193  33 439 258   0]\n",
            " [464  30 651 280   0]\n",
            " [315   5 536 220   0]]\n",
            "[[ 26   2 452 333   1]]\n",
            "[[ 32 223 270 501   2]\n",
            " [292 213 548 484   2]]\n",
            "epoch:18 step:   46/60, lr:0.000002, giou_loss:   2.38, conf_loss:  20.55, prob_loss:   2.55, total_loss:  25.48\n",
            "[[254 163 582 487   0]\n",
            " [217 448 535 713   0]\n",
            " [603 470 800 716   0]\n",
            " [468 179 727 467   0]\n",
            " [  1  63 308 414   0]]\n",
            "[[ 26  34 539 546   2]]\n",
            "[[ 28  39 214 221   0]]\n",
            "[[ 29  69 293 341   2]]\n",
            "epoch:18 step:   47/60, lr:0.000002, giou_loss:   2.25, conf_loss:  18.56, prob_loss:   3.52, total_loss:  24.33\n",
            "[[104  90 440 460   2]\n",
            " [458  79 787 401   2]]\n",
            "[[   7  257  861 1135    0]]\n",
            "[[ 21  21 486 477   2]]\n",
            "[[251  99 576 428   0]\n",
            " [ 35  66 306 357   0]]\n",
            "epoch:18 step:   48/60, lr:0.000002, giou_loss:   1.46, conf_loss:  18.47, prob_loss:   2.86, total_loss:  22.79\n",
            "[[ 21  87 194 259   2]\n",
            " [137  93 422 376   1]\n",
            " [180   5 344 166   0]]\n",
            "[[ 14   1 288 268   2]]\n",
            "[[  2  37 320 341   1]]\n",
            "[[  1   6 340 208   1]]\n",
            "epoch:18 step:   49/60, lr:0.000002, giou_loss:   0.97, conf_loss:  17.72, prob_loss:   1.65, total_loss:  20.34\n",
            "[[ 25  48 527 251   1]]\n",
            "[[ 123  730  926 1551    0]\n",
            " [ 629    1 1035  617    0]\n",
            " [ 412    4  932  557    0]]\n",
            "[[ 420   83 1173  765    0]]\n",
            "[[ 11  43 592 448   1]\n",
            " [ 24 174 599 657   1]]\n",
            "epoch:18 step:   50/60, lr:0.000002, giou_loss:   1.72, conf_loss:  18.14, prob_loss:   3.64, total_loss:  23.50\n",
            "[[ 68  77 599 582   2]]\n",
            "[[174  62 607 387   1]\n",
            " [322  77 696 439   1]\n",
            " [116  48 555 293   1]]\n",
            "[[ 37  40 440 448   2]]\n",
            "[[184 110 582 525   0]]\n",
            "epoch:18 step:   51/60, lr:0.000002, giou_loss:   0.94, conf_loss:  17.20, prob_loss:   0.95, total_loss:  19.08\n",
            "[[136  15 364 248   2]]\n",
            "[[ 39  65 519 269   1]]\n",
            "[[ 18  19 247 243   2]]\n",
            "[[118  19 240 142   2]\n",
            " [ 17  17 153 161   2]]\n",
            "epoch:18 step:   52/60, lr:0.000002, giou_loss:   1.11, conf_loss:  17.35, prob_loss:   3.02, total_loss:  21.47\n",
            "[[ 55 109 393 470   2]\n",
            " [351  69 703 432   2]]\n",
            "[[  8  34 327 146   1]]\n",
            "[[  4  11 151 155   0]]\n",
            "[[ 10  47 136 187   0]]\n",
            "epoch:18 step:   53/60, lr:0.000002, giou_loss:   0.64, conf_loss:  17.11, prob_loss:   1.58, total_loss:  19.34\n",
            "[[ 84  71 446 398   2]]\n",
            "[[ 27  32 279 291   2]]\n",
            "[[ 43 135 219 324   0]]\n",
            "[[  0  92 405 434   1]]\n",
            "epoch:18 step:   54/60, lr:0.000002, giou_loss:   0.57, conf_loss:  16.89, prob_loss:   0.69, total_loss:  18.15\n",
            "[[ 73  11 264 200   2]\n",
            " [186   3 346 181   2]]\n",
            "[[ 16 100 573 334   1]]\n",
            "[[121 161 588 436   1]\n",
            " [145 100 578 330   1]]\n",
            "[[ 238  215  661  622    2]\n",
            " [ 705  312 1089  739    2]\n",
            " [ 649  698 1129 1130    2]]\n",
            "epoch:18 step:   55/60, lr:0.000002, giou_loss:   2.61, conf_loss:  19.60, prob_loss:   4.01, total_loss:  26.21\n",
            "[[ 68  28 511 423   1]]\n",
            "[[280 146 642 511   0]]\n",
            "[[  33  293  667 1293    1]\n",
            " [ 449  114  974 1172    1]]\n",
            "[[ 55  77 238 267   2]]\n",
            "epoch:18 step:   56/60, lr:0.000002, giou_loss:   1.44, conf_loss:  17.95, prob_loss:   1.27, total_loss:  20.67\n",
            "[[  3   3 251 259   2]]\n",
            "[[ 659  329 1171  886    0]]\n",
            "[[367 155 931 735   0]\n",
            " [ 48 118 560 607   0]]\n",
            "[[  9 108 191 319   0]]\n",
            "epoch:18 step:   57/60, lr:0.000002, giou_loss:   0.86, conf_loss:  17.37, prob_loss:   2.41, total_loss:  20.64\n",
            "[[113  36 474 327   2]]\n",
            "[[151   7 587 244   1]]\n",
            "[[187 138 643 624   2]]\n",
            "[[ 87   6 518 447   2]]\n",
            "epoch:18 step:   58/60, lr:0.000002, giou_loss:   0.73, conf_loss:  16.36, prob_loss:   2.17, total_loss:  19.27\n",
            "[[300  39 485 131   1]\n",
            " [113  38 297 132   1]]\n",
            "[[ 99 202 214 301   2]\n",
            " [509 180 589 255   2]\n",
            " [483 123 581 200   2]\n",
            " [113  90 370 190   1]\n",
            " [151 132 385 227   1]\n",
            " [287  89 444 234   1]\n",
            " [315 139 451 268   1]\n",
            " [292  14 401 117   0]\n",
            " [402  47 516 152   0]]\n",
            "[[ 14  44 270 300   0]]\n",
            "[[ 18 153 386 542   2]]\n",
            "epoch:18 step:   59/60, lr:0.000002, giou_loss:   9.17, conf_loss:  27.47, prob_loss:  10.48, total_loss:  47.12\n",
            "[[ 193   66 1766  689    1]]\n",
            "[[  3  14 285 259   0]]\n",
            "[[  3   0 507 527   0]]\n",
            "[[  5 157 424 351   1]\n",
            " [ 96  94 418 231   1]\n",
            " [102  39 377 174   1]]\n",
            "epoch:18 step:    0/60, lr:0.000002, giou_loss:   1.61, conf_loss:  17.45, prob_loss:   3.04, total_loss:  22.10\n",
            "[[ 24  79 110 167   2]\n",
            " [ 56  66 134 157   2]]\n",
            "[[ 44  43 589 560   2]]\n",
            "[[ 47  63 215 233   0]]\n",
            "[[103 138 491 313   1]]\n",
            "epoch:18 step:    1/60, lr:0.000002, giou_loss:   1.04, conf_loss:  16.87, prob_loss:   1.24, total_loss:  19.15\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[155 105 453 436   0]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[203 115 584 452   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[150 165 923 983   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[143  40 415 346   0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.91, prob_val_loss:   3.76, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[190 129 331 370   1]\n",
            " [322 118 406 379   1]\n",
            " [412 135 485 374   1]\n",
            " [488 142 583 379   1]]\n",
            "[[ 184  221 1226  712    1]\n",
            " [  68  224 1011  751    1]]\n",
            "[[ 37   6 183 149   2]\n",
            " [ 26 148 332 230   1]\n",
            " [187   1 324 146   0]]\n",
            "[[167  29 528 320   2]]\n",
            "epoch:19 step:    2/60, lr:0.000002, giou_loss:   4.06, conf_loss:  20.67, prob_loss:   4.11, total_loss:  28.85\n",
            "[[ 13  46 196 236   2]]\n",
            "[[  40  344  995  980    1]\n",
            " [  40  548  821 1056    1]\n",
            " [ 359   59 1539  932    1]]\n",
            "[[218 163 546 487   0]\n",
            " [265 448 583 713   0]\n",
            " [  0 470 197 716   0]\n",
            " [ 73 179 332 467   0]\n",
            " [492  63 799 414   0]]\n",
            "[[ 70  14 493 343   1]]\n",
            "epoch:19 step:    3/60, lr:0.000002, giou_loss:   2.51, conf_loss:  18.75, prob_loss:   1.82, total_loss:  23.08\n",
            "[[  38  189 1017 1184    0]]\n",
            "[[  2  94 203 299   2]]\n",
            "[[ 16  45 334 349   1]]\n",
            "[[167 109 637 551   0]]\n",
            "epoch:19 step:    4/60, lr:0.000002, giou_loss:   0.44, conf_loss:  16.91, prob_loss:   0.51, total_loss:  17.86\n",
            "[[  68  305  947 1191    2]]\n",
            "[[ 85 137 488 545   2]]\n",
            "[[197 102 585 277   1]]\n",
            "[[   0   47 1867 1867    2]]\n",
            "epoch:19 step:    5/60, lr:0.000002, giou_loss:   0.64, conf_loss:  16.84, prob_loss:   1.21, total_loss:  18.68\n",
            "[[195  91 305 201   0]\n",
            " [127  64 228 159   0]\n",
            " [ 19  77 123 188   0]]\n",
            "[[349 227 861 784   0]]\n",
            "[[ 13  43 220 251   0]]\n",
            "[[ 73   1 305 171   1]\n",
            " [140  32 325 205   1]\n",
            " [205  45 355 235   1]\n",
            " [323  64 409 279   1]]\n",
            "epoch:19 step:    6/60, lr:0.000002, giou_loss:   2.71, conf_loss:  19.25, prob_loss:   6.33, total_loss:  28.29\n",
            "[[313 130 916 741   2]]\n",
            "[[406 177 718 465   2]\n",
            " [138 329 963 525   1]\n",
            " [148 448 991 656   1]]\n",
            "[[  58   85 2790 2568    1]]\n",
            "[[ 19  14 311 130   1]]\n",
            "epoch:19 step:    7/60, lr:0.000002, giou_loss:   1.90, conf_loss:  18.09, prob_loss:   2.58, total_loss:  22.57\n",
            "[[ 22 149 441 343   1]\n",
            " [ 28  86 350 223   1]\n",
            " [ 69  31 344 166   1]]\n",
            "[[  1 103 122 246   2]\n",
            " [ 22   0 128 114   2]\n",
            " [ 94  61 224 186   2]\n",
            " [114   1 224  69   2]\n",
            " [ 73 200 195 249   2]]\n",
            "[[ 95  80 375 381   2]]\n",
            "[[244 202 663 600   2]\n",
            " [664 128 919 369   2]]\n",
            "epoch:19 step:    8/60, lr:0.000002, giou_loss:   3.12, conf_loss:  21.96, prob_loss:  10.25, total_loss:  35.33\n",
            "[[  21  156 1127 1183    0]]\n",
            "[[ 47  25 299 284   2]]\n",
            "[[ 45  61 223 239   2]\n",
            " [248  75 416 218   0]\n",
            " [ 45 292 357 416   1]]\n",
            "[[190  68 387 838   1]]\n",
            "epoch:19 step:    9/60, lr:0.000002, giou_loss:   1.53, conf_loss:  17.59, prob_loss:   0.97, total_loss:  20.09\n",
            "[[ 10  72 335 401   0]\n",
            " [280  39 551 330   0]]\n",
            "[[  4  11 302 299   0]]\n",
            "[[ 74  78 250 267   0]]\n",
            "[[ 38 174 595 408   1]]\n",
            "epoch:19 step:   10/60, lr:0.000002, giou_loss:   0.70, conf_loss:  16.66, prob_loss:   2.80, total_loss:  20.16\n",
            "[[   9   71  742  846    2]\n",
            " [ 581   34 1274  766    2]]\n",
            "[[337  83 579 338   2]\n",
            " [134 148 360 404   0]\n",
            " [173 228 746 528   1]]\n",
            "[[  1  32 893 519   1]]\n",
            "[[ 31  27 633 480   1]\n",
            " [ 55   3 626 300   1]\n",
            " [ 92   7 603 216   1]\n",
            " [  1 147 200 480   1]]\n",
            "epoch:19 step:   11/60, lr:0.000002, giou_loss:   2.62, conf_loss:  19.88, prob_loss:   2.56, total_loss:  25.06\n",
            "[[483 170 857 548   2]\n",
            " [ 58 141 715 355   1]\n",
            " [ 75 274 661 558   1]]\n",
            "[[399 238 678 519   2]\n",
            " [559  81 869 339   2]\n",
            " [583 328 916 565   2]]\n",
            "[[368  73 626 321   2]\n",
            " [ 26  35 325 334   2]]\n",
            "[[ 350    1 1923  624    1]]\n",
            "epoch:19 step:   12/60, lr:0.000001, giou_loss:   2.89, conf_loss:  19.79, prob_loss:   4.64, total_loss:  27.31\n",
            "[[398 109 703 415   0]\n",
            " [ 88 274 376 539   0]\n",
            " [177 138 460 393   0]]\n",
            "[[262  52 508 313   2]]\n",
            "[[ 36  35 210 210   0]\n",
            " [183  22 333 190   0]]\n",
            "[[ 24  20 178 165   2]]\n",
            "epoch:19 step:   13/60, lr:0.000001, giou_loss:   1.34, conf_loss:  18.09, prob_loss:   1.29, total_loss:  20.72\n",
            "[[ 157  812  960 1633    0]\n",
            " [  48   83  454  699    0]\n",
            " [ 151   86  671  639    0]]\n",
            "[[ 97  83 533 320   1]]\n",
            "[[137 131 467 463   2]]\n",
            "[[ 71 104 304 323   2]]\n",
            "epoch:19 step:   14/60, lr:0.000001, giou_loss:   1.31, conf_loss:  17.87, prob_loss:   1.78, total_loss:  20.96\n",
            "[[197  72 339 217   0]\n",
            " [127 195 249 316   0]\n",
            " [134 311 286 435   0]\n",
            " [301 181 467 338   0]\n",
            " [ 60 101 159 191   0]\n",
            " [ 17 248  91 323   0]\n",
            " [  5  77  66 138   0]\n",
            " [  8 152  73 219   0]]\n",
            "[[ 71  54 248 221   0]]\n",
            "[[244  13 560 306   1]\n",
            " [ 95   5 467 180   1]\n",
            " [114   1 480 260   1]\n",
            " [105   7 448 211   1]]\n",
            "[[ 31   9 525 256   1]\n",
            " [ 54  17 280 243   1]]\n",
            "epoch:19 step:   15/60, lr:0.000001, giou_loss:   6.22, conf_loss:  25.27, prob_loss:  11.09, total_loss:  42.58\n",
            "[[ 23  32 410 225   1]\n",
            " [494 104 643 266   1]\n",
            " [ 14 151 556 340   1]]\n",
            "[[ 470  161  992  495    1]\n",
            " [ 628    1 1169  298    1]\n",
            " [   1    3  412  344    1]\n",
            " [   1  249  260  669    1]\n",
            " [ 229  449  710  674    1]\n",
            " [ 822  480 1198  674    1]]\n",
            "[[733 247 997 499   2]\n",
            " [ 20 268 291 535   2]\n",
            " [228 213 481 440   2]\n",
            " [507 247 741 455   2]]\n",
            "[[ 12  18 416 162   1]]\n",
            "epoch:19 step:   16/60, lr:0.000001, giou_loss:   6.41, conf_loss:  26.43, prob_loss:  15.54, total_loss:  48.38\n",
            "[[ 15  13 211 196   0]]\n",
            "[[ 72  27 300 260   2]]\n",
            "[[ 67  48 493 379   1]]\n",
            "[[227 174 416 368   0]\n",
            " [299  87 464 272   0]\n",
            " [159  98 328 280   0]]\n",
            "epoch:19 step:   17/60, lr:0.000001, giou_loss:   1.22, conf_loss:  17.52, prob_loss:   1.17, total_loss:  19.92\n",
            "[[146   6 650 533   0]]\n",
            "[[ 15  57 366 430   0]\n",
            " [332  81 739 512   0]]\n",
            "[[   4    3 1818  926    1]]\n",
            "[[ 284   12  856 1012    1]]\n",
            "epoch:19 step:   18/60, lr:0.000001, giou_loss:   1.08, conf_loss:  17.50, prob_loss:   1.39, total_loss:  19.97\n",
            "[[  45  500  590 1017    2]]\n",
            "[[ 93  79 272 249   2]]\n",
            "[[ 23  55 458 497   0]]\n",
            "[[174 101 576 190   1]\n",
            " [173 109 569 261   1]\n",
            " [163 145 560 354   1]\n",
            " [ 86 165 437 436   1]]\n",
            "epoch:19 step:   19/60, lr:0.000001, giou_loss:   1.37, conf_loss:  17.20, prob_loss:   0.59, total_loss:  19.17\n",
            "[[ 94 181 285 370   2]\n",
            " [ 12 173 172 351   2]]\n",
            "[[  2 101 428 315   1]]\n",
            "[[506   4 726 205   0]\n",
            " [543 196 761 432   0]\n",
            " [414 156 613 390   0]\n",
            " [  9 277 191 492   0]\n",
            " [121 349 298 546   0]\n",
            " [222 218 463 442   0]\n",
            " [423 329 605 522   0]\n",
            " [141 404 353 577   0]]\n",
            "[[144  46 340 291   1]]\n",
            "epoch:19 step:   20/60, lr:0.000001, giou_loss:   5.25, conf_loss:  23.36, prob_loss:   4.44, total_loss:  33.06\n",
            "[[  0  70 296 388   0]]\n",
            "[[114 105 338 347   2]]\n",
            "[[149  92 701 366   1]]\n",
            "[[404 173 827 595   0]\n",
            " [235 115 559 441   0]]\n",
            "epoch:19 step:   21/60, lr:0.000001, giou_loss:   0.95, conf_loss:  16.45, prob_loss:   0.70, total_loss:  18.10\n",
            "[[  1  60 294 176   1]]\n",
            "[[127  68 370 291   2]]\n",
            "[[ 13  56 182 211   2]\n",
            " [132  48 292 211   2]\n",
            " [194   1 336 142   2]]\n",
            "[[394 141 730 511   2]\n",
            " [ 47 130 376 452   2]]\n",
            "epoch:19 step:   22/60, lr:0.000001, giou_loss:   2.15, conf_loss:  19.26, prob_loss:   5.07, total_loss:  26.48\n",
            "[[ 33  22 218 114   1]\n",
            " [221  21 405 115   1]]\n",
            "[[127  12 463 375   2]]\n",
            "[[216 137 865 841   0]]\n",
            "[[ 27  27 715 547   1]\n",
            " [453  27 882 547   1]]\n",
            "epoch:19 step:   23/60, lr:0.000001, giou_loss:   2.11, conf_loss:  19.65, prob_loss:   3.39, total_loss:  25.15\n",
            "[[ 84 132 266 343   0]]\n",
            "[[ 38  49 700 752   2]]\n",
            "[[  5  31 191 213   0]]\n",
            "[[ 99  83 458 416   1]\n",
            " [186  39 624 382   1]\n",
            " [205   8 670 226   1]]\n",
            "epoch:19 step:   24/60, lr:0.000001, giou_loss:   1.02, conf_loss:  16.61, prob_loss:   1.20, total_loss:  18.83\n",
            "[[ 55 240 170 339   2]\n",
            " [465 218 545 293   2]\n",
            " [439 161 537 238   2]\n",
            " [ 69 128 326 228   1]\n",
            " [107 170 341 265   1]\n",
            " [243 127 400 272   1]\n",
            " [271 177 407 306   1]\n",
            " [248  52 357 155   0]\n",
            " [358  85 472 190   0]]\n",
            "[[  6  39 556 591   0]\n",
            " [398  45 839 513   0]\n",
            " [635  55 912 454   0]]\n",
            "[[217 137 426 358   2]\n",
            " [ 19  99 224 351   2]\n",
            " [129   1 348 171   2]]\n",
            "[[ 484  135 1163  883    0]]\n",
            "epoch:19 step:   25/60, lr:0.000001, giou_loss:   8.72, conf_loss:  29.37, prob_loss:  13.59, total_loss:  51.68\n",
            "[[ 185   49  605  425    2]\n",
            " [  58  302 1005  604    1]\n",
            " [ 561   90  930  402    0]]\n",
            "[[327   9 595 286   0]]\n",
            "[[ 45  34 130 128   1]\n",
            " [ 62  63 195 143   1]\n",
            " [  1  60  47 132   1]\n",
            " [ 17  40  77 124   1]]\n",
            "[[147  45 288 202   0]\n",
            " [ 46  40 148 149   0]\n",
            " [ 86 108 197 217   0]]\n",
            "epoch:19 step:   26/60, lr:0.000001, giou_loss:   2.96, conf_loss:  21.28, prob_loss:   3.95, total_loss:  28.19\n",
            "[[ 21 124 454 553   0]]\n",
            "[[173  29 606 354   1]\n",
            " [ 84  44 458 406   1]\n",
            " [225  15 664 260   1]]\n",
            "[[ 67   4 222 151   0]]\n",
            "[[ 289  215 1943 1112    1]\n",
            " [   9  264 1522 1332    1]\n",
            " [ 406  189 1999  768    1]]\n",
            "epoch:19 step:   27/60, lr:0.000001, giou_loss:   1.40, conf_loss:  16.61, prob_loss:   1.10, total_loss:  19.11\n",
            "[[ 10  16 490 220   1]]\n",
            "[[  5   6 184 178   0]]\n",
            "[[ 45  30 301 286   0]]\n",
            "[[ 561    1 1261  708    0]]\n",
            "epoch:19 step:   28/60, lr:0.000001, giou_loss:   0.81, conf_loss:  17.54, prob_loss:   1.05, total_loss:  19.41\n",
            "[[ 153  281  993 1117    2]]\n",
            "[[ 22  38 199 201   0]]\n",
            "[[434  36 899 492   2]]\n",
            "[[ 74  82 517 477   1]]\n",
            "epoch:19 step:   29/60, lr:0.000001, giou_loss:   0.71, conf_loss:  16.91, prob_loss:   0.81, total_loss:  18.44\n",
            "[[ 47  55 245 246   2]\n",
            " [211  32 380 205   2]]\n",
            "[[173  43 593 485   0]]\n",
            "[[ 38   1 345 299   2]]\n",
            "[[150 143 362 348   2]]\n",
            "epoch:19 step:   30/60, lr:0.000001, giou_loss:   0.79, conf_loss:  16.93, prob_loss:   4.44, total_loss:  22.16\n",
            "[[158   0 521 347   0]]\n",
            "[[ 12  42 313 362   2]]\n",
            "[[  34   99 1391 1419    0]]\n",
            "[[  2  69 407 411   1]]\n",
            "epoch:19 step:   31/60, lr:0.000001, giou_loss:   0.40, conf_loss:  16.77, prob_loss:   0.41, total_loss:  17.58\n",
            "[[ 13  21 251 299   2]\n",
            " [273  11 529 282   2]]\n",
            "[[  3 486 905 964   1]]\n",
            "[[  5  89 474 423   0]\n",
            " [303  24 775 423   0]]\n",
            "[[160  65 616 434   2]]\n",
            "epoch:19 step:   32/60, lr:0.000001, giou_loss:   1.47, conf_loss:  17.32, prob_loss:   1.25, total_loss:  20.03\n",
            "[[  8  13 208 201   0]]\n",
            "[[  14  107 1194  573    1]]\n",
            "[[ 15  87 255 291   0]]\n",
            "[[599  14 895 286   1]\n",
            " [138  44 406 387   1]\n",
            " [221  62 510 406   1]\n",
            " [250 142 510 536   1]\n",
            " [464 129 634 555   1]\n",
            " [530 128 821 463   1]\n",
            " [484  43 857 324   1]]\n",
            "epoch:19 step:   33/60, lr:0.000001, giou_loss:   3.99, conf_loss:  21.29, prob_loss:   9.67, total_loss:  34.95\n",
            "[[  3  25 225 244   2]\n",
            " [160  10 360 232   2]]\n",
            "[[ 127  369  505  780    2]\n",
            " [ 431   48 1153  476    1]\n",
            " [ 461  180 1131  798    1]]\n",
            "[[ 58  57 184 197   0]]\n",
            "[[ 15 151 239 382   1]\n",
            " [135 177 508 363   1]\n",
            " [100 102 475 250   1]]\n",
            "epoch:19 step:   34/60, lr:0.000001, giou_loss:   2.10, conf_loss:  18.90, prob_loss:   2.92, total_loss:  23.92\n",
            "[[ 255  243  604  611    2]\n",
            " [ 504  280  933  631    2]\n",
            " [ 736  220 1080  563    2]\n",
            " [ 480    4  920  362    2]]\n",
            "[[ 110  613  736 1751    1]]\n",
            "[[ 71  21 559 328   1]]\n",
            "[[143  63 501 421   2]\n",
            " [ 79  41 676 498   1]]\n",
            "epoch:19 step:   35/60, lr:0.000001, giou_loss:   2.71, conf_loss:  21.99, prob_loss:   4.33, total_loss:  29.03\n",
            "[[ 84   8 277 210   0]]\n",
            "[[142  22 264 145   2]\n",
            " [ 41  20 177 164   2]]\n",
            "[[506 262 670 412   2]\n",
            " [453  44 644 240   0]\n",
            " [337  39 463 426   1]\n",
            " [157 157 421 485   1]\n",
            " [256  38 410 415   1]]\n",
            "[[ 73  71 576 317   1]]\n",
            "epoch:19 step:   36/60, lr:0.000001, giou_loss:   3.93, conf_loss:  19.53, prob_loss:   4.58, total_loss:  28.03\n",
            "[[  6  25 153 169   0]]\n",
            "[[ 27  35 540 547   2]]\n",
            "[[ 71  53 311 297   2]\n",
            " [320  48 574 315   2]]\n",
            "[[  5  39 287 284   0]]\n",
            "epoch:19 step:   37/60, lr:0.000001, giou_loss:   0.77, conf_loss:  16.82, prob_loss:   2.58, total_loss:  20.18\n",
            "[[ 60  25 371 296   1]\n",
            " [136  85 397 373   1]]\n",
            "[[446 103 583 262   2]\n",
            " [456  28 592 167   2]\n",
            " [117  98 249 243   2]\n",
            " [ 75  33 224 163   2]\n",
            " [213  55 356 199   2]\n",
            " [280 107 431 249   2]\n",
            " [362  12 495 138   2]]\n",
            "[[332 291 700 680   2]]\n",
            "[[315 231 538 445   2]\n",
            " [110 223 337 434   0]\n",
            " [290 258 646 455   1]]\n",
            "epoch:19 step:   38/60, lr:0.000001, giou_loss:   5.67, conf_loss:  24.85, prob_loss:   8.61, total_loss:  39.13\n",
            "[[103  47 189 135   2]\n",
            " [ 79  34 157 125   2]]\n",
            "[[121  14 514 416   2]]\n",
            "[[ 13  21 261 277   2]]\n",
            "[[ 20 335 330 651   2]\n",
            " [181 198 787 415   1]\n",
            " [131 256 781 511   1]\n",
            " [471  33 733 326   0]]\n",
            "epoch:19 step:   39/60, lr:0.000001, giou_loss:   2.12, conf_loss:  18.10, prob_loss:   3.65, total_loss:  23.88\n",
            "[[270  80 435 275   2]\n",
            " [ 84  75 277 298   0]\n",
            " [ 30 293 575 546   1]]\n",
            "[[ 25 263 509 739   0]\n",
            " [308  61 675 534   0]]\n",
            "[[ 761  182 1186  591    2]]\n",
            "[[ 387   24  810  450    2]\n",
            " [ 642  108 1122  592    0]\n",
            " [ 123  196 1012  745    1]]\n",
            "epoch:19 step:   40/60, lr:0.000001, giou_loss:   2.61, conf_loss:  18.74, prob_loss:   4.24, total_loss:  25.59\n",
            "[[ 85  20 448 509   1]]\n",
            "[[ 22  98 693 355   1]]\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[ 415  170 1522  925    1]\n",
            " [ 548  589 1819 1270    1]\n",
            " [ 246    3 1221  613    1]\n",
            " [ 102    3  966  552    1]]\n",
            "epoch:19 step:   41/60, lr:0.000001, giou_loss:   2.34, conf_loss:  18.57, prob_loss:   6.61, total_loss:  27.51\n",
            "[[ 410 1063 1044 2063    1]\n",
            " [ 103  884  628 1942    1]]\n",
            "[[ 86 162 848 897   2]]\n",
            "[[136 117 240 224   2]]\n",
            "[[ 235  228 1742 1004    1]]\n",
            "epoch:19 step:   42/60, lr:0.000001, giou_loss:   1.96, conf_loss:  18.55, prob_loss:   1.66, total_loss:  22.17\n",
            "[[214 159 296 247   2]\n",
            " [156 156 229 231   2]\n",
            " [ 26  42 256 138   1]\n",
            " [ 15 177 109 268   0]]\n",
            "[[ 33  31 652 645   0]]\n",
            "[[ 158    2 1471 1069    1]]\n",
            "[[ 63 114 274 310   2]\n",
            " [ 16 353 225 571   2]\n",
            " [193 433 405 632   2]\n",
            " [128 518 330 688   2]]\n",
            "epoch:19 step:   43/60, lr:0.000001, giou_loss:   3.08, conf_loss:  21.15, prob_loss:   5.63, total_loss:  29.87\n",
            "[[  6   1 437 442   2]]\n",
            "[[  4  65 301 352   0]]\n",
            "[[ 31  10 199 180   0]]\n",
            "[[384  81 722 442   2]\n",
            " [ 74  41 426 404   2]]\n",
            "epoch:19 step:   44/60, lr:0.000001, giou_loss:   0.70, conf_loss:  16.49, prob_loss:   3.28, total_loss:  20.47\n",
            "[[254   9 580 284   0]]\n",
            "[[205 196 375 374   0]\n",
            " [137 144 303 328   0]]\n",
            "[[ 13  39 287 306   2]]\n",
            "[[512  36 814 350   0]\n",
            " [115 122 394 375   0]\n",
            " [424 183 701 425   0]\n",
            " [ 14  96 254 364   0]]\n",
            "epoch:19 step:   45/60, lr:0.000001, giou_loss:   2.23, conf_loss:  18.78, prob_loss:   2.24, total_loss:  23.25\n",
            "[[ 39 256 303 569   2]\n",
            " [ 30 104 350 359   0]\n",
            " [105  40 654 342   1]]\n",
            "[[ 248  368 1649 1759    2]]\n",
            "[[412 233 582 521   1]\n",
            " [256 256 368 572   1]\n",
            " [185 216 336 473   1]\n",
            " [353 269 464 586   1]]\n",
            "[[ 49 213 613 793   0]\n",
            " [420 176 932 665   0]]\n",
            "epoch:19 step:   46/60, lr:0.000001, giou_loss:   4.13, conf_loss:  22.31, prob_loss:   4.04, total_loss:  30.48\n",
            "[[ 11 204 178 381   0]\n",
            " [145 196 322 353   0]\n",
            " [ 85 105 264 274   0]]\n",
            "[[ 38  15 351 141   1]\n",
            " [190  34 413 249   1]\n",
            " [ 75  43 367 192   1]]\n",
            "[[ 27  18 655 192   1]\n",
            " [ 13 106 600 416   1]\n",
            " [  0  14 441 308   1]]\n",
            "[[280 146 642 511   0]]\n",
            "epoch:19 step:   47/60, lr:0.000001, giou_loss:   2.58, conf_loss:  19.33, prob_loss:   2.42, total_loss:  24.33\n",
            "[[  35    4  993  744    2]\n",
            " [ 363  646 1161 1069    2]]\n",
            "[[145  14 242 119   2]]\n",
            "[[ 428  133 1075  497    1]]\n",
            "[[  1 171 532 676   2]]\n",
            "epoch:19 step:   48/60, lr:0.000001, giou_loss:   1.13, conf_loss:  18.29, prob_loss:   3.34, total_loss:  22.76\n",
            "[[ 47  31 257 293   1]]\n",
            "[[ 20  17 270 272   0]]\n",
            "[[245 101 998 783   0]]\n",
            "[[  6  30 345 232   1]]\n",
            "epoch:19 step:   49/60, lr:0.000001, giou_loss:   0.60, conf_loss:  16.62, prob_loss:   0.36, total_loss:  17.58\n",
            "[[  5  46 403 461   0]]\n",
            "[[ 60   7 247 209   2]]\n",
            "[[341 199 517 369   0]\n",
            " [182 206 349 358   0]\n",
            " [420 194 574 334   0]\n",
            " [ 16 149 150 297   0]]\n",
            "[[ 132  388 1103 1172    1]\n",
            " [ 445  447 1069 1046    0]]\n",
            "epoch:19 step:   50/60, lr:0.000001, giou_loss:   2.53, conf_loss:  19.69, prob_loss:   2.84, total_loss:  25.06\n",
            "[[  4  69 366 396   2]]\n",
            "[[ 519   53 1097  565    2]]\n",
            "[[ 78  21 602 379   1]]\n",
            "[[ 29   9 435 428   0]]\n",
            "epoch:19 step:   51/60, lr:0.000001, giou_loss:   0.70, conf_loss:  16.34, prob_loss:   0.57, total_loss:  17.61\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[584 438 867 708   0]\n",
            " [492 141 740 394   0]\n",
            " [176 199 490 466   0]\n",
            " [367  17 619 240   0]\n",
            " [642  35 907 269   0]]\n",
            "[[ 75  43 394 155   1]]\n",
            "[[301  57 897 724   1]]\n",
            "epoch:19 step:   52/60, lr:0.000001, giou_loss:   4.51, conf_loss:  23.74, prob_loss:   4.95, total_loss:  33.20\n",
            "[[ 16 111 189 283   2]\n",
            " [132 117 417 400   1]\n",
            " [175  29 339 190   0]]\n",
            "[[   3  128 2459 4018    1]]\n",
            "[[  4   6 239 250   0]]\n",
            "[[1245  423 2710 1997    2]]\n",
            "epoch:19 step:   53/60, lr:0.000001, giou_loss:   1.34, conf_loss:  17.41, prob_loss:   0.81, total_loss:  19.56\n",
            "[[ 96 107 580 397   1]]\n",
            "[[ 130   95  524  476    2]\n",
            " [ 606   81 1007  467    0]\n",
            " [ 222  521  903  883    1]]\n",
            "[[ 23  33 272 265   2]]\n",
            "[[539 280 772 547   0]\n",
            " [363 368 602 592   0]\n",
            " [ 34 262 238 494   0]\n",
            " [217 214 447 429   0]\n",
            " [466 199 659 350   0]\n",
            " [325  45 557 239   0]\n",
            " [559  78 724 243   0]]\n",
            "epoch:19 step:   54/60, lr:0.000001, giou_loss:   3.62, conf_loss:  21.28, prob_loss:   3.33, total_loss:  28.24\n",
            "[[  77  230  841  572    1]\n",
            " [ 363  211 1013  754    1]\n",
            " [  37  187  793  485    1]]\n",
            "[[ 27  26 314 312   0]]\n",
            "[[294 127 543 379   0]\n",
            " [ 46 112 326 385   0]]\n",
            "[[143   4 412 268   0]]\n",
            "epoch:19 step:   55/60, lr:0.000001, giou_loss:   1.21, conf_loss:  16.71, prob_loss:   1.46, total_loss:  19.38\n",
            "[[ 607  133 1030  540    2]\n",
            " [1074  230 1458  657    2]\n",
            " [1018  616 1498 1048    2]]\n",
            "[[ 18  48 281 336   0]\n",
            " [262  15 521 267   0]]\n",
            "[[ 15  10 322 342   0]]\n",
            "[[ 559  424 1293 1145    2]\n",
            " [  25  348  713 1010    2]]\n",
            "epoch:19 step:   56/60, lr:0.000001, giou_loss:   3.00, conf_loss:  20.59, prob_loss:   5.24, total_loss:  28.82\n",
            "[[  8   1 331 335   0]]\n",
            "[[ 87 265 694 868   0]]\n",
            "[[162  27 743 432   1]\n",
            " [155 158 730 641   1]]\n",
            "[[ 79  63 228 278   1]]\n",
            "epoch:19 step:   57/60, lr:0.000001, giou_loss:   1.11, conf_loss:  18.20, prob_loss:   0.76, total_loss:  20.07\n",
            "[[ 66 161 185 276   0]\n",
            " [206 181 337 306   0]\n",
            " [262  64 368 159   0]\n",
            " [329   1 464 105   0]\n",
            " [418  46 539 162   0]\n",
            " [322 104 436 211   0]]\n",
            "[[ 415  282 1032  902    2]\n",
            " [ 990  370 1578  974    2]]\n",
            "[[ 82  59 414 388   2]]\n",
            "[[170  37 498 339   1]\n",
            " [ 54 114 452 371   1]\n",
            " [126  31 438 226   1]]\n",
            "epoch:19 step:   58/60, lr:0.000001, giou_loss:   6.03, conf_loss:  25.00, prob_loss:   4.82, total_loss:  35.85\n",
            "[[ 69  83 238 191   1]]\n",
            "[[ 79  92 581 295   1]]\n",
            "[[  26  835  833 1774    1]\n",
            " [ 188  784 1153 1462    1]\n",
            " [ 300  659 1198 1149    1]\n",
            " [ 254  472 1035 1051    1]]\n",
            "[[255  36 501 261   0]\n",
            " [ 43  33 230 283   0]\n",
            " [158   8 379 223   0]]\n",
            "epoch:19 step:   59/60, lr:0.000001, giou_loss:   2.61, conf_loss:  22.53, prob_loss:   2.02, total_loss:  27.16\n",
            "[[ 146   87 1000  965    0]]\n",
            "[[ 18  15 472 471   2]]\n",
            "[[ 24  11 253 235   2]]\n",
            "[[256 101 712 587   2]]\n",
            "epoch:19 step:    0/60, lr:0.000001, giou_loss:   0.57, conf_loss:  16.79, prob_loss:   4.21, total_loss:  21.57\n",
            "[[222   8 486 280   2]]\n",
            "[[196  70 663 345   1]\n",
            " [220   9 653 239   1]]\n",
            "[[259 125 638 474   0]]\n",
            "[[ 12  98 471 348   1]]\n",
            "epoch:19 step:    1/60, lr:0.000001, giou_loss:   1.00, conf_loss:  16.91, prob_loss:   0.51, total_loss:  18.42\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[174  20 364 199   2]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[145  36 421 286   2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[143  40 415 346   0]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.78, prob_val_loss:   3.64, total_val_loss:    nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-3Ae77yB81l",
        "outputId": "7bd286ae-dda9-42d9-bd9c-bf47040b8782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.245620727539062"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NoPYfFSXlWw"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "MKS9tanWXjI4",
        "outputId": "11b6f996-3265-4900-eed6-f48050703f9b"
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "YOLO_INPUT_SIZE = 416\n",
        "input_size=YOLO_INPUT_SIZE\n",
        "\n",
        "\n",
        "\n",
        "image_path =\"/content/drive/MyDrive/fruit/test/banana_77.jpg\" #image_info[0]\n",
        "\n",
        "yolo = Create_Yolov3(input_size=input_size, CLASSES=TRAIN_CLASSES)\n",
        "yolo.load_weights(\"./chkpt_fruits/yolov3_custom\")\n",
        "\n",
        "\n",
        "\n",
        "img = detect_image(yolo, image_path, \"\", input_size=input_size, show=True, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x360 at 0x7FBBCA6BAB10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JThlN9YaFW5c",
        "outputId": "5c840133-a597-4090-8f6d-7012bb209204"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jHWJOLySH8Vh",
        "outputId": "f1a90fa2-b9cd-4e75-e713-21603150c0c6"
      },
      "source": [
        "image_path"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/fruit/test/banana_77.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}