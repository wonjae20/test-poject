{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "yolov3_training_furits (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae20/test-poject/blob/main/yolov3_training_furits_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpvZnHe4OeLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea1c7b3-1430-4f5a-bdff-c3c4f882e9ba"
      },
      "source": [
        "import os, sys \n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('./drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "os.chdir(r'/content/drive/MyDrive/fruit/train')\n",
        "path = r'/content/drive/MyDrive/fruit/train'\n",
        "\n",
        "def xml_to_txt(path):\n",
        "    txt_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        everyrow_xml_list = []\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        everyrow_xml_list.append(path + '/' + root.find('filename').text)\n",
        "        for member in root.findall('object'):\n",
        "            xmin = str(int(member[4][0].text))\n",
        "            ymin = str(int(member[4][1].text))\n",
        "            xmax = str(int(member[4][2].text))\n",
        "            ymax = str(int(member[4][3].text))\n",
        "            if xmin==\"0\":\n",
        "                xmin=\"1\"\n",
        "            if ymin==\"0\":\n",
        "                ymin=\"1\"\n",
        "            if xmax==\"0\":\n",
        "                xmax=\"1\"\n",
        "            if ymax==\"0\":\n",
        "                ymax=\"1\"\n",
        "            if member.find('name').text == 'apple':\n",
        "              obj_class = \"0\"\n",
        "            elif member.find('name').text == 'banana':\n",
        "              obj_class = \"1\"\n",
        "            elif member.find('name').text == 'orange':\n",
        "              obj_class = \"2\"\n",
        "            value = xmin+','+ymin+','+xmax+','+ymax+','+obj_class\n",
        "            everyrow_xml_list.append(value)\n",
        "        txt_list.append(everyrow_xml_list)#image_path x_min,y_min,x_max,y_max,class_id  x_min,y_min,x_max,y_max,class_id ……\n",
        "    return txt_list\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    image_path = path\n",
        "    xml2txt_list = xml_to_txt(image_path)\n",
        "    with open(r'/content/drive/MyDrive/fruit/train.txt', 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f,delimiter=' ')\n",
        "        writer.writerows(xml2txt_list)\n",
        "    print('Successfully converted xml to txt.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSBfkOaC4FxB",
        "outputId": "79302769-78ee-4084-9692-ed6dfdcf4692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "os.chdir(r'/content/drive/MyDrive/fruit/test')\n",
        "path = r'/content/drive/MyDrive/fruit/test'\n",
        "\n",
        "def xml_to_txt(path):\n",
        "    txt_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        everyrow_xml_list = []\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        everyrow_xml_list.append(path + '/' + root.find('filename').text)\n",
        "        for member in root.findall('object'):\n",
        "            xmin = str(int(member[4][0].text))\n",
        "            ymin = str(int(member[4][1].text))\n",
        "            xmax = str(int(member[4][2].text))\n",
        "            ymax = str(int(member[4][3].text))\n",
        "            if xmin==\"0\":\n",
        "                xmin=\"1\"\n",
        "            if ymin==\"0\":\n",
        "                ymin=\"1\"\n",
        "            if xmax==\"0\":\n",
        "                xmax=\"1\"\n",
        "            if ymax==\"0\":\n",
        "                ymax=\"1\"\n",
        "            if member.find('name').text == 'apple':\n",
        "              obj_class = \"0\"\n",
        "            elif member.find('name').text == 'banana':\n",
        "              obj_class = \"1\"\n",
        "            elif member.find('name').text == 'orange':\n",
        "              obj_class = \"2\"\n",
        "            value = xmin+','+ymin+','+xmax+','+ymax+','+obj_class\n",
        "            everyrow_xml_list.append(value)\n",
        "        txt_list.append(everyrow_xml_list)#image_path x_min,y_min,x_max,y_max,class_id  x_min,y_min,x_max,y_max,class_id ……\n",
        "    return txt_list\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    image_path = path\n",
        "    xml2txt_list = xml_to_txt(image_path)\n",
        "    with open(r'/content/drive/MyDrive/fruit/test.txt', 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f,delimiter=' ')\n",
        "        writer.writerows(xml2txt_list)\n",
        "    print('Successfully converted xml to txt.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SYCag8o4FnH",
        "outputId": "c1598c8c-58a6-4802-f6c3-40f97d7804ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "B0f4OjZhFxlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e1bf73-7b2c-4fcb-8daa-6925fa8b553c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_77.jpg  apple_89.jpg   banana_82.jpg  banana_94.jpg  orange_83.jpg\n",
            "apple_77.xml  apple_89.xml   banana_82.xml  banana_94.xml  orange_83.xml\n",
            "apple_78.jpg  apple_90.jpg   banana_83.jpg  mixed_21.jpg   orange_84.jpg\n",
            "apple_78.xml  apple_90.xml   banana_83.xml  mixed_21.xml   orange_84.xml\n",
            "apple_79.jpg  apple_91.jpg   banana_84.jpg  mixed_22.jpg   orange_85.jpg\n",
            "apple_79.xml  apple_91.xml   banana_84.xml  mixed_22.xml   orange_85.xml\n",
            "apple_80.jpg  apple_92.jpg   banana_85.jpg  mixed_23.jpg   orange_86.jpg\n",
            "apple_80.xml  apple_92.xml   banana_85.xml  mixed_23.xml   orange_86.xml\n",
            "apple_81.jpg  apple_93.jpg   banana_86.jpg  mixed_24.jpg   orange_87.jpg\n",
            "apple_81.xml  apple_93.xml   banana_86.xml  mixed_24.xml   orange_87.xml\n",
            "apple_82.jpg  apple_94.jpg   banana_87.jpg  mixed_25.jpg   orange_89.jpg\n",
            "apple_82.xml  apple_94.xml   banana_87.xml  mixed_25.xml   orange_89.xml\n",
            "apple_83.jpg  apple_95.jpg   banana_88.jpg  orange_77.jpg  orange_90.jpg\n",
            "apple_83.xml  apple_95.xml   banana_88.xml  orange_77.xml  orange_90.xml\n",
            "apple_84.jpg  banana_77.jpg  banana_89.jpg  orange_78.jpg  orange_91.jpg\n",
            "apple_84.xml  banana_77.xml  banana_89.xml  orange_78.xml  orange_91.xml\n",
            "apple_85.jpg  banana_78.jpg  banana_90.jpg  orange_79.jpg  orange_92.jpg\n",
            "apple_85.xml  banana_78.xml  banana_90.xml  orange_79.xml  orange_92.xml\n",
            "apple_86.jpg  banana_79.jpg  banana_91.jpg  orange_80.jpg  orange_93.jpg\n",
            "apple_86.xml  banana_79.xml  banana_91.xml  orange_80.xml  orange_93.xml\n",
            "apple_87.jpg  banana_80.jpg  banana_92.jpg  orange_81.jpg  orange_94.jpg\n",
            "apple_87.xml  banana_80.xml  banana_92.xml  orange_81.xml  orange_94.xml\n",
            "apple_88.jpg  banana_81.jpg  banana_93.jpg  orange_82.jpg  orange_95.jpg\n",
            "apple_88.xml  banana_81.xml  banana_93.xml  orange_82.xml  orange_95.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKw7HZG7LgtP",
        "outputId": "94a8f21f-e816-4f23-e2ca-8be4b3e85c6f"
      },
      "source": [
        "cd /content/content/My Drive/LSCV/project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/content/My Drive/LSCV/project'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0epuu1ng1Sp",
        "outputId": "ef674415-d87c-45df-ad49-7be760c0bb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_77.jpg  apple_89.jpg   banana_82.jpg  banana_94.jpg  orange_83.jpg\n",
            "apple_77.xml  apple_89.xml   banana_82.xml  banana_94.xml  orange_83.xml\n",
            "apple_78.jpg  apple_90.jpg   banana_83.jpg  mixed_21.jpg   orange_84.jpg\n",
            "apple_78.xml  apple_90.xml   banana_83.xml  mixed_21.xml   orange_84.xml\n",
            "apple_79.jpg  apple_91.jpg   banana_84.jpg  mixed_22.jpg   orange_85.jpg\n",
            "apple_79.xml  apple_91.xml   banana_84.xml  mixed_22.xml   orange_85.xml\n",
            "apple_80.jpg  apple_92.jpg   banana_85.jpg  mixed_23.jpg   orange_86.jpg\n",
            "apple_80.xml  apple_92.xml   banana_85.xml  mixed_23.xml   orange_86.xml\n",
            "apple_81.jpg  apple_93.jpg   banana_86.jpg  mixed_24.jpg   orange_87.jpg\n",
            "apple_81.xml  apple_93.xml   banana_86.xml  mixed_24.xml   orange_87.xml\n",
            "apple_82.jpg  apple_94.jpg   banana_87.jpg  mixed_25.jpg   orange_89.jpg\n",
            "apple_82.xml  apple_94.xml   banana_87.xml  mixed_25.xml   orange_89.xml\n",
            "apple_83.jpg  apple_95.jpg   banana_88.jpg  orange_77.jpg  orange_90.jpg\n",
            "apple_83.xml  apple_95.xml   banana_88.xml  orange_77.xml  orange_90.xml\n",
            "apple_84.jpg  banana_77.jpg  banana_89.jpg  orange_78.jpg  orange_91.jpg\n",
            "apple_84.xml  banana_77.xml  banana_89.xml  orange_78.xml  orange_91.xml\n",
            "apple_85.jpg  banana_78.jpg  banana_90.jpg  orange_79.jpg  orange_92.jpg\n",
            "apple_85.xml  banana_78.xml  banana_90.xml  orange_79.xml  orange_92.xml\n",
            "apple_86.jpg  banana_79.jpg  banana_91.jpg  orange_80.jpg  orange_93.jpg\n",
            "apple_86.xml  banana_79.xml  banana_91.xml  orange_80.xml  orange_93.xml\n",
            "apple_87.jpg  banana_80.jpg  banana_92.jpg  orange_81.jpg  orange_94.jpg\n",
            "apple_87.xml  banana_80.xml  banana_92.xml  orange_81.xml  orange_94.xml\n",
            "apple_88.jpg  banana_81.jpg  banana_93.jpg  orange_82.jpg  orange_95.jpg\n",
            "apple_88.xml  banana_81.xml  banana_93.xml  orange_82.xml  orange_95.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.19.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHTotNPCGdB5",
        "outputId": "03e4b933-cfc7-42a3-e1d2-16f34185fa53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.19.0 in /usr/local/lib/python3.7/dist-packages (1.19.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISd6eTgXQNd"
      },
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQzbsaxpXSVs"
      },
      "source": [
        "# YOLO options\n",
        "YOLO_DARKNET_WEIGHTS        = \"/model_data/yolov3.weights\"\n",
        "YOLO_COCO_CLASSES           = \"/model_data/coco.names\"\n",
        "YOLO_STRIDES                = [8, 16, 32]\n",
        "YOLO_IOU_LOSS_THRESH        = 0.5\n",
        "YOLO_ANCHOR_PER_SCALE       = 3\n",
        "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
        "YOLO_INPUT_SIZE             = 416\n",
        "YOLO_ANCHORS                = [[[10,  13], [16,   30], [33,   23]],\n",
        "                               [[30,  61], [62,   45], [59,  119]],\n",
        "                               [[116, 90], [156, 198], [373, 326]]]\n",
        "# Train options\n",
        "TRAIN_CLASSES               = \"/content/drive/MyDrive/fruits.names\"\n",
        "TRAIN_ANNOT_PATH            = \"/content/drive/MyDrive/train.txt\"\n",
        "TRAIN_BATCH_SIZE            = 4\n",
        "TRAIN_INPUT_SIZE            = 416\n",
        "TRAIN_DATA_AUG              = True\n",
        "TRAIN_TRANSFER              = False\n",
        "TRAIN_FROM_CHECKPOINT       = False #\"./checkpoints_furits/yolov3_custom\"\n",
        "\n",
        "TRAIN_LR_INIT               = 1e-4\n",
        "TRAIN_LR_END                = 1e-6\n",
        "TRAIN_WARMUP_EPOCHS         = 2\n",
        "TRAIN_EPOCHS                = 20\n",
        "\n",
        "# TEST options\n",
        "TEST_ANNOT_PATH             = \"/content/drive/MyDrive/test.txt\"\n",
        "TEST_BATCH_SIZE             = 4\n",
        "TEST_INPUT_SIZE             = 416\n",
        "TEST_DATA_AUG               = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KzpkCyp95zC"
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import colorsys\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8JMPV9_-m1M"
      },
      "source": [
        "utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raaIsjRk98PJ"
      },
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() # used to reset layer names\n",
        "    # load Darknet original weights to Keras model\n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(75):\n",
        "            if i > 0:\n",
        "                conv_layer_name = 'conv2d_%d' %i\n",
        "            else:\n",
        "                conv_layer_name = 'conv2d'\n",
        "                \n",
        "            if j > 0:\n",
        "                bn_layer_name = 'batch_normalization_%d' %j\n",
        "            else:\n",
        "                bn_layer_name = 'batch_normalization'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "            if i not in [58, 66, 74]:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBrLfn24-CaP"
      },
      "source": [
        "def read_class_names(class_file_name):\n",
        "    # loads class name from a file\n",
        "    #print(class_file_name)\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXTy87MuLlX0",
        "outputId": "0a352206-135d-4fd4-9718-05985aa874fc"
      },
      "source": [
        "read_class_names(TRAIN_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'apple', 1: 'banana', 2: 'orange'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IKBK700-EXF"
      },
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "    print(gt_boxes)\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDX_984L-F1Y"
      },
      "source": [
        "\n",
        "def draw_bbox(image, bboxes, CLASSES=TRAIN_CLASSES, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors=''):   \n",
        "    NUM_CLASS = read_class_names(CLASSES)\n",
        "    num_classes = len(NUM_CLASS)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    #print(\"hsv_tuples\", hsv_tuples)\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != ''else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        #print(image_h, image_w, bbox_thick)\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = f' {score:.2f}' if show_confidence else '' \n",
        "            label = f'{NUM_CLASS[class_ind]}' + score_str\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                                                                  fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY2vi4Fi-OsJ"
      },
      "source": [
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(float).eps)\n",
        "\n",
        "    return ious\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxduNYb6-QNh"
      },
      "source": [
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3):\n",
        "\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
        "        while len(cls_bboxes) > 0:\n",
        "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            # Process 3: Calculate this bounding box A and\n",
        "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=float)\n",
        "\n",
        "            iou_mask = iou > iou_threshold\n",
        "            weight[iou_mask] = 0.0\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcenMeqH-SeO"
      },
      "source": [
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "    #print(coors)\n",
        "\n",
        "    #print(coors[0])\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf91vRsKXTQd"
      },
      "source": [
        "def detect_image(YoloV3, image_path, output_path, input_size=416, show=False, CLASSES=TRAIN_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
        "    original_image      = cv2.imread(image_path)\n",
        "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    #original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "    image_data = tf.expand_dims(image_data, 0)\n",
        "\n",
        "    pred_bbox = YoloV3.predict(image_data)\n",
        "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "    \n",
        "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "    #xx=np.array(bboxes)\n",
        "    #print(xx.shape)\n",
        "\n",
        "    bboxes = nms(bboxes, iou_threshold)\n",
        "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
        "    #cv2.imwrite('./output.jpg', image)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWfbwjQ-fiU"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDDDzxjh-qmA"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "STRIDES         = np.array(YOLO_STRIDES)\n",
        "ANCHORS         = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
        "IOU_LOSS_THRESH = YOLO_IOU_LOSS_THRESH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMrWDDaDXaE_"
      },
      "source": [
        "class BatchNormalization(BatchNormalization):\n",
        "    # \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
        "    # `layer.trainable = False` is to freeze the layer, so the layer will use\n",
        "    # stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n",
        "    # and `beta` will not be updated !\n",
        "    def call(self, x, training=False):\n",
        "        if not training:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True):\n",
        "    if downsample:\n",
        "        input_layer = ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
        "                  padding=padding, use_bias=not bn, kernel_regularizer=l2(0.0005),\n",
        "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "    if bn:\n",
        "        conv = BatchNormalization()(conv)\n",
        "    if activate == True:\n",
        "        conv = LeakyReLU(alpha=0.1)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1))\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2))\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
        "\n",
        "\n",
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, (3, 3,  3,  32))\n",
        "    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64,  32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3,  64, 128), downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128,  64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data\n",
        "\n",
        "def YOLOv3(input_layer, NUM_CLASS):\n",
        "    # After the input layer enters the Darknet-53 network, we get three branches\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
        "    \n",
        "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
        "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1,  512,  256))\n",
        "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = convolutional(conv, (1, 1, 512, 256))\n",
        "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
        "\n",
        "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = convolutional(conv, (1, 1, 256, 128))\n",
        "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
        "    \n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def Create_Yolov3(input_size=416, channels=3, training=False, CLASSES=TRAIN_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    input_layer  = Input([input_size, input_size, channels])\n",
        "\n",
        "    conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
        "\n",
        "    output_tensors = []\n",
        "    for i, conv_tensor in enumerate(conv_tensors):\n",
        "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
        "        if training: output_tensors.append(conv_tensor)\n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    YoloV3 = tf.keras.Model(input_layer, output_tensors)\n",
        "    return YoloV3\n",
        "\n",
        "def decode(conv_output, NUM_CLASS, i=0):\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
        "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
        "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
        "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box \n",
        "\n",
        "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
        "    y = tf.range(output_size, dtype=tf.int32)\n",
        "    y = tf.expand_dims(y, -1)\n",
        "    y = tf.tile(y, [1, output_size])\n",
        "    x = tf.range(output_size,dtype=tf.int32)\n",
        "    x = tf.expand_dims(x, 0)\n",
        "    x = tf.tile(x, [output_size, 1])\n",
        "\n",
        "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "def bbox_iou(boxes1, boxes2):\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area\n",
        "\n",
        "def bbox_giou(boxes1, boxes2):\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "\n",
        "def compute_loss(pred, conv, label, bboxes, i=0, CLASSES=TRAIN_CLASSES):\n",
        "    NUM_CLASS = len(read_class_names(CLASSES))\n",
        "    conv_shape  = tf.shape(conv)\n",
        "    batch_size  = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "    input_size  = STRIDES[i] * output_size\n",
        "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
        "\n",
        "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
        "    pred_conf     = pred[:, :, :, :, 4:5]\n",
        "\n",
        "    label_xywh    = label[:, :, :, :, 0:4]\n",
        "    respond_bbox  = label[:, :, :, :, 4:5]\n",
        "    label_prob    = label[:, :, :, :, 5:]\n",
        "\n",
        "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
        "    input_size = tf.cast(input_size, tf.float32)\n",
        "\n",
        "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
        "    giou_loss = respond_bbox * bbox_loss_scale * (1- giou)\n",
        "\n",
        "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
        "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
        "\n",
        "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < IOU_LOSS_THRESH, tf.float32)\n",
        "\n",
        "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
        "\n",
        "    conf_loss = conf_focal * (\n",
        "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "            +\n",
        "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "    )\n",
        "\n",
        "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
        "\n",
        "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
        "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
        "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
        "\n",
        "    return giou_loss, conf_loss, prob_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoTCdT7V-isD"
      },
      "source": [
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9FsKyf7Xdfu"
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class Dataset(object):\n",
        "    # Dataset preprocess implementation\n",
        "    def __init__(self, dataset_type):\n",
        "        self.annot_path  = TRAIN_ANNOT_PATH if dataset_type == 'train' else TEST_ANNOT_PATH\n",
        "        self.input_sizes = TRAIN_INPUT_SIZE if dataset_type == 'train' else TEST_INPUT_SIZE\n",
        "        self.batch_size  = TRAIN_BATCH_SIZE if dataset_type == 'train' else TEST_BATCH_SIZE\n",
        "        self.data_aug    = TRAIN_DATA_AUG   if dataset_type == 'train' else TEST_DATA_AUG\n",
        "\n",
        "        self.train_input_sizes = TRAIN_INPUT_SIZE\n",
        "        self.strides = np.array(YOLO_STRIDES)\n",
        "        self.classes = read_class_names(TRAIN_CLASSES)\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
        "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
        "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
        "\n",
        "        self.annotations = self.load_annotations(dataset_type)\n",
        "        self.num_samples = len(self.annotations)\n",
        "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size))\n",
        "        self.batch_count = 0\n",
        "\n",
        "\n",
        "    def load_annotations(self, dataset_type):\n",
        "        final_annotations = []\n",
        "        with open(self.annot_path, 'r') as f:\n",
        "            txt = f.readlines()\n",
        "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
        "        np.random.shuffle(annotations)\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            # fully parse annotations\n",
        "            line = annotation.split()\n",
        "            image_path, index = \"\", 1\n",
        "            for i, one_line in enumerate(line):\n",
        "                if not one_line.replace(\",\",\"\").isnumeric():\n",
        "                    if image_path != \"\": image_path += \" \"\n",
        "                    image_path += one_line\n",
        "                else:\n",
        "                    index = i\n",
        "                    break\n",
        "            if not os.path.exists(image_path):\n",
        "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
        "\n",
        "            final_annotations.append([image_path, line[index:]])\n",
        "\n",
        "        return final_annotations\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with tf.device('/cpu:0'):\n",
        "            self.train_input_size = random.choice([self.train_input_sizes])\n",
        "            self.train_output_sizes = self.train_input_size // self.strides\n",
        "\n",
        "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
        "\n",
        "            batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "            batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2],\n",
        "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
        "\n",
        "            batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
        "\n",
        "            num = 0\n",
        "            if self.batch_count < self.num_batchs:\n",
        "                while num < self.batch_size:\n",
        "                    index = self.batch_count * self.batch_size + num\n",
        "                    if index >= self.num_samples: index -= self.num_samples\n",
        "                    annotation = self.annotations[index]\n",
        "                    image, bboxes = self.parse_annotation(annotation)\n",
        "                    label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
        "\n",
        "                    batch_image[num, :, :, :] = image\n",
        "                    batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
        "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
        "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
        "                    batch_sbboxes[num, :, :] = sbboxes\n",
        "                    batch_mbboxes[num, :, :] = mbboxes\n",
        "                    batch_lbboxes[num, :, :] = lbboxes\n",
        "                    num += 1\n",
        "                self.batch_count += 1\n",
        "                batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
        "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
        "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
        "\n",
        "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
        "            else:\n",
        "                self.batch_count = 0\n",
        "                np.random.shuffle(self.annotations)\n",
        "                raise StopIteration\n",
        "\n",
        "    def random_horizontal_flip(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            _, w, _ = image.shape\n",
        "            image = image[:, ::-1, :]\n",
        "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_crop(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
        "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
        "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
        "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
        "\n",
        "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def random_translate(self, image, bboxes):\n",
        "        if random.random() < 0.5:\n",
        "            h, w, _ = image.shape\n",
        "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
        "\n",
        "            max_l_trans = max_bbox[0]\n",
        "            max_u_trans = max_bbox[1]\n",
        "            max_r_trans = w - max_bbox[2]\n",
        "            max_d_trans = h - max_bbox[3]\n",
        "\n",
        "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
        "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
        "\n",
        "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
        "            image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
        "\n",
        "        return image, bboxes\n",
        "\n",
        "    def parse_annotation(self, annotation):\n",
        "\n",
        "        image_path = annotation[0]\n",
        "        image = cv2.imread(image_path)\n",
        "            \n",
        "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
        "\n",
        "        if self.data_aug:\n",
        "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
        "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image, bboxes = image_preprocess(np.copy(image), [self.train_input_size, self.train_input_size], np.copy(bboxes))\n",
        "        return image, bboxes\n",
        "\n",
        "    def preprocess_true_boxes(self, bboxes):\n",
        "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
        "                           5 + self.num_classes)) for i in range(3)]\n",
        "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(3)]\n",
        "        bbox_count = np.zeros((3,))\n",
        "\n",
        "        for bbox in bboxes:\n",
        "            bbox_coor = bbox[:4]\n",
        "            bbox_class_ind = bbox[4]\n",
        "\n",
        "            onehot = np.zeros(self.num_classes, dtype=np.float64)\n",
        "            onehot[bbox_class_ind] = 1.0\n",
        "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
        "            deta = 0.01\n",
        "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
        "\n",
        "            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
        "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n",
        "\n",
        "            iou = []\n",
        "            exist_positive = False\n",
        "            for i in range(3):\n",
        "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
        "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
        "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
        "\n",
        "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
        "                iou.append(iou_scale)\n",
        "                iou_mask = iou_scale > 0.3\n",
        "\n",
        "                if np.any(iou_mask):\n",
        "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
        "\n",
        "                    label[i][yind, xind, iou_mask, :] = 0\n",
        "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
        "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
        "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
        "\n",
        "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
        "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
        "                    bbox_count[i] += 1\n",
        "\n",
        "                    exist_positive = True\n",
        "\n",
        "            if not exist_positive:\n",
        "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
        "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
        "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
        "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
        "\n",
        "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
        "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
        "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
        "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
        "                \n",
        "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
        "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
        "                bbox_count[best_detect] += 1\n",
        "\n",
        "        label_sbbox, label_mbbox, label_lbbox = label\n",
        "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
        "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgvPlA8Ufp8f",
        "outputId": "fc302aef-fcc1-4286-8de4-60426a2bc354"
      },
      "source": [
        "trainset = Dataset('train')\n",
        "steps_per_epoch = len(trainset)\n",
        "\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIQuRMfmXpgX"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMp-XBHSXicX",
        "outputId": "5c8773ca-399e-4517-9875-51c1b7ab74ea"
      },
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "global TRAIN_FROM_CHECKPOINT\n",
        "input_size = YOLO_INPUT_SIZE\n",
        "Darknet_weights = YOLO_DARKNET_WEIGHTS\n",
        "\n",
        "\n",
        "save_best_only = True # saves only best model according validation loss\n",
        "save_checkpoints = False # saves all best validated checkpoints in training process (may require a lot disk space)\n",
        "\n",
        "\n",
        "trainset = Dataset('train')\n",
        "testset = Dataset('test')\n",
        "\n",
        "steps_per_epoch = len(trainset)\n",
        "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
        "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
        "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
        "\n",
        "if TRAIN_TRANSFER:\n",
        "    Darknet = Create_Yolov3(input_size=input_size)\n",
        "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
        "\n",
        "yolo = Create_Yolov3(input_size=input_size, training=True, CLASSES=TRAIN_CLASSES)\n",
        "\n",
        "#TRAIN_FROM_CHECKPOINT = False\n",
        "if TRAIN_FROM_CHECKPOINT:\n",
        "    yolo.load_weights(TRAIN_FROM_CHECKPOINT)\n",
        "\n",
        "## transfer && Not use checkpoint\n",
        "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
        "    for i, l in enumerate(Darknet.layers):\n",
        "        layer_weights = l.get_weights()\n",
        "        if layer_weights != []:\n",
        "            try:\n",
        "                yolo.layers[i].set_weights(layer_weights)\n",
        "            except:\n",
        "                print(\"skipping\", yolo.layers[i].name)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def train_step(image_data, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred_result = yolo(image_data, training=True)\n",
        "        giou_loss=conf_loss=prob_loss=0\n",
        "        # optimizing process\n",
        "        for i in range(3):\n",
        "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
        "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
        "            giou_loss += loss_items[0]\n",
        "            conf_loss += loss_items[1]\n",
        "            prob_loss += loss_items[2]\n",
        "        total_loss = giou_loss + conf_loss + prob_loss\n",
        "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
        "\n",
        "\n",
        "        # update learning rate\n",
        "        global_steps.assign_add(1)\n",
        "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
        "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
        "        else:\n",
        "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
        "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
        "        optimizer.lr.assign(lr.numpy())\n",
        "\n",
        "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
        "\n",
        "\n",
        "\n",
        "def validate_step(image_data, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred_result = yolo(image_data, training=False)\n",
        "        giou_loss=conf_loss=prob_loss=0\n",
        "\n",
        "        # optimizing process\n",
        "        for i in range(3):\n",
        "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
        "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
        "            giou_loss += loss_items[0]\n",
        "            conf_loss += loss_items[1]\n",
        "            prob_loss += loss_items[2]\n",
        "\n",
        "        total_loss = giou_loss + conf_loss + prob_loss\n",
        "        \n",
        "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
        "\n",
        "\n",
        "best_val_loss = 1000 # should be large at start\n",
        "\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    for image_data, target in trainset:\n",
        "        results = train_step(image_data, target)\n",
        "        cur_step = results[0]%steps_per_epoch\n",
        "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
        "                  .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
        "        \n",
        "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
        "    for image_data, target in testset:\n",
        "        results = validate_step(image_data, target)\n",
        "        count += 1\n",
        "        giou_val += results[0]\n",
        "        conf_val += results[1]\n",
        "        prob_val += results[2]\n",
        "        total_val += results[3]\n",
        "\n",
        "        \n",
        "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
        "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
        "\n",
        "    if save_best_only and best_val_loss > total_val/count: \n",
        "        yolo.save_weights(\"./chkpt_fruits/yolov3_custom\")\n",
        "        best_val_loss = total_val/count\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[[162 153 327 348   2]\n",
            " [320 148 513 371   0]\n",
            " [ 22 366 567 619   1]]\n",
            "[[ 35  14 353 318   1]]\n",
            "[[   5  773  812 1712    1]\n",
            " [ 167  722 1132 1400    1]\n",
            " [ 279  597 1177 1087    1]\n",
            " [ 233  410 1014  989    1]]\n",
            "epoch:12 step:   22/60, lr:0.000039, giou_loss:   4.25, conf_loss:  25.67, prob_loss:   7.59, total_loss:  37.52\n",
            "[[336  84 574 362   2]\n",
            " [ 58  74 314 345   2]]\n",
            "[[ 44  86 395 459   0]\n",
            " [361 110 768 541   0]]\n",
            "[[ 16  16 184 186   0]]\n",
            "[[136 242 400 555   2]\n",
            " [127  90 447 345   0]\n",
            " [202  26 751 328   1]]\n",
            "epoch:12 step:   23/60, lr:0.000039, giou_loss:   2.13, conf_loss:  23.42, prob_loss:   2.85, total_loss:  28.41\n",
            "[[ 32 144 435 552   2]]\n",
            "[[ 83  36 290 244   0]]\n",
            "[[556 177 835 458   2]\n",
            " [365  20 675 278   2]\n",
            " [318 267 651 504   2]]\n",
            "[[164 218 353 412   0]\n",
            " [236 131 401 316   0]\n",
            " [ 96 142 265 324   0]]\n",
            "epoch:12 step:   24/60, lr:0.000039, giou_loss:   2.81, conf_loss:  25.09, prob_loss:   4.29, total_loss:  32.19\n",
            "[[ 71  79 678 682   0]]\n",
            "[[ 25  42 275 297   0]]\n",
            "[[ 21  37 670 741   0]]\n",
            "[[ 47  52 379 381   2]]\n",
            "epoch:12 step:   25/60, lr:0.000038, giou_loss:   0.51, conf_loss:  20.87, prob_loss:   0.55, total_loss:  21.94\n",
            "[[  5 161 124 276   0]\n",
            " [145 181 276 306   0]\n",
            " [201  64 307 159   0]\n",
            " [268   1 403 105   0]\n",
            " [357  46 478 162   0]\n",
            " [261 104 375 211   0]]\n",
            "[[429 101 566 260   2]\n",
            " [439  26 575 165   2]\n",
            " [100  96 232 241   2]\n",
            " [ 58  31 207 161   2]\n",
            " [196  53 339 197   2]\n",
            " [263 105 414 247   2]\n",
            " [345  10 478 136   2]]\n",
            "[[188 288 672 764   0]\n",
            " [ 22  86 389 559   0]]\n",
            "[[ 80 261 385 567   0]\n",
            " [407 426 695 691   0]\n",
            " [323 290 606 545   0]]\n",
            "epoch:12 step:   26/60, lr:0.000038, giou_loss:   9.02, conf_loss:  35.98, prob_loss:  13.06, total_loss:  58.07\n",
            "[[ 94  49 357 337   0]\n",
            " [338  16 597 268   0]]\n",
            "[[ 25 403 374 771   2]\n",
            " [274 440 703 791   2]\n",
            " [506 380 850 723   2]\n",
            " [250 164 690 522   2]]\n",
            "[[  5   7 102 112   2]]\n",
            "[[ 16   6 248 176   1]\n",
            " [ 83  37 268 210   1]\n",
            " [148  50 298 240   1]\n",
            " [266  69 352 284   1]]\n",
            "epoch:12 step:   27/60, lr:0.000038, giou_loss:   4.05, conf_loss:  24.78, prob_loss:   4.77, total_loss:  33.60\n",
            "[[ 56  88 278 307   2]\n",
            " [213  73 413 295   2]]\n",
            "[[110 103 231 246   2]\n",
            " [104   0 210 114   2]\n",
            " [  8  61 138 186   2]\n",
            " [  8   1 118  69   2]\n",
            " [ 37 200 159 249   2]]\n",
            "[[ 18  58 246 291   2]]\n",
            "[[582 163 956 541   2]\n",
            " [157 134 814 348   1]\n",
            " [174 267 760 551   1]]\n",
            "epoch:12 step:   28/60, lr:0.000038, giou_loss:   3.60, conf_loss:  23.81, prob_loss:   9.77, total_loss:  37.18\n",
            "[[ 37  19 521 309   1]]\n",
            "[[ 534  106 1267  881    2]\n",
            " [   2   69  695  801    2]]\n",
            "[[  16    1 1589  624    1]]\n",
            "[[151  98 407 328   2]\n",
            " [ 20   0 235 186   2]\n",
            " [397  46 596 296   2]\n",
            " [201  24 413 208   2]\n",
            " [298 271 562 397   2]]\n",
            "epoch:12 step:   29/60, lr:0.000038, giou_loss:   2.88, conf_loss:  24.40, prob_loss:  13.74, total_loss:  41.03\n",
            "[[ 18   8 197 180   0]]\n",
            "[[ 68   8 337 272   0]]\n",
            "[[ 14  18 214 206   0]]\n",
            "[[ 41  66 619 578   2]]\n",
            "epoch:12 step:   30/60, lr:0.000038, giou_loss:   0.62, conf_loss:  21.46, prob_loss:   0.86, total_loss:  22.94\n",
            "[[ 84  71 446 398   2]]\n",
            "[[ 49  11 377 313   1]\n",
            " [ 95  88 493 345   1]\n",
            " [109   5 421 200   1]]\n",
            "[[205  24 708 270   1]]\n",
            "[[ 25  39 412 232   1]\n",
            " [496 111 645 273   1]\n",
            " [ 16 158 558 347   1]]\n",
            "epoch:12 step:   31/60, lr:0.000038, giou_loss:   2.23, conf_loss:  23.12, prob_loss:   5.24, total_loss:  30.58\n",
            "[[  3  14 285 259   0]]\n",
            "[[ 98 139 274 328   0]]\n",
            "[[ 11  43 592 448   1]\n",
            " [ 24 174 599 657   1]]\n",
            "[[ 282   59 1936  956    1]\n",
            " [   2  108 1515 1176    1]\n",
            " [ 399   33 1992  612    1]]\n",
            "epoch:12 step:   32/60, lr:0.000037, giou_loss:   1.38, conf_loss:  21.60, prob_loss:   2.48, total_loss:  25.47\n",
            "[[ 45  44 130 138   1]\n",
            " [ 62  73 195 153   1]\n",
            " [  1  70  47 142   1]\n",
            " [ 17  50  77 134   1]]\n",
            "[[ 55  91 509 547   2]]\n",
            "[[ 504  208 1266  943    2]]\n",
            "[[ 60  16 146 104   2]\n",
            " [ 36   3 114  94   2]]\n",
            "epoch:12 step:   33/60, lr:0.000037, giou_loss:   2.81, conf_loss:  23.24, prob_loss:   4.30, total_loss:  30.34\n",
            "[[121  88 332 284   2]\n",
            " [ 74 327 283 545   2]\n",
            " [251 407 463 606   2]\n",
            " [186 492 388 662   2]]\n",
            "[[165  86 269 193   2]]\n",
            "[[ 11  74 209 265   2]\n",
            " [175  51 344 224   2]]\n",
            "[[301  57 897 724   1]]\n",
            "epoch:12 step:   34/60, lr:0.000037, giou_loss:   2.88, conf_loss:  23.54, prob_loss:   7.11, total_loss:  33.53\n",
            "[[ 46  33 242 278   1]]\n",
            "[[  6  17 437 458   2]]\n",
            "[[ 17  23 511 270   1]\n",
            " [ 40  31 266 257   1]]\n",
            "[[580  13 876 285   1]\n",
            " [119  43 387 386   1]\n",
            " [202  61 491 405   1]\n",
            " [231 141 491 535   1]\n",
            " [445 128 615 554   1]\n",
            " [511 127 802 462   1]\n",
            " [465  42 838 323   1]]\n",
            "epoch:12 step:   35/60, lr:0.000037, giou_loss:   5.31, conf_loss:  27.32, prob_loss:   8.86, total_loss:  41.50\n",
            "[[ 41  74 586 591   2]]\n",
            "[[ 74  37 323 289   0]\n",
            " [291  22 571 295   0]]\n",
            "[[121   9 298 172   0]]\n",
            "[[233 137 442 358   2]\n",
            " [ 35  99 240 351   2]\n",
            " [145   1 364 171   2]]\n",
            "epoch:12 step:   36/60, lr:0.000037, giou_loss:   1.74, conf_loss:  21.41, prob_loss:   1.33, total_loss:  24.49\n",
            "[[ 46  55 343 342   0]]\n",
            "[[ 24   2 178 147   2]]\n",
            "[[  77  476 2533 4366    1]]\n",
            "[[322 151 634 439   2]\n",
            " [ 77 303 902 499   1]\n",
            " [ 49 422 892 630   1]]\n",
            "epoch:12 step:   37/60, lr:0.000037, giou_loss:   2.13, conf_loss:  22.20, prob_loss:   3.59, total_loss:  27.91\n",
            "[[ 80   1 267 203   2]]\n",
            "[[ 336  116 1442 1143    0]]\n",
            "[[  3 155  85 243   2]\n",
            " [ 70 152 143 227   2]\n",
            " [ 43  38 273 134   1]\n",
            " [190 173 284 264   0]]\n",
            "[[ 16   5 449 434   0]]\n",
            "epoch:12 step:   38/60, lr:0.000037, giou_loss:   1.90, conf_loss:  22.38, prob_loss:   4.32, total_loss:  28.59\n",
            "[[135  10 496 301   2]]\n",
            "[[249  31 611 396   0]]\n",
            "[[  24  247  641  867    2]\n",
            " [ 599  335 1187  939    2]]\n",
            "[[ 654   91 1079  500    2]]\n",
            "epoch:12 step:   39/60, lr:0.000036, giou_loss:   1.29, conf_loss:  19.97, prob_loss:   0.80, total_loss:  22.06\n",
            "[[ 40   2 544 529   0]]\n",
            "[[201  48 627 379   1]]\n",
            "[[  4   8 244 212   0]]\n",
            "[[ 67   1 430 348   0]]\n",
            "epoch:12 step:   40/60, lr:0.000036, giou_loss:   0.58, conf_loss:  20.25, prob_loss:   2.80, total_loss:  23.64\n",
            "[[132  69 274 214   0]\n",
            " [222 192 344 313   0]\n",
            " [185 308 337 432   0]\n",
            " [  4 178 170 335   0]\n",
            " [312  98 411 188   0]\n",
            " [380 245 454 320   0]\n",
            " [405  74 466 135   0]\n",
            " [398 149 463 216   0]]\n",
            "[[197  94 398 299   2]]\n",
            "[[ 283  189 1262 1184    0]]\n",
            "[[113 258 583 700   0]]\n",
            "epoch:12 step:   41/60, lr:0.000036, giou_loss:   5.33, conf_loss:  28.65, prob_loss:   8.21, total_loss:  42.20\n",
            "[[  77  230  841  572    1]\n",
            " [ 363  211 1013  754    1]\n",
            " [  37  187  793  485    1]]\n",
            "[[ 271  187 1125 1065    0]]\n",
            "[[ 43  49 301 297   2]\n",
            " [344  11 643 310   2]]\n",
            "[[303  68 772 402   0]\n",
            " [  2   3 474 402   0]]\n",
            "epoch:12 step:   42/60, lr:0.000036, giou_loss:   1.79, conf_loss:  20.49, prob_loss:   3.85, total_loss:  26.13\n",
            "[[132  17 254 140   2]\n",
            " [ 31  15 167 159   2]]\n",
            "[[ 163  294 1003 1130    2]]\n",
            "[[ 65  43 428 532   1]]\n",
            "[[255   1 562 299   2]]\n",
            "epoch:12 step:   43/60, lr:0.000036, giou_loss:   1.08, conf_loss:  20.30, prob_loss:   1.97, total_loss:  23.35\n",
            "[[397 213 961 793   0]\n",
            " [ 78 176 590 665   0]]\n",
            "[[ 10  29 250 273   2]\n",
            " [259  24 513 291   2]]\n",
            "[[125 196 295 374   0]\n",
            " [197 144 363 328   0]]\n",
            "[[ 50  73 456 492   0]]\n",
            "epoch:12 step:   44/60, lr:0.000036, giou_loss:   1.64, conf_loss:  21.41, prob_loss:   3.10, total_loss:  26.15\n",
            "[[106 104 247 345   1]\n",
            " [238  93 322 354   1]\n",
            " [328 110 401 349   1]\n",
            " [404 117 499 354   1]]\n",
            "[[ 11  55 913 533   1]]\n",
            "[[ 600  381 1226 1519    1]]\n",
            "[[170  17 481 288   1]\n",
            " [144  77 405 365   1]]\n",
            "epoch:12 step:   45/60, lr:0.000036, giou_loss:   5.02, conf_loss:  25.14, prob_loss:   8.60, total_loss:  38.76\n",
            "[[ 98   2 760 705   2]]\n",
            "[[  1  60 294 176   1]]\n",
            "[[ 99 156 323 387   1]\n",
            " [219 182 592 368   1]\n",
            " [184 107 559 255   1]]\n",
            "[[ 32  39 210 217   2]\n",
            " [235  53 403 196   0]\n",
            " [ 32 270 344 394   1]]\n",
            "epoch:12 step:   46/60, lr:0.000035, giou_loss:   2.50, conf_loss:  21.63, prob_loss:   2.12, total_loss:  26.25\n",
            "[[160  37 496 400   2]]\n",
            "[[  2  36 428 250   1]]\n",
            "[[123  58 546 387   1]]\n",
            "[[  44  387  422  798    2]\n",
            " [ 348   66 1070  494    1]\n",
            " [ 378  198 1048  816    1]]\n",
            "epoch:12 step:   47/60, lr:0.000035, giou_loss:   1.47, conf_loss:  20.83, prob_loss:   1.31, total_loss:  23.61\n",
            "[[  8   3 347 205   1]]\n",
            "[[236 162 692 648   2]]\n",
            "[[ 73  53 389 346   1]\n",
            " [166  45 538 220   1]\n",
            " [153  41 519 300   1]\n",
            " [185  47 528 251   1]]\n",
            "[[ 10  10 266 266   0]]\n",
            "epoch:12 step:   48/60, lr:0.000035, giou_loss:   1.14, conf_loss:  20.60, prob_loss:   0.71, total_loss:  22.44\n",
            "[[ 53  28 488 470   0]]\n",
            "[[ 318  170 1425  925    1]\n",
            " [  21  589 1292 1270    1]\n",
            " [ 619    3 1594  613    1]\n",
            " [ 874    3 1738  552    1]]\n",
            "[[215 181 406 370   2]\n",
            " [328 173 488 351   2]]\n",
            "[[ 211    2 1253  493    1]\n",
            " [  95    5 1038  532    1]]\n",
            "epoch:12 step:   49/60, lr:0.000035, giou_loss:   2.53, conf_loss:  22.94, prob_loss:   3.17, total_loss:  28.63\n",
            "[[ 54   1 180 141   0]]\n",
            "[[342  83 701 416   1]\n",
            " [176  39 614 382   1]\n",
            " [130   8 595 226   1]]\n",
            "[[ 26  56 222 239   0]]\n",
            "[[ 461   13 1774 1080    1]]\n",
            "epoch:12 step:   50/60, lr:0.000035, giou_loss:   1.37, conf_loss:  20.15, prob_loss:   2.53, total_loss:  24.05\n",
            "[[ 63  13 283 214   0]\n",
            " [ 28 205 246 441   0]\n",
            " [176 165 375 399   0]\n",
            " [598 286 780 501   0]\n",
            " [491 358 668 555   0]\n",
            " [326 227 567 451   0]\n",
            " [184 338 366 531   0]\n",
            " [436 413 648 586   0]]\n",
            "[[ 34 247 198 397   2]\n",
            " [ 60  29 251 225   0]\n",
            " [241  24 367 411   1]\n",
            " [283 142 547 470   1]\n",
            " [294  23 448 400   1]]\n",
            "[[ 26 108 318 224   1]]\n",
            "[[ 292   43  715  469    2]\n",
            " [ 547  127 1027  611    0]\n",
            " [  28  215  917  764    1]]\n",
            "epoch:12 step:   51/60, lr:0.000035, giou_loss:   8.42, conf_loss:  32.09, prob_loss:  12.27, total_loss:  52.78\n",
            "[[179  38 414 282   0]]\n",
            "[[ 25  46 575 598   0]\n",
            " [417  52 858 520   0]\n",
            " [654  62 931 461   0]]\n",
            "[[  71  119 1428 1439    0]]\n",
            "[[ 48  31 940 518   1]]\n",
            "epoch:12 step:   52/60, lr:0.000035, giou_loss:   1.43, conf_loss:  20.82, prob_loss:   4.87, total_loss:  27.11\n",
            "[[ 10  54 207 824   1]]\n",
            "[[116  26 380 298   2]]\n",
            "[[1261  157 2726 1731    2]]\n",
            "[[  1   5 194 207   0]]\n",
            "epoch:12 step:   53/60, lr:0.000035, giou_loss:   0.85, conf_loss:  19.78, prob_loss:   1.09, total_loss:  21.72\n",
            "[[ 87  60 523 297   1]]\n",
            "[[530  86 832 400   0]\n",
            " [133 172 412 425   0]\n",
            " [442 233 719 475   0]\n",
            " [ 32 146 272 414   0]]\n",
            "[[126  22 267 179   0]\n",
            " [ 25  17 127 126   0]\n",
            " [ 65  85 176 194   0]]\n",
            "[[ 518  114 1090 1114    1]]\n",
            "epoch:12 step:   54/60, lr:0.000034, giou_loss:   3.13, conf_loss:  22.93, prob_loss:   4.41, total_loss:  30.47\n",
            "[[149 138 537 313   1]]\n",
            "[[  5  21 253 277   2]]\n",
            "[[ 96 275 272 445   0]\n",
            " [264 282 431 434   0]\n",
            " [ 39 270 193 410   0]\n",
            " [463 225 597 373   0]]\n",
            "[[ 156  151  844  671    1]\n",
            " [ 582  151 1011  671    1]]\n",
            "epoch:12 step:   55/60, lr:0.000034, giou_loss:   2.80, conf_loss:  23.40, prob_loss:   1.99, total_loss:  28.19\n",
            "[[324 291 692 680   2]]\n",
            "[[525  23 948 430   2]\n",
            " [ 97 120 481 547   2]\n",
            " [ 57 506 537 938   2]]\n",
            "[[  1 129 532 634   2]]\n",
            "[[  9  19 533 377   1]]\n",
            "epoch:12 step:   56/60, lr:0.000034, giou_loss:   2.23, conf_loss:  22.38, prob_loss:   5.27, total_loss:  29.88\n",
            "[[ 17  11 574 245   1]]\n",
            "[[ 54  14 447 416   2]]\n",
            "[[ 45  72 547 275   1]]\n",
            "[[154  19 574 395   2]\n",
            " [ 27 272 974 574   1]\n",
            " [530  60 899 372   0]]\n",
            "epoch:12 step:   57/60, lr:0.000034, giou_loss:   1.62, conf_loss:  20.04, prob_loss:   1.57, total_loss:  23.23\n",
            "[[ 13   8 265 267   2]]\n",
            "[[ 19  53 229 315   1]]\n",
            "[[130 159 342 364   2]]\n",
            "[[194  97 706 654   0]]\n",
            "epoch:12 step:   58/60, lr:0.000034, giou_loss:   0.73, conf_loss:  19.84, prob_loss:   0.86, total_loss:  21.43\n",
            "[[379  89 549 377   1]\n",
            " [223 112 335 428   1]\n",
            " [152  72 303 329   1]\n",
            " [320 125 431 442   1]]\n",
            "[[ 69  26 467 441   0]]\n",
            "[[  60   85 2792 2568    1]]\n",
            "[[ 22 134 246 376   2]]\n",
            "epoch:12 step:   59/60, lr:0.000034, giou_loss:   3.44, conf_loss:  22.28, prob_loss:   3.32, total_loss:  29.04\n",
            "[[ 15   5 334 117   1]]\n",
            "[[233 103 406 275   2]\n",
            " [  5 109 290 392   1]\n",
            " [ 83  21 247 182   0]]\n",
            "[[ 470  160  992  494    1]\n",
            " [ 628    0 1169  297    1]\n",
            " [   1    2  412  343    1]\n",
            " [   1  248  260  668    1]\n",
            " [ 229  448  710  673    1]\n",
            " [ 822  479 1198  673    1]]\n",
            "[[ 20  83 533 595   2]]\n",
            "epoch:12 step:    0/60, lr:0.000034, giou_loss:   4.27, conf_loss:  24.65, prob_loss:   6.35, total_loss:  35.27\n",
            "[[ 29   6 303 273   2]]\n",
            "[[125 104 405 405   2]]\n",
            "[[ 30  85 486 454   2]]\n",
            "[[ 23  33 272 265   2]]\n",
            "epoch:12 step:    1/60, lr:0.000033, giou_loss:   0.74, conf_loss:  19.52, prob_loss:   3.67, total_loss:  23.94\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[227  62 723 500   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[155 105 453 436   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[111  51 372 277   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "\n",
            "\n",
            "giou_val_loss:   2.89, conf_val_loss:  23.86, prob_val_loss:   5.03, total_val_loss:  31.78\n",
            "\n",
            "\n",
            "[[ 20   1 825 214   1]]\n",
            "[[ 73  97 471 512   0]]\n",
            "[[ 49  22 482 451   0]]\n",
            "[[  4   9 151 153   0]]\n",
            "epoch:13 step:    2/60, lr:0.000033, giou_loss:   0.65, conf_loss:  20.13, prob_loss:   1.56, total_loss:  22.34\n",
            "[[319  51 582 339   0]\n",
            " [ 79  18 338 270   0]]\n",
            "[[ 444  101 1123  849    0]]\n",
            "[[  5  31 287 276   0]]\n",
            "[[ 16   6 314 294   0]]\n",
            "epoch:13 step:    3/60, lr:0.000033, giou_loss:   1.13, conf_loss:  20.67, prob_loss:   3.54, total_loss:  25.34\n",
            "[[ 49   2 269 203   0]\n",
            " [ 14 194 232 430   0]\n",
            " [162 154 361 388   0]\n",
            " [584 275 766 490   0]\n",
            " [477 347 654 544   0]\n",
            " [312 216 553 440   0]\n",
            " [170 327 352 520   0]\n",
            " [422 402 634 575   0]]\n",
            "[[  6  22 199 224   0]]\n",
            "[[337  83 579 338   2]\n",
            " [134 148 360 404   0]\n",
            " [173 228 746 528   1]]\n",
            "[[205 196 375 374   0]\n",
            " [137 144 303 328   0]]\n",
            "epoch:13 step:    4/60, lr:0.000033, giou_loss:   5.63, conf_loss:  28.81, prob_loss:   5.52, total_loss:  39.96\n",
            "[[ 43  21 350 353   0]]\n",
            "[[320  14 898 526   2]]\n",
            "[[  5  15 202 785   1]]\n",
            "[[ 96 257 498 346   1]\n",
            " [103 265 499 417   1]\n",
            " [112 301 509 510   1]\n",
            " [235 321 586 592   1]]\n",
            "epoch:13 step:    5/60, lr:0.000033, giou_loss:   2.28, conf_loss:  19.97, prob_loss:   1.39, total_loss:  23.64\n",
            "[[584 438 867 708   0]\n",
            " [492 141 740 394   0]\n",
            " [176 199 490 466   0]\n",
            " [367  17 619 240   0]\n",
            " [642  35 907 269   0]]\n",
            "[[ 126  560  760 1560    1]\n",
            " [ 542  381 1067 1439    1]]\n",
            "[[114  58 338 289   1]\n",
            " [234  84 607 270   1]\n",
            " [199   9 574 157   1]]\n",
            "[[329 265 936 868   0]]\n",
            "epoch:13 step:    6/60, lr:0.000033, giou_loss:   4.34, conf_loss:  26.21, prob_loss:   6.21, total_loss:  36.76\n",
            "[[222  11 922 718   0]]\n",
            "[[171  79 372 284   2]]\n",
            "[[309  66 778 400   0]\n",
            " [  8   1 480 400   0]]\n",
            "[[ 87  49 571 339   1]]\n",
            "epoch:13 step:    7/60, lr:0.000033, giou_loss:   1.14, conf_loss:  19.77, prob_loss:   2.13, total_loss:  23.04\n",
            "[[ 13 152 432 346   1]\n",
            " [104  89 426 226   1]\n",
            " [110  34 385 169   1]]\n",
            "[[ 39  57 222 247   2]]\n",
            "[[ 35 170 154 285   0]\n",
            " [175 190 306 315   0]\n",
            " [231  73 337 168   0]\n",
            " [298  10 433 114   0]\n",
            " [387  55 508 171   0]\n",
            " [291 113 405 220   0]]\n",
            "[[ 43 135 219 324   0]]\n",
            "epoch:13 step:    8/60, lr:0.000032, giou_loss:   5.31, conf_loss:  25.88, prob_loss:   4.08, total_loss:  35.27\n",
            "[[ 42  19 370 321   1]\n",
            " [ 88  96 486 353   1]\n",
            " [102  13 414 208   1]]\n",
            "[[313  33 778 489   2]]\n",
            "[[ 49 213 613 793   0]\n",
            " [420 176 932 665   0]]\n",
            "[[ 70  53 305 297   0]]\n",
            "epoch:13 step:    9/60, lr:0.000032, giou_loss:   1.15, conf_loss:  20.61, prob_loss:   0.90, total_loss:  22.66\n",
            "[[319  66 559 310   2]\n",
            " [ 56  61 310 328   2]]\n",
            "[[ 57  56 183 196   0]]\n",
            "[[ 551   58 1284  833    2]\n",
            " [  19   21  712  753    2]]\n",
            "[[220  27 536 320   1]\n",
            " [ 71  19 443 194   1]\n",
            " [ 90  15 456 274   1]\n",
            " [ 81  21 424 225   1]]\n",
            "epoch:13 step:   10/60, lr:0.000032, giou_loss:   2.23, conf_loss:  21.15, prob_loss:   2.58, total_loss:  25.95\n",
            "[[  1  72 427 286   1]]\n",
            "[[ 11  43 267 299   0]]\n",
            "[[254 231 617 720   1]]\n",
            "[[ 203  325 1174 1109    1]\n",
            " [ 516  384 1140  983    0]]\n",
            "epoch:13 step:   11/60, lr:0.000032, giou_loss:   0.93, conf_loss:  19.66, prob_loss:   1.33, total_loss:  21.92\n",
            "[[ 283  189 1262 1184    0]]\n",
            "[[ 38  43 339 363   2]]\n",
            "[[  25  231 2757 2714    1]]\n",
            "[[219   4 483 276   2]]\n",
            "epoch:13 step:   12/60, lr:0.000032, giou_loss:   0.63, conf_loss:  19.90, prob_loss:   2.25, total_loss:  22.78\n",
            "[[ 17  57 421 201   1]]\n",
            "[[ 12  39 471 289   1]]\n",
            "[[ 63  48 273 310   1]]\n",
            "[[ 81 143 292 339   2]\n",
            " [ 34 382 243 600   2]\n",
            " [211 462 423 661   2]\n",
            " [146 547 348 717   2]]\n",
            "epoch:13 step:   13/60, lr:0.000032, giou_loss:   2.42, conf_loss:  22.02, prob_loss:   9.19, total_loss:  33.62\n",
            "[[ 436  278 1039  889    2]]\n",
            "[[ 34  26 267 245   2]]\n",
            "[[ 28  10 197 118   1]]\n",
            "[[ 24   5 335 276   1]\n",
            " [100  65 361 353   1]]\n",
            "epoch:13 step:   14/60, lr:0.000032, giou_loss:   0.93, conf_loss:  19.66, prob_loss:   0.73, total_loss:  21.31\n",
            "[[  62  394 1527 1968    2]]\n",
            "[[ 54  72 604 624   0]\n",
            " [446  78 887 546   0]\n",
            " [683  88 960 487   0]]\n",
            "[[255   1 562 299   2]]\n",
            "[[144 136 470 411   0]]\n",
            "epoch:13 step:   15/60, lr:0.000032, giou_loss:   1.47, conf_loss:  20.62, prob_loss:   1.09, total_loss:  23.18\n",
            "[[ 27  15 558 520   2]]\n",
            "[[132  61 229 166   2]]\n",
            "[[ 34  70 683 774   0]]\n",
            "[[470  47 844 425   2]\n",
            " [ 45  18 702 232   1]\n",
            " [ 62 151 648 435   1]]\n",
            "epoch:13 step:   16/60, lr:0.000031, giou_loss:   1.56, conf_loss:  20.62, prob_loss:   3.03, total_loss:  25.21\n",
            "[[120  45 481 336   2]]\n",
            "[[ 18  15 195 178   0]]\n",
            "[[  31  161 1073  652    1]\n",
            " [ 246  164 1189  691    1]]\n",
            "[[ 757  348 1135  759    2]\n",
            " [ 109   27  831  455    1]\n",
            " [ 131  159  801  777    1]]\n",
            "epoch:13 step:   17/60, lr:0.000031, giou_loss:   1.68, conf_loss:  20.02, prob_loss:   1.10, total_loss:  22.80\n",
            "[[255  23 642 216   1]\n",
            " [ 22  95 171 257   1]\n",
            " [109 142 651 331   1]]\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "[[  57  211 1711 1108    1]\n",
            " [ 478  260 1991 1328    1]\n",
            " [   1  185 1594  764    1]]\n",
            "[[ 55  55 461 474   0]]\n",
            "epoch:13 step:   18/60, lr:0.000031, giou_loss:   3.37, conf_loss:  22.44, prob_loss:   3.37, total_loss:  29.17\n",
            "[[ 43 128 714 385   1]]\n",
            "[[ 71  46 390 158   1]]\n",
            "[[ 74  58 497 387   1]]\n",
            "[[136  22 258 145   2]\n",
            " [ 35  20 171 164   2]]\n",
            "epoch:13 step:   19/60, lr:0.000031, giou_loss:   1.42, conf_loss:  19.22, prob_loss:   0.68, total_loss:  21.31\n",
            "[[371  51 617 276   0]\n",
            " [159  48 346 298   0]\n",
            " [274  23 495 238   0]]\n",
            "[[ 58   4 243  96   1]\n",
            " [246   3 430  97   1]]\n",
            "[[160   6 306 149   2]\n",
            " [ 11 148 317 230   1]\n",
            " [ 19   1 156 146   0]]\n",
            "[[ 71   1 250 173   0]]\n",
            "epoch:13 step:   20/60, lr:0.000031, giou_loss:   3.97, conf_loss:  23.73, prob_loss:   8.15, total_loss:  35.85\n",
            "[[ 592  207 1015  614    2]\n",
            " [ 164  304  548  731    2]\n",
            " [ 124  690  604 1122    2]]\n",
            "[[ 60   2 242 213   0]]\n",
            "[[377  20 689 308   2]\n",
            " [132 172 957 368   1]\n",
            " [104 291 947 499   1]]\n",
            "[[ 12  39 330 343   1]]\n",
            "epoch:13 step:   21/60, lr:0.000031, giou_loss:   3.71, conf_loss:  23.55, prob_loss:   6.30, total_loss:  33.56\n",
            "[[237   6 818 411   1]\n",
            " [230 137 805 620   1]]\n",
            "[[ 831  117 1210  466    0]]\n",
            "[[389  82 740 455   0]\n",
            " [ 16 106 423 537   0]]\n",
            "[[494 170 888 551   2]\n",
            " [ 11 156 412 542   0]\n",
            " [115 596 796 958   1]]\n",
            "epoch:13 step:   22/60, lr:0.000031, giou_loss:   1.60, conf_loss:  19.49, prob_loss:   1.88, total_loss:  22.98\n",
            "[[ 10  37 189 207   2]]\n",
            "[[171 229 859 749   1]\n",
            " [  4 229 433 749   1]]\n",
            "[[  1  53 294 169   1]]\n",
            "[[ 248  368 1649 1759    2]]\n",
            "epoch:13 step:   23/60, lr:0.000030, giou_loss:   1.19, conf_loss:  19.56, prob_loss:   4.92, total_loss:  25.67\n",
            "[[322  82 492 370   1]\n",
            " [166 105 278 421   1]\n",
            " [ 95  65 246 322   1]\n",
            " [263 118 374 435   1]]\n",
            "[[154   4 678 362   1]]\n",
            "[[ 75  96 531 465   2]]\n",
            "[[ 45  40 539 287   1]\n",
            " [ 68  48 294 274   1]]\n",
            "epoch:13 step:   24/60, lr:0.000030, giou_loss:   4.13, conf_loss:  22.80, prob_loss:   7.48, total_loss:  34.41\n",
            "[[ 15  82 894 968   2]]\n",
            "[[133  29 274 186   0]\n",
            " [ 32  24 134 133   0]\n",
            " [ 72  92 183 201   0]]\n",
            "[[ 16   2 339 336   0]]\n",
            "[[ 10  71 413 479   2]]\n",
            "epoch:13 step:   25/60, lr:0.000030, giou_loss:   1.11, conf_loss:  19.69, prob_loss:   1.40, total_loss:  22.20\n",
            "[[168  36 601 361   1]\n",
            " [316  51 690 413   1]\n",
            " [110  22 549 267   1]]\n",
            "[[ 50  10 386 373   2]]\n",
            "[[253 226 678 635   2]]\n",
            "[[181  72 477 390   0]]\n",
            "epoch:13 step:   26/60, lr:0.000030, giou_loss:   1.50, conf_loss:  19.59, prob_loss:   1.85, total_loss:  22.94\n",
            "[[398 250 662 563   2]\n",
            " [351  98 671 353   0]\n",
            " [ 47  34 596 336   1]]\n",
            "[[ 31 232 243 437   2]]\n",
            "[[  26  231  760  952    2]\n",
            " [ 606  155 1294  817    2]]\n",
            "[[178 209 942 551   1]\n",
            " [  6 190 656 733   1]\n",
            " [226 166 982 464   1]]\n",
            "epoch:13 step:   27/60, lr:0.000030, giou_loss:   2.19, conf_loss:  20.95, prob_loss:   6.52, total_loss:  29.65\n",
            "[[ 496  168 1603  923    1]\n",
            " [ 199  587 1470 1268    1]\n",
            " [ 797    1 1772  611    1]\n",
            " [1052    1 1916  550    1]]\n",
            "[[ 749  131 1321 1131    1]]\n",
            "[[  40  324 2496 4214    1]]\n",
            "[[ 33  19 369 389   2]\n",
            " [387   8 716 330   2]]\n",
            "epoch:13 step:   28/60, lr:0.000030, giou_loss:   2.76, conf_loss:  22.44, prob_loss:   7.36, total_loss:  32.56\n",
            "[[318 146 680 511   0]]\n",
            "[[190  12 422 182   1]\n",
            " [170  43 355 216   1]\n",
            " [140  56 290 246   1]\n",
            " [ 86  75 172 290   1]]\n",
            "[[103  57 699 724   1]]\n",
            "[[379 129 516 288   2]\n",
            " [389  54 525 193   2]\n",
            " [ 50 124 182 269   2]\n",
            " [  8  59 157 189   2]\n",
            " [146  81 289 225   2]\n",
            " [213 133 364 275   2]\n",
            " [295  38 428 164   2]]\n",
            "epoch:13 step:   29/60, lr:0.000030, giou_loss:   6.64, conf_loss:  28.29, prob_loss:   7.04, total_loss:  41.97\n",
            "[[ 40  45 268 278   2]]\n",
            "[[178  25 376 216   2]\n",
            " [ 43   2 212 175   2]]\n",
            "[[167  83 603 320   1]]\n",
            "[[ 14  27 214 215   0]]\n",
            "epoch:13 step:   30/60, lr:0.000030, giou_loss:   0.86, conf_loss:  19.15, prob_loss:   1.40, total_loss:  21.41\n",
            "[[ 15  33 302 319   0]]\n",
            "[[  6 144 270 396   2]\n",
            " [712 165 983 432   2]\n",
            " [522 110 775 337   2]\n",
            " [262 144 496 352   2]]\n",
            "[[ 86  40 416 372   2]]\n",
            "[[150  38 455 344   0]\n",
            " [477 203 765 468   0]\n",
            " [393  67 676 322   0]]\n",
            "epoch:13 step:   31/60, lr:0.000029, giou_loss:   3.57, conf_loss:  23.48, prob_loss:   8.06, total_loss:  35.11\n",
            "[[ 66   1 151  95   1]\n",
            " [  1  30 134 110   1]\n",
            " [149  27 195  99   1]\n",
            " [119   7 179  91   1]]\n",
            "[[ 65  43 345 344   2]]\n",
            "[[ 65  18 252 220   2]]\n",
            "[[275 234 643 623   2]]\n",
            "epoch:13 step:   32/60, lr:0.000029, giou_loss:   1.96, conf_loss:  20.45, prob_loss:   5.55, total_loss:  27.96\n",
            "[[131 150 298 327   0]\n",
            " [265 142 442 299   0]\n",
            " [205  51 384 220   0]]\n",
            "[[  36   52 1393 1372    0]]\n",
            "[[ 37 252 594 486   1]]\n",
            "[[368 109 706 470   2]\n",
            " [ 58  69 410 432   2]]\n",
            "epoch:13 step:   33/60, lr:0.000029, giou_loss:   1.79, conf_loss:  20.32, prob_loss:   1.32, total_loss:  23.43\n",
            "[[ 69 166 315 427   2]]\n",
            "[[ 600  381 1226 1519    1]]\n",
            "[[  9  13 444 455   0]]\n",
            "[[ 16   8 171 155   0]]\n",
            "epoch:13 step:   34/60, lr:0.000029, giou_loss:   1.16, conf_loss:  19.43, prob_loss:   2.48, total_loss:  23.06\n",
            "[[ 228  259  577  627    2]\n",
            " [ 477  296  906  647    2]\n",
            " [ 709  236 1053  579    2]\n",
            " [ 453   20  893  378    2]]\n",
            "[[ 710  436  989  717    2]\n",
            " [ 870  279 1180  537    2]\n",
            " [ 894  526 1227  763    2]]\n",
            "[[ 51  25 303 284   2]]\n",
            "[[ 27  18 655 192   1]\n",
            " [ 13 106 600 416   1]\n",
            " [  0  14 441 308   1]]\n",
            "epoch:13 step:   35/60, lr:0.000029, giou_loss:   4.78, conf_loss:  25.73, prob_loss:   7.33, total_loss:  37.84\n",
            "[[ 16  42 184 212   0]]\n",
            "[[ 25  20 481 506   2]]\n",
            "[[ 40  99 463 521   0]\n",
            " [308  41 632 367   0]]\n",
            "[[ 350    1 1923  624    1]]\n",
            "epoch:13 step:   36/60, lr:0.000029, giou_loss:   0.89, conf_loss:  19.35, prob_loss:   1.94, total_loss:  22.18\n",
            "[[ 23 103 245 322   2]\n",
            " [180  88 380 310   2]]\n",
            "[[  1  85 174 257   2]\n",
            " [117  91 402 374   1]\n",
            " [160   3 324 164   0]]\n",
            "[[ 292   43  715  469    2]\n",
            " [ 547  127 1027  611    0]\n",
            " [  28  215  917  764    1]]\n",
            "[[ 207  160  729  494    1]\n",
            " [  30    0  571  297    1]\n",
            " [ 787    2 1198  343    1]\n",
            " [ 939  248 1198  668    1]\n",
            " [ 489  448  970  673    1]\n",
            " [   1  479  377  673    1]]\n",
            "epoch:13 step:   37/60, lr:0.000029, giou_loss:   4.93, conf_loss:  25.21, prob_loss:   8.78, total_loss:  38.91\n",
            "[[  87  151  941 1029    0]]\n",
            "[[274  49 439 244   2]\n",
            " [ 88  44 281 267   0]\n",
            " [ 34 262 579 515   1]]\n",
            "[[151  72 544 474   2]]\n",
            "[[111  44 499 219   1]]\n",
            "epoch:13 step:   38/60, lr:0.000029, giou_loss:   1.32, conf_loss:  19.50, prob_loss:   2.38, total_loss:  23.20\n",
            "[[ 87 137 325 415   2]\n",
            " [347 127 603 398   2]]\n",
            "[[ 76 108 495 506   2]\n",
            " [496  34 751 275   2]]\n",
            "[[  8  53 300 169   1]]\n",
            "[[ 71  21 559 328   1]]\n",
            "epoch:13 step:   39/60, lr:0.000028, giou_loss:   1.74, conf_loss:  20.24, prob_loss:   3.15, total_loss:  25.12\n",
            "[[  19  135 1199  601    1]]\n",
            "[[ 68   8 581 520   2]]\n",
            "[[233 137 442 358   2]\n",
            " [ 35  99 240 351   2]\n",
            " [145   1 364 171   2]]\n",
            "[[ 604  403 1149  920    2]]\n",
            "epoch:13 step:   40/60, lr:0.000028, giou_loss:   1.40, conf_loss:  19.08, prob_loss:   1.68, total_loss:  22.17\n",
            "[[ 94  21 318 263   2]]\n",
            "[[ 146   13 1459 1080    1]]\n",
            "[[ 61 178 481 620   0]]\n",
            "[[ 46  55 343 342   0]]\n",
            "epoch:13 step:   41/60, lr:0.000028, giou_loss:   0.75, conf_loss:  18.76, prob_loss:   1.14, total_loss:  20.65\n",
            "[[ 69  43 218 258   1]]\n",
            "[[ 17   2 266 234   2]]\n",
            "[[103 117 207 224   2]]\n",
            "[[ 10   9 164 154   2]]\n",
            "epoch:13 step:   42/60, lr:0.000028, giou_loss:   0.88, conf_loss:  18.73, prob_loss:   0.82, total_loss:  20.42\n",
            "[[ 381  823 1188 1762    1]\n",
            " [  61  772 1026 1450    1]\n",
            " [  16  647  914 1137    1]\n",
            " [ 179  460  960 1039    1]]\n",
            "[[ 29  52 269 256   0]]\n",
            "[[ 47  39 295 295   2]]\n",
            "[[140  98 396 328   2]\n",
            " [  9   0 224 186   2]\n",
            " [386  46 585 296   2]\n",
            " [190  24 402 208   2]\n",
            " [287 271 551 397   2]]\n",
            "epoch:13 step:   43/60, lr:0.000028, giou_loss:   2.96, conf_loss:  22.76, prob_loss:   6.08, total_loss:  31.80\n",
            "[[ 93 137 269 307   0]\n",
            " [261 144 428 296   0]\n",
            " [ 36 132 190 272   0]\n",
            " [460  87 594 235   0]]\n",
            "[[506 257 739 524   0]\n",
            " [330 345 569 569   0]\n",
            " [  1 239 205 471   0]\n",
            " [184 191 414 406   0]\n",
            " [433 176 626 327   0]\n",
            " [292  22 524 216   0]\n",
            " [526  55 691 220   0]]\n",
            "[[215 181 406 370   2]\n",
            " [328 173 488 351   2]]\n",
            "[[150   5 446 277   1]\n",
            " [639  35 907 378   1]\n",
            " [535  53 824 397   1]\n",
            " [535 133 795 527   1]\n",
            " [411 120 581 546   1]\n",
            " [224 119 515 454   1]\n",
            " [188  34 561 315   1]]\n",
            "epoch:13 step:   44/60, lr:0.000028, giou_loss:   9.43, conf_loss:  32.27, prob_loss:  12.75, total_loss:  54.45\n",
            "[[106   1 610 528   0]]\n",
            "[[ 43  91 796 773   0]]\n",
            "[[148 109 651 355   1]]\n",
            "[[228 301 712 777   0]\n",
            " [ 62  99 429 572   0]]\n",
            "epoch:13 step:   45/60, lr:0.000028, giou_loss:   0.81, conf_loss:  18.70, prob_loss:   5.04, total_loss:  24.56\n",
            "[[ 476  207 1123  571    1]]\n",
            "[[117 258 587 700   0]]\n",
            "[[ 13 108 493 312   1]]\n",
            "[[  8  17 347 219   1]]\n",
            "epoch:13 step:   46/60, lr:0.000028, giou_loss:   0.85, conf_loss:  19.20, prob_loss:   0.83, total_loss:  20.88\n",
            "[[ 69 203 258 397   0]\n",
            " [141 116 306 301   0]\n",
            " [  1 127 170 309   0]]\n",
            "[[286   3 649 350   0]]\n",
            "[[257  50 582 379   0]\n",
            " [ 41  17 312 308   0]]\n",
            "[[  5  40 212 248   0]]\n",
            "epoch:13 step:   47/60, lr:0.000027, giou_loss:   1.48, conf_loss:  20.11, prob_loss:   8.17, total_loss:  29.76\n",
            "[[  1  67 259 315   2]\n",
            " [302  29 601 328   2]]\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "[[172  10 834 713   2]]\n",
            "[[304 155 445 396   1]\n",
            " [229 144 313 405   1]\n",
            " [150 161 223 400   1]\n",
            " [ 52 168 147 405   1]]\n",
            "epoch:13 step:   48/60, lr:0.000027, giou_loss:   5.36, conf_loss:  23.79, prob_loss:   4.00, total_loss:  33.15\n",
            "[[135  37 561 368   1]]\n",
            "[[  1  38 406 380   1]]\n",
            "[[315 231 538 445   2]\n",
            " [110 223 337 434   0]\n",
            " [290 258 646 455   1]]\n",
            "[[ 97 127 346 379   0]\n",
            " [314 112 594 385   0]]\n",
            "epoch:13 step:   49/60, lr:0.000027, giou_loss:   1.94, conf_loss:  20.71, prob_loss:   3.73, total_loss:  26.38\n",
            "[[ 73 142 540 417   1]\n",
            " [ 97  81 530 311   1]]\n",
            "[[133  36 553 412   2]\n",
            " [  6 289 953 591   1]\n",
            " [509  77 878 389   0]]\n",
            "[[456 228 620 378   2]\n",
            " [403  10 594 206   0]\n",
            " [287   5 413 392   1]\n",
            " [107 123 371 451   1]\n",
            " [206   4 360 381   1]]\n",
            "[[123  38 566 433   1]]\n",
            "epoch:13 step:   50/60, lr:0.000027, giou_loss:   4.63, conf_loss:  23.54, prob_loss:   9.08, total_loss:  37.24\n",
            "[[ 30  29 392 356   2]]\n",
            "[[141  35 315 210   0]\n",
            " [ 18  22 168 190   0]]\n",
            "[[   9   53 1823  976    1]]\n",
            "[[ 166  343 1006 1179    2]]\n",
            "epoch:13 step:   51/60, lr:0.000027, giou_loss:   0.88, conf_loss:  19.06, prob_loss:   0.61, total_loss:  20.55\n",
            "[[ 91  92 710 706   0]]\n",
            "[[  99  408 1001  886    1]]\n",
            "[[ 78  26 391 152   1]\n",
            " [ 16  45 239 260   1]\n",
            " [ 62  54 354 203   1]]\n",
            "[[ 494    1 1452  741    2]\n",
            " [ 822  643 1620 1066    2]]\n",
            "epoch:13 step:   52/60, lr:0.000027, giou_loss:   1.65, conf_loss:  20.46, prob_loss:   2.24, total_loss:  24.35\n",
            "[[  31  141 1898 1961    2]]\n",
            "[[  6  65 183 232   0]]\n",
            "[[ 28  25 630 478   1]\n",
            " [ 35   1 606 298   1]\n",
            " [ 58   5 569 214   1]\n",
            " [461 145 660 478   1]]\n",
            "[[ 461  130 1223  865    2]]\n",
            "epoch:13 step:   53/60, lr:0.000027, giou_loss:   1.68, conf_loss:  21.35, prob_loss:   1.18, total_loss:  24.22\n",
            "[[ 100  150 1607  926    1]]\n",
            "[[  53   25 1159 1052    0]]\n",
            "[[180  95 290 205   0]\n",
            " [112  68 213 163   0]\n",
            " [  4  81 108 192   0]]\n",
            "[[ 18 143 570 417   1]]\n",
            "epoch:13 step:   54/60, lr:0.000027, giou_loss:   2.23, conf_loss:  20.34, prob_loss:   6.32, total_loss:  28.88\n",
            "[[218 147 546 471   0]\n",
            " [265 432 583 697   0]\n",
            " [  0 454 197 700   0]\n",
            " [ 73 163 332 451   0]\n",
            " [492  47 799 398   0]]\n",
            "[[ 48  22 550 225   1]]\n",
            "[[164  36 595 477   2]]\n",
            "[[ 23  55 219 238   0]]\n",
            "epoch:13 step:   55/60, lr:0.000026, giou_loss:   2.61, conf_loss:  20.85, prob_loss:   2.34, total_loss:  25.80\n",
            "[[ 20 103 141 246   2]\n",
            " [ 41   0 147 114   2]\n",
            " [113  61 243 186   2]\n",
            " [133   1 243  69   2]\n",
            " [ 92 200 214 249   2]]\n",
            "[[458 229 573 328   2]\n",
            " [ 83 207 163 282   2]\n",
            " [ 91 150 189 227   2]\n",
            " [302 117 559 217   1]\n",
            " [287 159 521 254   1]\n",
            " [228 116 385 261   1]\n",
            " [221 166 357 295   1]\n",
            " [271  41 380 144   0]\n",
            " [156  74 270 179   0]]\n",
            "[[ 10 135  92 223   2]\n",
            " [ 77 132 150 207   2]\n",
            " [ 50  18 280 114   1]\n",
            " [197 153 291 244   0]]\n",
            "[[  8   9 282 276   2]]\n",
            "epoch:13 step:   56/60, lr:0.000026, giou_loss:  10.51, conf_loss:  34.93, prob_loss:  18.78, total_loss:  64.22\n",
            "[[ 46 140 500 596   2]]\n",
            "[[200  40 443 263   2]]\n",
            "[[ 550  273 1167  893    2]\n",
            " [   4  361  592  965    2]]\n",
            "[[ 76 120 162 208   2]\n",
            " [ 52 107 130 198   2]]\n",
            "epoch:13 step:   57/60, lr:0.000026, giou_loss:   1.59, conf_loss:  18.80, prob_loss:   2.17, total_loss:  22.56\n",
            "[[ 25  42 275 297   0]]\n",
            "[[  78  753  881 1574    0]\n",
            " [ 584   24  990  640    0]\n",
            " [ 367   27  887  580    0]]\n",
            "[[ 79  76 438 409   1]\n",
            " [166  32 604 375   1]\n",
            " [185   1 650 219   1]]\n",
            "[[ 571  417 1526 1053    1]\n",
            " [ 745  621 1526 1129    1]\n",
            " [  27  132 1207 1005    1]]\n",
            "epoch:13 step:   58/60, lr:0.000026, giou_loss:   2.19, conf_loss:  20.58, prob_loss:   5.53, total_loss:  28.30\n",
            "[[ 78   7 410 336   2]]\n",
            "[[ 27  12 295 289   0]]\n",
            "[[123  37 392 301   0]]\n",
            "[[243  45 421 223   2]\n",
            " [ 50  59 218 202   0]\n",
            " [109 276 421 400   1]]\n",
            "epoch:13 step:   59/60, lr:0.000026, giou_loss:   1.24, conf_loss:  18.89, prob_loss:   1.93, total_loss:  22.06\n",
            "[[ 11  62 197 244   0]]\n",
            "[[ 25  40 917 527   1]]\n",
            "[[195  53 337 198   0]\n",
            " [125 176 247 297   0]\n",
            " [132 292 284 416   0]\n",
            " [299 162 465 319   0]\n",
            " [ 58  82 157 172   0]\n",
            " [ 15 229  89 304   0]\n",
            " [  3  58  64 119   0]\n",
            " [  6 133  71 200   0]]\n",
            "[[ 45  57 214 212   2]\n",
            " [164  49 324 212   2]\n",
            " [226   2 368 143   2]]\n",
            "epoch:13 step:    0/60, lr:0.000026, giou_loss:   6.06, conf_loss:  27.21, prob_loss:   6.77, total_loss:  40.04\n",
            "[[ 70  54 428 412   2]\n",
            " [  6  32 603 489   1]]\n",
            "[[339 227 851 784   0]]\n",
            "[[ 35  60 231 305   1]]\n",
            "[[ 24  11 253 235   2]]\n",
            "epoch:13 step:    1/60, lr:0.000026, giou_loss:   0.95, conf_loss:  18.66, prob_loss:   1.76, total_loss:  21.38\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[279  14 562 295   2]]\n",
            "[[133 165 922 525   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[155 105 453 436   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 75  62 711 745   2]]\n",
            "\n",
            "\n",
            "giou_val_loss:   2.67, conf_val_loss:  22.37, prob_val_loss:   4.99, total_val_loss:  30.04\n",
            "\n",
            "\n",
            "[[ 224   61 1103  947    2]]\n",
            "[[194  93 958 435   1]\n",
            " [ 22  74 672 617   1]\n",
            " [242  50 998 348   1]]\n",
            "[[ 34   6 347 132   1]\n",
            " [186  25 409 240   1]\n",
            " [ 71  34 363 183   1]]\n",
            "[[ 73  77 432 410   1]\n",
            " [160  33 598 376   1]\n",
            " [179   2 644 220   1]]\n",
            "epoch:14 step:    2/60, lr:0.000026, giou_loss:   2.46, conf_loss:  20.86, prob_loss:   3.68, total_loss:  27.00\n",
            "[[ 336  116 1442 1143    0]]\n",
            "[[ 37  52 205 222   0]]\n",
            "[[475 113 811 483   2]\n",
            " [128 102 457 424   2]]\n",
            "[[  1 123 427 337   1]]\n",
            "epoch:14 step:    3/60, lr:0.000025, giou_loss:   0.87, conf_loss:  18.66, prob_loss:   0.91, total_loss:  20.44\n",
            "[[ 41  67 151 177   0]\n",
            " [118  40 219 135   0]\n",
            " [223  53 327 164   0]]\n",
            "[[ 64 101 466 190   1]\n",
            " [ 71 109 467 261   1]\n",
            " [ 80 145 477 354   1]\n",
            " [203 165 554 436   1]]\n",
            "[[202  37 470 314   0]]\n",
            "[[119  72 613 319   1]\n",
            " [142  80 368 306   1]]\n",
            "epoch:14 step:    4/60, lr:0.000025, giou_loss:   2.68, conf_loss:  21.22, prob_loss:   8.17, total_loss:  32.07\n",
            "[[222   8 486 280   2]]\n",
            "[[  3  67 472 401   0]\n",
            " [301   2 773 401   0]]\n",
            "[[ 12   1 286 268   2]]\n",
            "[[138 250 402 563   2]\n",
            " [129  98 449 353   0]\n",
            " [204  34 753 336   1]]\n",
            "epoch:14 step:    5/60, lr:0.000025, giou_loss:   1.53, conf_loss:  20.50, prob_loss:   2.73, total_loss:  24.75\n",
            "[[330 177 875 694   2]]\n",
            "[[  84  570 2540 4460    1]]\n",
            "[[561 268 910 636   2]\n",
            " [232 305 661 656   2]\n",
            " [ 85 245 429 588   2]\n",
            " [245  29 685 387   2]]\n",
            "[[234 132 416 343   0]]\n",
            "epoch:14 step:    6/60, lr:0.000025, giou_loss:   1.98, conf_loss:  20.93, prob_loss:   2.72, total_loss:  25.63\n",
            "[[ 75  96 531 465   2]]\n",
            "[[ 81  63 524 458   1]]\n",
            "[[118  40 780 743   2]]\n",
            "[[ 67  36 386 148   1]]\n",
            "epoch:14 step:    7/60, lr:0.000025, giou_loss:   0.76, conf_loss:  19.01, prob_loss:   2.02, total_loss:  21.79\n",
            "[[509 125 811 439   0]\n",
            " [112 211 391 464   0]\n",
            " [421 272 698 514   0]\n",
            " [ 11 185 251 453   0]]\n",
            "[[ 33  80 119 168   2]\n",
            " [ 65  67 143 158   2]]\n",
            "[[  7 150 426 344   1]\n",
            " [ 13  87 335 224   1]\n",
            " [ 54  32 329 167   1]]\n",
            "[[ 47 121 506 371   1]]\n",
            "epoch:14 step:    8/60, lr:0.000025, giou_loss:   3.57, conf_loss:  22.03, prob_loss:   2.01, total_loss:  27.61\n",
            "[[115  20 256 177   0]\n",
            " [ 14  15 116 124   0]\n",
            " [ 54  83 165 192   0]]\n",
            "[[ 102  508  480  919    2]\n",
            " [ 406  187 1128  615    1]\n",
            " [ 436  319 1106  937    1]]\n",
            "[[  1  55 178 222   0]]\n",
            "[[125  13 677 287   1]]\n",
            "epoch:14 step:    9/60, lr:0.000025, giou_loss:   2.24, conf_loss:  19.86, prob_loss:   2.86, total_loss:  24.96\n",
            "[[105  18 412 316   2]]\n",
            "[[ 33   3 535 206   1]]\n",
            "[[  4  57 343 259   1]]\n",
            "[[1321  244 2786 1818    2]]\n",
            "epoch:14 step:   10/60, lr:0.000025, giou_loss:   0.89, conf_loss:  17.77, prob_loss:   0.45, total_loss:  19.11\n",
            "[[166 167 333 344   0]\n",
            " [ 22 159 199 316   0]\n",
            " [ 80  68 259 237   0]]\n",
            "[[ 145   60  833  580    1]\n",
            " [ 571   60 1000  580    1]]\n",
            "[[ 75  21 563 328   1]]\n",
            "[[ 576  441 1210 1441    1]\n",
            " [ 269  262  794 1320    1]]\n",
            "epoch:14 step:   11/60, lr:0.000024, giou_loss:   2.28, conf_loss:  20.64, prob_loss:   6.48, total_loss:  29.39\n",
            "[[472 317 782 633   2]\n",
            " [ 15 180 621 397   1]\n",
            " [ 21 238 671 493   1]\n",
            " [ 69  15 331 308   0]]\n",
            "[[  4 151  86 239   2]\n",
            " [ 71 148 144 223   2]\n",
            " [ 44  34 274 130   1]\n",
            " [191 169 285 260   0]]\n",
            "[[ 75  34 508 463   0]]\n",
            "[[197  98 453 328   2]\n",
            " [369   0 584 186   2]\n",
            " [  8  46 207 296   2]\n",
            " [191  24 403 208   2]\n",
            " [ 42 271 306 397   2]]\n",
            "epoch:14 step:   12/60, lr:0.000024, giou_loss:   4.12, conf_loss:  24.88, prob_loss:   7.88, total_loss:  36.87\n",
            "[[140  72 368 305   2]]\n",
            "[[ 30  16 346 309   1]\n",
            " [123   8 495 183   1]\n",
            " [110   4 476 263   1]\n",
            " [142  10 485 214   1]]\n",
            "[[221 115 900 863   0]]\n",
            "[[262  27 727 483   2]]\n",
            "epoch:14 step:   13/60, lr:0.000024, giou_loss:   1.25, conf_loss:  18.25, prob_loss:   0.83, total_loss:  20.33\n",
            "[[ 61   1 565 528   0]]\n",
            "[[ 37 404 316 685   2]\n",
            " [197 247 507 505   2]\n",
            " [221 494 554 731   2]]\n",
            "[[236  95 843 698   0]]\n",
            "[[315 231 538 445   2]\n",
            " [110 223 337 434   0]\n",
            " [290 258 646 455   1]]\n",
            "epoch:14 step:   14/60, lr:0.000024, giou_loss:   3.30, conf_loss:  23.60, prob_loss:   6.02, total_loss:  32.92\n",
            "[[ 17  18 335 322   1]]\n",
            "[[128   7 315 209   2]]\n",
            "[[ 88   9 481 411   2]]\n",
            "[[ 45 222 529 698   0]\n",
            " [328  20 695 493   0]]\n",
            "epoch:14 step:   15/60, lr:0.000024, giou_loss:   0.82, conf_loss:  19.45, prob_loss:   1.80, total_loss:  22.08\n",
            "[[383 222 559 392   0]\n",
            " [224 229 391 381   0]\n",
            " [462 217 616 357   0]\n",
            " [ 58 172 192 320   0]]\n",
            "[[117   3 540 332   1]]\n",
            "[[  11  832  814 1653    0]\n",
            " [ 517  103  923  719    0]\n",
            " [ 300  106  820  659    0]]\n",
            "[[264 162 497 381   2]]\n",
            "epoch:14 step:   16/60, lr:0.000024, giou_loss:   3.37, conf_loss:  21.73, prob_loss:   2.84, total_loss:  27.94\n",
            "[[ 18  20 531 532   2]]\n",
            "[[ 52   7 174 130   2]\n",
            " [139   5 275 149   2]]\n",
            "[[728 229 992 481   2]\n",
            " [ 15 250 286 517   2]\n",
            " [223 195 476 422   2]\n",
            " [502 229 736 437   2]]\n",
            "[[ 67 127 441 505   2]\n",
            " [209  98 866 312   1]\n",
            " [263 231 849 515   1]]\n",
            "epoch:14 step:   17/60, lr:0.000024, giou_loss:   3.96, conf_loss:  22.93, prob_loss:  13.08, total_loss:  39.97\n",
            "[[ 16  41 313 328   0]]\n",
            "[[  1   4 156 151   0]]\n",
            "[[178 107 367 301   0]\n",
            " [130  20 295 205   0]\n",
            " [266  31 435 213   0]]\n",
            "[[ 15  35 267 294   2]]\n",
            "epoch:14 step:   18/60, lr:0.000024, giou_loss:   1.50, conf_loss:  20.27, prob_loss:   3.96, total_loss:  25.73\n",
            "[[ 18  44 453 486   0]]\n",
            "[[ 54  66 508 522   2]]\n",
            "[[ 706  111 1440  832    2]\n",
            " [ 172   35  860  697    2]]\n",
            "[[ 88 123 225 282   2]\n",
            " [ 79  48 215 187   2]\n",
            " [422 118 554 263   2]\n",
            " [447  53 596 183   2]\n",
            " [315  75 458 219   2]\n",
            " [240 127 391 269   2]\n",
            " [176  32 309 158   2]]\n",
            "epoch:14 step:   19/60, lr:0.000023, giou_loss:   4.45, conf_loss:  25.66, prob_loss:  11.11, total_loss:  41.22\n",
            "[[150 112 362 317   2]]\n",
            "[[  8  44 162 189   2]]\n",
            "[[ 69  43 218 258   1]]\n",
            "[[162  13 363 218   2]]\n",
            "epoch:14 step:   20/60, lr:0.000023, giou_loss:   0.92, conf_loss:  18.17, prob_loss:   0.96, total_loss:  20.05\n",
            "[[  1  13 337 376   2]]\n",
            "[[ 43 135 219 324   0]]\n",
            "[[ 38 174 595 408   1]]\n",
            "[[ 64  24 544 228   1]]\n",
            "epoch:14 step:   21/60, lr:0.000023, giou_loss:   0.78, conf_loss:  17.87, prob_loss:   0.69, total_loss:  19.35\n",
            "[[ 14  44 270 300   0]]\n",
            "[[ 470  161  992  495    1]\n",
            " [ 628    1 1169  298    1]\n",
            " [   1    3  412  344    1]\n",
            " [   1  249  260  669    1]\n",
            " [ 229  449  710  674    1]\n",
            " [ 822  480 1198  674    1]]\n",
            "[[415 261 720 567   0]\n",
            " [105 426 393 691   0]\n",
            " [194 290 477 545   0]]\n",
            "[[ 66  79 263 849   1]]\n",
            "epoch:14 step:   22/60, lr:0.000023, giou_loss:   4.40, conf_loss:  24.52, prob_loss:   7.55, total_loss:  36.46\n",
            "[[129  28 271 173   0]\n",
            " [219 151 341 272   0]\n",
            " [182 267 334 391   0]\n",
            " [  1 137 167 294   0]\n",
            " [309  57 408 147   0]\n",
            " [377 204 451 279   0]\n",
            " [402  33 463  94   0]\n",
            " [395 108 460 175   0]]\n",
            "[[  4   1 183 171   2]]\n",
            "[[ 28  85 379 458   0]\n",
            " [345 109 752 540   0]]\n",
            "[[421 314 536 413   2]\n",
            " [ 46 292 126 367   2]\n",
            " [ 54 235 152 312   2]\n",
            " [265 202 522 302   1]\n",
            " [250 244 484 339   1]\n",
            " [191 201 348 346   1]\n",
            " [184 251 320 380   1]\n",
            " [234 126 343 229   0]\n",
            " [119 159 233 264   0]]\n",
            "epoch:14 step:   23/60, lr:0.000023, giou_loss:  13.06, conf_loss:  36.34, prob_loss:  14.76, total_loss:  64.16\n",
            "[[319  51 582 339   0]\n",
            " [ 79  18 338 270   0]]\n",
            "[[199 162 423 404   2]]\n",
            "[[  4  51 408 195   1]]\n",
            "[[215  73 718 319   1]]\n",
            "epoch:14 step:   24/60, lr:0.000023, giou_loss:   1.00, conf_loss:  18.17, prob_loss:   2.56, total_loss:  21.74\n",
            "[[ 90  79 513 501   0]\n",
            " [358  21 682 347   0]]\n",
            "[[ 113    5 1071  745    2]\n",
            " [ 441  647 1239 1070    2]]\n",
            "[[239  13 626 206   1]\n",
            " [  6  85 155 247   1]\n",
            " [ 93 132 635 321   1]]\n",
            "[[  1  11 148 155   0]]\n",
            "epoch:14 step:   25/60, lr:0.000023, giou_loss:   2.07, conf_loss:  21.23, prob_loss:   4.53, total_loss:  27.83\n",
            "[[262  52 508 313   2]]\n",
            "[[ 297  294 1137 1130    2]]\n",
            "[[356   9 906 561   0]\n",
            " [ 73  15 514 483   0]\n",
            " [  0  25 277 424   0]]\n",
            "[[162 210 541 559   0]]\n",
            "epoch:14 step:   26/60, lr:0.000023, giou_loss:   1.78, conf_loss:  19.64, prob_loss:   1.37, total_loss:  22.79\n",
            "[[312 125 561 377   0]\n",
            " [ 64 110 344 383   0]]\n",
            "[[213  30 459 255   0]\n",
            " [  1  27 188 277   0]\n",
            " [116   2 337 217   0]]\n",
            "[[207 137 416 358   2]\n",
            " [  9  99 214 351   2]\n",
            " [119   1 338 171   2]]\n",
            "[[ 16  38 212 221   0]]\n",
            "epoch:14 step:   27/60, lr:0.000022, giou_loss:   2.95, conf_loss:  21.26, prob_loss:   6.77, total_loss:  30.99\n",
            "[[117 103 238 246   2]\n",
            " [111   0 217 114   2]\n",
            " [ 15  61 145 186   2]\n",
            " [ 15   1 125  69   2]\n",
            " [ 44 200 166 249   2]]\n",
            "[[  35   93 1392 1413    0]]\n",
            "[[ 26  13 318 129   1]]\n",
            "[[227 144 585 502   2]\n",
            " [163 122 760 579   1]]\n",
            "epoch:14 step:   28/60, lr:0.000022, giou_loss:   2.20, conf_loss:  20.72, prob_loss:   3.41, total_loss:  26.33\n",
            "[[  1  17 893 504   1]]\n",
            "[[ 78 196 497 594   2]\n",
            " [498 122 753 363   2]]\n",
            "[[  1 171 532 676   2]]\n",
            "[[ 81  35 258 198   0]]\n",
            "epoch:14 step:   29/60, lr:0.000022, giou_loss:   1.01, conf_loss:  18.33, prob_loss:   1.87, total_loss:  21.20\n",
            "[[ 350    1 1923  624    1]]\n",
            "[[148  70 313 265   2]\n",
            " [306  65 499 288   0]\n",
            " [  8 283 553 536   1]]\n",
            "[[202  61 445 284   2]]\n",
            "[[  39  119 1906 1939    2]]\n",
            "epoch:14 step:   30/60, lr:0.000022, giou_loss:   2.08, conf_loss:  19.32, prob_loss:   4.43, total_loss:  25.83\n",
            "[[234  62 622 237   1]]\n",
            "[[ 146    4 1459 1071    1]]\n",
            "[[ 57  77 395 438   2]\n",
            " [353  37 705 400   2]]\n",
            "[[ 17   1 717 708   0]]\n",
            "epoch:14 step:   31/60, lr:0.000022, giou_loss:   1.14, conf_loss:  18.98, prob_loss:   0.68, total_loss:  20.80\n",
            "[[  3  39 201 230   2]\n",
            " [167  16 336 189   2]]\n",
            "[[ 68  19 687 633   0]]\n",
            "[[218 174 546 498   0]\n",
            " [265 459 583 724   0]\n",
            " [  0 481 197 727   0]\n",
            " [ 73 190 332 478   0]\n",
            " [492  74 799 425   0]]\n",
            "[[185  80 652 355   1]\n",
            " [209  19 642 249   1]]\n",
            "epoch:14 step:   32/60, lr:0.000022, giou_loss:   2.45, conf_loss:  19.59, prob_loss:   1.66, total_loss:  23.70\n",
            "[[203  43 381 221   2]\n",
            " [ 10  57 178 200   0]\n",
            " [ 69 274 381 398   1]]\n",
            "[[ 117   94  689 1094    1]]\n",
            "[[ 89  12 495 431   0]]\n",
            "[[ 67  25 669 478   1]\n",
            " [ 91   1 662 298   1]\n",
            " [128   5 639 214   1]\n",
            " [ 37 145 236 478   1]]\n",
            "epoch:14 step:   33/60, lr:0.000022, giou_loss:   2.47, conf_loss:  20.96, prob_loss:   3.86, total_loss:  27.28\n",
            "[[107 126 475 515   2]]\n",
            "[[  1  18 180 190   0]]\n",
            "[[  8   4 331 338   0]]\n",
            "[[138  94 734 761   1]]\n",
            "epoch:14 step:   34/60, lr:0.000022, giou_loss:   0.74, conf_loss:  18.67, prob_loss:   0.50, total_loss:  19.90\n",
            "[[ 367  566 1174 1505    1]\n",
            " [  47  515 1012 1193    1]\n",
            " [   2  390  900  880    1]\n",
            " [ 165  203  946  782    1]]\n",
            "[[  37   64 1851  987    1]]\n",
            "[[110  31 279 139   1]]\n",
            "[[141  35 315 210   0]\n",
            " [ 18  22 168 190   0]]\n",
            "epoch:14 step:   35/60, lr:0.000022, giou_loss:   2.25, conf_loss:  20.28, prob_loss:   2.90, total_loss:  25.43\n",
            "[[166  15 599 340   1]\n",
            " [ 77  30 451 392   1]\n",
            " [218   1 657 246   1]]\n",
            "[[  4   1 367 348   0]]\n",
            "[[  7  59 369 386   2]]\n",
            "[[164 104 811 468   1]]\n",
            "epoch:14 step:   36/60, lr:0.000021, giou_loss:   1.27, conf_loss:  18.49, prob_loss:   1.38, total_loss:  21.14\n",
            "[[ 96 107 580 397   1]]\n",
            "[[ 48 111 270 330   2]\n",
            " [205  96 405 318   2]]\n",
            "[[ 28  14 125 119   2]]\n",
            "[[ 52  22 450 437   0]]\n",
            "epoch:14 step:   37/60, lr:0.000021, giou_loss:   1.09, conf_loss:  18.50, prob_loss:   1.34, total_loss:  20.94\n",
            "[[ 50   4 236 186   0]]\n",
            "[[  6   5 206 193   0]]\n",
            "[[ 46  39 187 280   1]\n",
            " [178  28 262 289   1]\n",
            " [268  45 341 284   1]\n",
            " [344  52 439 289   1]]\n",
            "[[505   2 725 203   0]\n",
            " [542 194 760 430   0]\n",
            " [413 154 612 388   0]\n",
            " [  8 275 190 490   0]\n",
            " [120 347 297 544   0]\n",
            " [221 216 462 440   0]\n",
            " [422 327 604 520   0]\n",
            " [140 402 352 575   0]]\n",
            "epoch:14 step:   38/60, lr:0.000021, giou_loss:   7.67, conf_loss:  27.46, prob_loss:  10.53, total_loss:  45.65\n",
            "[[ 37  42 220 232   2]]\n",
            "[[187 170 949 905   2]]\n",
            "[[ 28  74 356 376   1]\n",
            " [ 74 151 472 408   1]\n",
            " [ 88  68 400 263   1]]\n",
            "[[ 85 182 688 793   2]]\n",
            "epoch:14 step:   39/60, lr:0.000021, giou_loss:   1.18, conf_loss:  19.06, prob_loss:   0.86, total_loss:  21.10\n",
            "[[207 189 677 631   0]]\n",
            "[[ 568  282 1185  902    2]\n",
            " [  22  370  610  974    2]]\n",
            "[[ 33  48 661 222   1]\n",
            " [ 88 136 675 446   1]\n",
            " [247  44 688 338   1]]\n",
            "[[158   9 304 152   2]\n",
            " [  9 151 315 233   1]\n",
            " [ 17   4 154 149   0]]\n",
            "epoch:14 step:   40/60, lr:0.000021, giou_loss:   1.72, conf_loss:  18.32, prob_loss:   1.06, total_loss:  21.11\n",
            "[[339 181 651 469   2]\n",
            " [ 94 333 919 529   1]\n",
            " [ 66 452 909 660   1]]\n",
            "[[ 15 231 377 596   0]]\n",
            "[[ 41   1 565 359   1]]\n",
            "[[ 60   8 267 216   0]]\n",
            "epoch:14 step:   41/60, lr:0.000021, giou_loss:   1.74, conf_loss:  19.13, prob_loss:   0.89, total_loss:  21.77\n",
            "[[133  34 987 912   0]]\n",
            "[[ 31  52 280 284   2]]\n",
            "[[  3   5 253 260   0]]\n",
            "[[ 19  79 212 281   0]]\n",
            "epoch:14 step:   42/60, lr:0.000021, giou_loss:   0.42, conf_loss:  18.03, prob_loss:   1.73, total_loss:  20.18\n",
            "[[ 25  69 603 581   2]]\n",
            "[[337  62 579 317   2]\n",
            " [134 127 360 383   0]\n",
            " [173 207 746 507   1]]\n",
            "[[141  66 245 173   2]]\n",
            "[[  73  157  496  564    2]\n",
            " [ 540  254  924  681    2]\n",
            " [ 484  640  964 1072    2]]\n",
            "epoch:14 step:   43/60, lr:0.000021, giou_loss:   2.78, conf_loss:  21.83, prob_loss:   4.95, total_loss:  29.56\n",
            "[[ 661  111 1310  815    0]]\n",
            "[[  1  14 294 130   1]]\n",
            "[[ 34  95 359 424   0]\n",
            " [304  62 575 353   0]]\n",
            "[[ 10  16 239 240   2]]\n",
            "epoch:14 step:   44/60, lr:0.000020, giou_loss:   0.88, conf_loss:  17.66, prob_loss:   0.63, total_loss:  19.18\n",
            "[[ 175   66 1576 1457    2]]\n",
            "[[143  10 579 247   1]]\n",
            "[[ 230  404 1201 1188    1]\n",
            " [ 543  463 1167 1062    0]]\n",
            "[[ 211  108 1016  321    1]]\n",
            "epoch:14 step:   45/60, lr:0.000020, giou_loss:   1.00, conf_loss:  17.78, prob_loss:   3.13, total_loss:  21.91\n",
            "[[144  31 355 227   2]\n",
            " [193 270 402 488   2]\n",
            " [ 13 350 225 549   2]\n",
            " [ 88 435 290 605   2]]\n",
            "[[572  16 868 288   1]\n",
            " [111  46 379 389   1]\n",
            " [194  64 483 408   1]\n",
            " [223 144 483 538   1]\n",
            " [437 131 607 557   1]\n",
            " [503 130 794 465   1]\n",
            " [457  45 830 326   1]]\n",
            "[[ 66   8 497 449   2]]\n",
            "[[  5   4 431 335   1]]\n",
            "epoch:14 step:   46/60, lr:0.000020, giou_loss:   5.87, conf_loss:  26.04, prob_loss:   9.26, total_loss:  41.17\n",
            "[[ 45  57 214 212   2]\n",
            " [164  49 324 212   2]\n",
            " [226   2 368 143   2]]\n",
            "[[117  82 302 174   1]\n",
            " [305  81 489 175   1]]\n",
            "[[ 79  49 319 293   2]\n",
            " [328  44 582 311   2]]\n",
            "[[ 61  17 422 308   2]]\n",
            "epoch:14 step:   47/60, lr:0.000020, giou_loss:   2.96, conf_loss:  20.57, prob_loss:   6.66, total_loss:  30.19\n",
            "[[ 269  192 1248 1187    0]]\n",
            "[[ 13  40 311 328   0]]\n",
            "[[  28   49 2760 2532    1]]\n",
            "[[   3   46  736  821    2]\n",
            " [ 575    9 1268  741    2]]\n",
            "epoch:14 step:   48/60, lr:0.000020, giou_loss:   0.68, conf_loss:  18.53, prob_loss:   0.76, total_loss:  19.97\n",
            "[[ 96 155 998 633   1]]\n",
            "[[ 67  29 378 300   1]\n",
            " [ 41  89 302 377   1]]\n",
            "[[260  23 456 268   1]]\n",
            "[[187  70 513 345   0]]\n",
            "epoch:14 step:   49/60, lr:0.000020, giou_loss:   1.11, conf_loss:  17.97, prob_loss:   5.72, total_loss:  24.80\n",
            "[[ 29  25 316 311   0]]\n",
            "[[  16  157 1196  623    1]]\n",
            "[[453 189 572 304   0]\n",
            " [301 209 432 334   0]\n",
            " [270  92 376 187   0]\n",
            " [174  29 309 133   0]\n",
            " [ 99  74 220 190   0]\n",
            " [202 132 316 239   0]]\n",
            "[[501  63 895 444   2]\n",
            " [ 18  49 419 435   0]\n",
            " [122 489 803 851   1]]\n",
            "epoch:14 step:   50/60, lr:0.000020, giou_loss:   5.15, conf_loss:  24.43, prob_loss:   7.72, total_loss:  37.31\n",
            "[[506 262 670 412   2]\n",
            " [453  44 644 240   0]\n",
            " [337  39 463 426   1]\n",
            " [157 157 421 485   1]\n",
            " [256  38 410 415   1]]\n",
            "[[ 10 245 243 512   0]\n",
            " [180 333 419 557   0]\n",
            " [544 227 748 459   0]\n",
            " [335 179 565 394   0]\n",
            " [123 164 316 315   0]\n",
            " [225  10 457 204   0]\n",
            " [ 58  43 223 208   0]]\n",
            "[[  2  86 242 290   0]]\n",
            "[[613 431 896 701   0]\n",
            " [521 134 769 387   0]\n",
            " [205 192 519 459   0]\n",
            " [396  10 648 233   0]\n",
            " [671  28 936 262   0]]\n",
            "epoch:14 step:   51/60, lr:0.000020, giou_loss:   8.79, conf_loss:  30.06, prob_loss:  18.82, total_loss:  57.67\n",
            "[[ 179   40 1221  531    1]\n",
            " [  63   43 1006  570    1]]\n",
            "[[ 285   93 1939  990    1]\n",
            " [   5  142 1518 1210    1]\n",
            " [ 402   67 1995  646    1]]\n",
            "[[215 181 406 370   2]\n",
            " [328 173 488 351   2]]\n",
            "[[  4 128 675 385   1]]\n",
            "epoch:14 step:   52/60, lr:0.000020, giou_loss:   2.36, conf_loss:  20.37, prob_loss:   5.28, total_loss:  28.01\n",
            "[[345 137 583 415   2]\n",
            " [ 67 127 323 398   2]]\n",
            "[[ 258   59 1765  835    1]]\n",
            "[[ 64  27 333 291   0]]\n",
            "[[279 136 449 424   1]\n",
            " [123 159 235 475   1]\n",
            " [ 52 119 203 376   1]\n",
            " [220 172 331 489   1]]\n",
            "epoch:14 step:   53/60, lr:0.000019, giou_loss:   3.86, conf_loss:  21.54, prob_loss:   3.68, total_loss:  29.08\n",
            "[[141   5 421 306   2]]\n",
            "[[ 38  23 370 352   2]]\n",
            "[[397 213 961 793   0]\n",
            " [ 78 176 590 665   0]]\n",
            "[[  3  31 285 276   0]]\n",
            "epoch:14 step:   54/60, lr:0.000019, giou_loss:   1.06, conf_loss:  19.01, prob_loss:   2.98, total_loss:  23.06\n",
            "[[  7   2 314 334   0]]\n",
            "[[ 643  364 1396 1046    0]]\n",
            "[[ 45   2 130  96   1]\n",
            " [ 62  31 195 111   1]\n",
            " [  1  28  47 100   1]\n",
            " [ 17   8  77  92   1]]\n",
            "[[ 641  112 1153  669    0]]\n",
            "epoch:14 step:   55/60, lr:0.000019, giou_loss:   1.49, conf_loss:  19.09, prob_loss:   3.72, total_loss:  24.30\n",
            "[[ 592  396 1547 1032    1]\n",
            " [ 766  600 1547 1108    1]\n",
            " [  48  111 1228  984    1]]\n",
            "[[204 154 624 596   0]]\n",
            "[[348  67 606 315   2]\n",
            " [  6  29 305 328   2]]\n",
            "[[190  60 771 465   1]\n",
            " [203 191 778 674   1]]\n",
            "epoch:14 step:   56/60, lr:0.000019, giou_loss:   1.61, conf_loss:  18.43, prob_loss:   0.98, total_loss:  21.02\n",
            "[[ 80  23 381 343   2]]\n",
            "[[390 391 815 800   2]]\n",
            "[[ 28 196 324 514   0]]\n",
            "[[ 11  75 414 483   2]]\n",
            "epoch:14 step:   57/60, lr:0.000019, giou_loss:   0.88, conf_loss:  17.80, prob_loss:   2.40, total_loss:  21.08\n",
            "[[ 440  178 1547  933    1]\n",
            " [ 573  597 1844 1278    1]\n",
            " [ 271   11 1246  621    1]\n",
            " [ 127   11  991  560    1]]\n",
            "[[ 32  41 362 373   2]]\n",
            "[[1162 1004 1788 2142    1]]\n",
            "[[ 43  57 278 301   0]]\n",
            "epoch:14 step:   58/60, lr:0.000019, giou_loss:   2.27, conf_loss:  20.31, prob_loss:   2.32, total_loss:  24.90\n",
            "[[ 364    8  787  434    2]\n",
            " [ 619   92 1099  576    0]\n",
            " [ 100  180  989  729    1]]\n",
            "[[  4  92 409 434   1]]\n",
            "[[ 77  54 287 316   1]]\n",
            "[[328  20 784 506   2]]\n",
            "epoch:14 step:   59/60, lr:0.000019, giou_loss:   1.11, conf_loss:  18.33, prob_loss:   2.13, total_loss:  21.56\n",
            "[[ 15  12 247 182   1]\n",
            " [ 82  43 267 216   1]\n",
            " [147  56 297 246   1]\n",
            " [265  75 351 290   1]]\n",
            "[[254 231 617 720   1]]\n",
            "[[ 46  32 172 172   0]]\n",
            "[[ 22 116 192 294   0]\n",
            " [ 94  64 260 248   0]]\n",
            "epoch:14 step:    0/60, lr:0.000019, giou_loss:   2.78, conf_loss:  19.34, prob_loss:   3.47, total_loss:  25.59\n",
            "[[ 11   8 259 264   2]]\n",
            "[[ 56  81 280 312   1]\n",
            " [176 107 549 293   1]\n",
            " [141  32 516 180   1]]\n",
            "[[ 19  99 192 271   2]\n",
            " [135 105 420 388   1]\n",
            " [178  17 342 178   0]]\n",
            "[[145   7 565 383   2]\n",
            " [ 18 260 965 562   1]\n",
            " [521  48 890 360   0]]\n",
            "epoch:14 step:    1/60, lr:0.000019, giou_loss:   2.73, conf_loss:  20.52, prob_loss:   4.17, total_loss:  27.42\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[203 115 584 452   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[174  20 364 199   2]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "\n",
            "\n",
            "giou_val_loss:   2.71, conf_val_loss:  21.28, prob_val_loss:   4.19, total_val_loss:  28.19\n",
            "\n",
            "\n",
            "[[  1  14 406 356   1]]\n",
            "[[ 125  328 1167  819    1]\n",
            " [   9  331  952  858    1]]\n",
            "[[ 45  51 186 292   1]\n",
            " [177  40 261 301   1]\n",
            " [267  57 340 296   1]\n",
            " [343  64 438 301   1]]\n",
            "[[ 19  22 259 226   0]]\n",
            "epoch:15 step:    2/60, lr:0.000018, giou_loss:   3.71, conf_loss:  20.57, prob_loss:   4.22, total_loss:  28.51\n",
            "[[123  58 546 387   1]]\n",
            "[[140 136 466 411   0]]\n",
            "[[199  82 384 174   1]\n",
            " [ 12  81 196 175   1]]\n",
            "[[ 65  18 693 192   1]\n",
            " [120 106 707 416   1]\n",
            " [279  14 720 308   1]]\n",
            "epoch:15 step:    3/60, lr:0.000018, giou_loss:   2.62, conf_loss:  19.85, prob_loss:   2.64, total_loss:  25.10\n",
            "[[172  57 395 271   2]\n",
            " [373  49 600 260   0]\n",
            " [ 64  84 420 281   1]]\n",
            "[[ 83  40 975 527   1]]\n",
            "[[216  53 652 290   1]]\n",
            "[[199  23 632 348   1]\n",
            " [347  38 721 400   1]\n",
            " [141   9 580 254   1]]\n",
            "epoch:15 step:    4/60, lr:0.000018, giou_loss:   2.06, conf_loss:  18.37, prob_loss:   4.31, total_loss:  24.75\n",
            "[[371 291 535 441   2]\n",
            " [318  73 509 269   0]\n",
            " [202  68 328 455   1]\n",
            " [ 22 186 286 514   1]\n",
            " [121  67 275 444   1]]\n",
            "[[ 80   2 391 273   1]\n",
            " [ 54  62 315 350   1]]\n",
            "[[ 50  13 285 257   0]]\n",
            "[[173   1 677 528   0]]\n",
            "epoch:15 step:    5/60, lr:0.000018, giou_loss:   3.61, conf_loss:  20.87, prob_loss:   4.71, total_loss:  29.19\n",
            "[[389   6 939 558   0]\n",
            " [106  12 547 480   0]\n",
            " [ 33  22 310 421   0]]\n",
            "[[193  33 439 258   0]\n",
            " [464  30 651 280   0]\n",
            " [315   5 536 220   0]]\n",
            "[[  62    7 1375 1074    1]]\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "epoch:15 step:    6/60, lr:0.000018, giou_loss:   2.87, conf_loss:  21.21, prob_loss:   3.31, total_loss:  27.39\n",
            "[[ 11  30 446 472   0]]\n",
            "[[  3 192 429 406   1]]\n",
            "[[  40  118  612 1118    1]]\n",
            "[[ 16  49 238 268   2]\n",
            " [173  34 373 256   2]]\n",
            "epoch:15 step:    7/60, lr:0.000018, giou_loss:   0.93, conf_loss:  18.60, prob_loss:   2.00, total_loss:  21.52\n",
            "[[ 11  17 158 161   0]]\n",
            "[[  77  230  841  572    1]\n",
            " [ 363  211 1013  754    1]\n",
            " [  37  187  793  485    1]]\n",
            "[[304 288 600 606   0]]\n",
            "[[ 10  16 164 161   2]]\n",
            "epoch:15 step:    8/60, lr:0.000018, giou_loss:   1.07, conf_loss:  17.97, prob_loss:   0.98, total_loss:  20.02\n",
            "[[180 161 647 436   1]\n",
            " [190 100 623 330   1]]\n",
            "[[255   1 562 299   2]]\n",
            "[[ 37  15 287 270   0]]\n",
            "[[ 37  87 213 276   0]]\n",
            "epoch:15 step:    9/60, lr:0.000018, giou_loss:   1.06, conf_loss:  17.38, prob_loss:   0.86, total_loss:  19.30\n",
            "[[   9  438  816 1377    1]\n",
            " [ 171  387 1136 1065    1]\n",
            " [ 283  262 1181  752    1]\n",
            " [ 237   75 1018  654    1]]\n",
            "[[ 92  32 269 195   0]]\n",
            "[[505  57 807 371   0]\n",
            " [108 143 387 396   0]\n",
            " [417 204 694 446   0]\n",
            " [  7 117 247 385   0]]\n",
            "[[ 31  82 157 222   0]]\n",
            "epoch:15 step:   10/60, lr:0.000018, giou_loss:   3.34, conf_loss:  20.22, prob_loss:   3.40, total_loss:  26.96\n",
            "[[150  37 418 314   0]]\n",
            "[[ 10  14 184 189   0]\n",
            " [157   1 307 169   0]]\n",
            "[[ 54 156 534 360   1]]\n",
            "[[ 564  265 1181  885    2]\n",
            " [  18  353  606  957    2]]\n",
            "epoch:15 step:   11/60, lr:0.000017, giou_loss:   1.05, conf_loss:  17.93, prob_loss:   1.28, total_loss:  20.26\n",
            "[[415 123 552 282   2]\n",
            " [425  48 561 187   2]\n",
            " [ 86 118 218 263   2]\n",
            " [ 44  53 193 183   2]\n",
            " [182  75 325 219   2]\n",
            " [249 127 400 269   2]\n",
            " [331  32 464 158   2]]\n",
            "[[371 110 796 519   2]]\n",
            "[[  29   31 1135 1058    0]]\n",
            "[[ 38  11 290 270   2]]\n",
            "epoch:15 step:   12/60, lr:0.000017, giou_loss:   4.61, conf_loss:  24.75, prob_loss:  11.02, total_loss:  40.38\n",
            "[[244  83 603 416   1]\n",
            " [ 78  39 516 382   1]\n",
            " [ 32   8 497 226   1]]\n",
            "[[100   2 498 417   0]]\n",
            "[[124  52 357 271   2]]\n",
            "[[ 22   8 350 310   1]\n",
            " [ 68  85 466 342   1]\n",
            " [ 82   2 394 197   1]]\n",
            "epoch:15 step:   13/60, lr:0.000017, giou_loss:   1.50, conf_loss:  18.33, prob_loss:   0.86, total_loss:  20.70\n",
            "[[732  78 996 330   2]\n",
            " [ 19  99 290 366   2]\n",
            " [227  44 480 271   2]\n",
            " [506  78 740 286   2]]\n",
            "[[ 13  86 401 261   1]]\n",
            "[[ 62 148 271 369   2]\n",
            " [264 110 469 362   2]\n",
            " [140  12 359 182   2]]\n",
            "[[ 418   31  841  457    2]\n",
            " [ 106  115  586  599    0]\n",
            " [ 216  203 1105  752    1]]\n",
            "epoch:15 step:   14/60, lr:0.000017, giou_loss:   3.54, conf_loss:  21.99, prob_loss:   7.27, total_loss:  32.80\n",
            "[[ 553  120 1232  868    0]]\n",
            "[[ 62  77 245 267   2]]\n",
            "[[  38  189 1017 1184    0]]\n",
            "[[ 66  68 235 176   1]]\n",
            "epoch:15 step:   15/60, lr:0.000017, giou_loss:   0.61, conf_loss:  17.64, prob_loss:   0.78, total_loss:  19.03\n",
            "[[  14  100 1881 1920    2]]\n",
            "[[ 45   3 130  97   1]\n",
            " [ 62  32 195 112   1]\n",
            " [  1  29  47 101   1]\n",
            " [ 17   9  77  93   1]]\n",
            "[[ 18  21 336 325   1]]\n",
            "[[   5  148 1362 1468    0]]\n",
            "epoch:15 step:   16/60, lr:0.000017, giou_loss:   1.54, conf_loss:  19.56, prob_loss:   1.86, total_loss:  22.96\n",
            "[[ 19  34 317 322   0]]\n",
            "[[ 23  15 525 218   1]]\n",
            "[[ 11   4 166 151   0]]\n",
            "[[  5 119 330 448   0]\n",
            " [275  86 546 377   0]]\n",
            "epoch:15 step:   17/60, lr:0.000017, giou_loss:   0.72, conf_loss:  17.71, prob_loss:   2.82, total_loss:  21.26\n",
            "[[139  21 720 426   1]\n",
            " [132 152 707 635   1]]\n",
            "[[ 592   77 1241  781    0]]\n",
            "[[ 75   7 599 365   1]]\n",
            "[[333  56 596 344   0]\n",
            " [ 93  23 352 275   0]]\n",
            "epoch:15 step:   18/60, lr:0.000017, giou_loss:   1.27, conf_loss:  17.98, prob_loss:   2.02, total_loss:  21.28\n",
            "[[ 106   81  840  802    2]\n",
            " [ 686    5 1374  667    2]]\n",
            "[[238 121 411 293   2]\n",
            " [ 10 127 295 410   1]\n",
            " [ 88  39 252 200   0]]\n",
            "[[ 306  545  940 1545    1]\n",
            " [ 722  366 1247 1424    1]]\n",
            "[[ 470  160  992  494    1]\n",
            " [ 628    0 1169  297    1]\n",
            " [   1    2  412  343    1]\n",
            " [   1  248  260  668    1]\n",
            " [ 229  448  710  673    1]\n",
            " [ 822  479 1198  673    1]]\n",
            "epoch:15 step:   19/60, lr:0.000017, giou_loss:   4.46, conf_loss:  23.57, prob_loss:   9.14, total_loss:  37.18\n",
            "[[  2  23 284 268   0]]\n",
            "[[  2  73 471 407   0]\n",
            " [300   8 772 407   0]]\n",
            "[[ 10 161 129 276   0]\n",
            " [150 181 281 306   0]\n",
            " [206  64 312 159   0]\n",
            " [273   1 408 105   0]\n",
            " [362  46 483 162   0]\n",
            " [266 104 380 211   0]]\n",
            "[[546 425 829 695   0]\n",
            " [454 128 702 381   0]\n",
            " [138 186 452 453   0]\n",
            " [329   4 581 227   0]\n",
            " [604  22 869 256   0]]\n",
            "epoch:15 step:   20/60, lr:0.000017, giou_loss:   6.31, conf_loss:  29.64, prob_loss:  15.70, total_loss:  51.65\n",
            "[[ 84 236 517 665   0]]\n",
            "[[ 22  22 265 245   2]]\n",
            "[[ 92  66 546 522   2]]\n",
            "[[119  72 613 319   1]\n",
            " [142  80 368 306   1]]\n",
            "epoch:15 step:   21/60, lr:0.000016, giou_loss:   1.05, conf_loss:  17.45, prob_loss:   5.54, total_loss:  24.04\n",
            "[[ 58  69 359 389   2]]\n",
            "[[103  80 722 694   0]]\n",
            "[[548  69 884 439   2]\n",
            " [201  58 530 380   2]]\n",
            "[[117   5 478 296   2]]\n",
            "epoch:15 step:   22/60, lr:0.000016, giou_loss:   1.21, conf_loss:  18.42, prob_loss:   2.62, total_loss:  22.26\n",
            "[[194  30 336 175   0]\n",
            " [124 153 246 274   0]\n",
            " [131 269 283 393   0]\n",
            " [298 139 464 296   0]\n",
            " [ 57  59 156 149   0]\n",
            " [ 14 206  88 281   0]\n",
            " [  2  35  63  96   0]\n",
            " [  5 110  70 177   0]]\n",
            "[[120 103 400 404   2]]\n",
            "[[ 95  82 292 852   1]]\n",
            "[[ 10  23 441 464   2]]\n",
            "epoch:15 step:   23/60, lr:0.000016, giou_loss:   5.49, conf_loss:  24.79, prob_loss:   5.49, total_loss:  35.77\n",
            "[[ 15  24 156 181   0]\n",
            " [155  19 257 128   0]\n",
            " [106  87 217 196   0]]\n",
            "[[ 27  48 237 310   1]]\n",
            "[[468 158 924 644   2]]\n",
            "[[ 65   8 384 120   1]]\n",
            "epoch:15 step:   24/60, lr:0.000016, giou_loss:   1.97, conf_loss:  19.62, prob_loss:   1.85, total_loss:  23.43\n",
            "[[  58   85 2790 2568    1]]\n",
            "[[147 218 336 412   0]\n",
            " [ 99 131 264 316   0]\n",
            " [235 142 404 324   0]]\n",
            "[[ 49  62 226 229   0]]\n",
            "[[ 257  388 1228 1172    1]\n",
            " [ 291  447  915 1046    0]]\n",
            "epoch:15 step:   25/60, lr:0.000016, giou_loss:   1.88, conf_loss:  20.47, prob_loss:   1.67, total_loss:  24.02\n",
            "[[ 682  911 1308 2049    1]]\n",
            "[[ 74  25 676 478   1]\n",
            " [ 98   1 669 298   1]\n",
            " [135   5 646 214   1]\n",
            " [ 44 145 243 478   1]]\n",
            "[[ 81   3 274 205   0]]\n",
            "[[  9  18 348 220   1]]\n",
            "epoch:15 step:   26/60, lr:0.000016, giou_loss:   2.36, conf_loss:  20.62, prob_loss:   2.57, total_loss:  25.55\n",
            "[[ 80  28 442 355   2]]\n",
            "[[146  56 793 420   1]]\n",
            "[[344  56 584 300   2]\n",
            " [ 81  51 335 318   2]]\n",
            "[[148  88 359 284   2]\n",
            " [197 327 406 545   2]\n",
            " [ 17 407 229 606   2]\n",
            " [ 92 492 294 662   2]]\n",
            "epoch:15 step:   27/60, lr:0.000016, giou_loss:   1.89, conf_loss:  19.64, prob_loss:   4.61, total_loss:  26.15\n",
            "[[  10   95  743  870    2]\n",
            " [ 582   58 1275  790    2]]\n",
            "[[ 90  60 593 306   1]]\n",
            "[[120  24 299 196   0]]\n",
            "[[ 10  14 210 202   0]]\n",
            "epoch:15 step:   28/60, lr:0.000016, giou_loss:   0.78, conf_loss:  17.87, prob_loss:   1.15, total_loss:  19.80\n",
            "[[  40  431  418  842    2]\n",
            " [ 344  110 1066  538    1]\n",
            " [ 374  242 1044  860    1]]\n",
            "[[  1  16 294 132   1]]\n",
            "[[ 97  12 427 344   2]]\n",
            "[[193  29 596 437   2]]\n",
            "epoch:15 step:   29/60, lr:0.000016, giou_loss:   1.16, conf_loss:  17.68, prob_loss:   3.37, total_loss:  22.21\n",
            "[[ 63 129 965 607   1]]\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[ 110  730  913 1551    0]\n",
            " [   1    1  407  617    0]\n",
            " [ 104    4  624  557    0]]\n",
            "[[222 130 645 552   0]\n",
            " [490  72 814 398   0]]\n",
            "epoch:15 step:   30/60, lr:0.000015, giou_loss:   3.13, conf_loss:  20.71, prob_loss:   4.13, total_loss:  27.97\n",
            "[[515 257 748 524   0]\n",
            " [339 345 578 569   0]\n",
            " [ 10 239 214 471   0]\n",
            " [193 191 423 406   0]\n",
            " [442 176 635 327   0]\n",
            " [301  22 533 216   0]\n",
            " [535  55 700 220   0]]\n",
            "[[ 89 137 447 495   2]\n",
            " [ 25 115 622 572   1]]\n",
            "[[ 159  233 1013 1111    0]]\n",
            "[[ 95 227 262 404   0]\n",
            " [229 219 406 376   0]\n",
            " [169 128 348 297   0]]\n",
            "epoch:15 step:   31/60, lr:0.000015, giou_loss:   3.86, conf_loss:  22.08, prob_loss:   4.22, total_loss:  30.16\n",
            "[[  1 171 532 676   2]]\n",
            "[[ 47  39 295 295   2]]\n",
            "[[ 23   4 346 338   0]]\n",
            "[[ 21  79 861 915   2]]\n",
            "epoch:15 step:   32/60, lr:0.000015, giou_loss:   0.63, conf_loss:  17.70, prob_loss:   5.43, total_loss:  23.75\n",
            "[[  2 103 123 246   2]\n",
            " [ 23   0 129 114   2]\n",
            " [ 95  61 225 186   2]\n",
            " [115   1 225  69   2]\n",
            " [ 74 200 196 249   2]]\n",
            "[[177  93 636 343   1]]\n",
            "[[116  92 478 457   0]]\n",
            "[[ 180  324  529  692    2]\n",
            " [ 429  361  858  712    2]\n",
            " [ 661  301 1005  644    2]\n",
            " [ 405   85  845  443    2]]\n",
            "epoch:15 step:   33/60, lr:0.000015, giou_loss:   3.46, conf_loss:  21.73, prob_loss:  10.89, total_loss:  36.08\n",
            "[[292  49 541 301   0]\n",
            " [ 44  34 324 307   0]]\n",
            "[[ 155  178 1662  954    1]]\n",
            "[[166   7 312 150   2]\n",
            " [ 17 149 323 231   1]\n",
            " [ 25   2 162 147   0]]\n",
            "[[250  86 419 241   2]\n",
            " [140  78 300 241   2]\n",
            " [ 96  31 238 172   2]]\n",
            "epoch:15 step:   34/60, lr:0.000015, giou_loss:   2.14, conf_loss:  18.71, prob_loss:   2.55, total_loss:  23.40\n",
            "[[163  25 759 692   1]]\n",
            "[[ 613  354 1568  990    1]\n",
            " [ 787  558 1568 1066    1]\n",
            " [  69   69 1249  942    1]]\n",
            "[[253 143 581 467   0]\n",
            " [216 428 534 693   0]\n",
            " [602 450 799 696   0]\n",
            " [467 159 726 447   0]\n",
            " [  0  43 307 394   0]]\n",
            "[[ 97  62 366 326   0]]\n",
            "epoch:15 step:   35/60, lr:0.000015, giou_loss:   2.64, conf_loss:  20.03, prob_loss:   2.42, total_loss:  25.09\n",
            "[[ 95   5 327 175   1]\n",
            " [162  36 347 209   1]\n",
            " [227  49 377 239   1]\n",
            " [345  68 431 283   1]]\n",
            "[[ 47  44 560 556   2]]\n",
            "[[ 48  86 467 484   2]\n",
            " [468  12 723 253   2]]\n",
            "[[ 97  52 402 358   0]\n",
            " [424 217 712 482   0]\n",
            " [340  81 623 336   0]]\n",
            "epoch:15 step:   36/60, lr:0.000015, giou_loss:   2.95, conf_loss:  21.37, prob_loss:   2.91, total_loss:  27.23\n",
            "[[ 857  367 1136  648    2]\n",
            " [ 666  210  976  468    2]\n",
            " [ 619  457  952  694    2]]\n",
            "[[ 20 293 135 392   2]\n",
            " [430 271 510 346   2]\n",
            " [404 214 502 291   2]\n",
            " [ 34 181 291 281   1]\n",
            " [ 72 223 306 318   1]\n",
            " [208 180 365 325   1]\n",
            " [236 230 372 359   1]\n",
            " [213 105 322 208   0]\n",
            " [323 138 437 243   0]]\n",
            "[[   7    4 1821  927    1]]\n",
            "[[ 207  187 1086 1073    2]]\n",
            "epoch:15 step:   37/60, lr:0.000015, giou_loss:   8.72, conf_loss:  29.56, prob_loss:  13.11, total_loss:  51.39\n",
            "[[246  32 702 401   2]]\n",
            "[[ 141   66 1714  689    1]]\n",
            "[[ 24  11 253 235   2]]\n",
            "[[136 117 240 224   2]]\n",
            "epoch:15 step:   38/60, lr:0.000015, giou_loss:   0.91, conf_loss:  17.80, prob_loss:   1.85, total_loss:  20.56\n",
            "[[  8 105 410 194   1]\n",
            " [ 15 113 411 265   1]\n",
            " [ 24 149 421 358   1]\n",
            " [147 169 498 440   1]]\n",
            "[[206 307 690 783   0]\n",
            " [ 40 105 407 578   0]]\n",
            "[[ 69  34 218 249   1]]\n",
            "[[307   1 670 348   0]]\n",
            "epoch:15 step:   39/60, lr:0.000015, giou_loss:   2.54, conf_loss:  19.97, prob_loss:   4.61, total_loss:  27.11\n",
            "[[ 96 154 516 596   0]]\n",
            "[[ 791  317 1170  666    0]]\n",
            "[[  2  39 673 296   1]]\n",
            "[[ 14  38 200 220   0]]\n",
            "epoch:15 step:   40/60, lr:0.000014, giou_loss:   1.08, conf_loss:  17.82, prob_loss:   1.35, total_loss:  20.25\n",
            "[[138  40 336 231   2]\n",
            " [  3  17 172 190   2]]\n",
            "[[398 250 662 563   2]\n",
            " [351  98 671 353   0]\n",
            " [ 47  34 596 336   1]]\n",
            "[[ 136  455 1537 1846    2]]\n",
            "[[  4 146 757 828   0]]\n",
            "epoch:15 step:   41/60, lr:0.000014, giou_loss:   1.50, conf_loss:  18.22, prob_loss:   2.35, total_loss:  22.08\n",
            "[[115  14 316 219   2]]\n",
            "[[ 53  47 385 376   2]]\n",
            "[[134 208 896 943   2]]\n",
            "[[164  73 428 345   2]]\n",
            "epoch:15 step:   42/60, lr:0.000014, giou_loss:   0.65, conf_loss:  17.60, prob_loss:   2.73, total_loss:  20.97\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[338  67 676 428   2]\n",
            " [ 28  27 380 390   2]]\n",
            "[[217   4 459 259   2]\n",
            " [436  69 662 325   0]\n",
            " [ 50 149 623 449   1]]\n",
            "[[403  59 754 432   0]\n",
            " [ 30  83 437 514   0]]\n",
            "epoch:15 step:   43/60, lr:0.000014, giou_loss:   1.48, conf_loss:  18.32, prob_loss:   1.42, total_loss:  21.22\n",
            "[[ 168    1 1126  741    2]\n",
            " [   0  643  798 1066    2]]\n",
            "[[ 75  32 257 243   0]]\n",
            "[[ 555   50 1100  567    2]]\n",
            "[[  4  47 410 466   0]]\n",
            "epoch:15 step:   44/60, lr:0.000014, giou_loss:   1.03, conf_loss:  18.15, prob_loss:   2.31, total_loss:  21.49\n",
            "[[  3  99 182 269   2]]\n",
            "[[331 342 895 922   0]\n",
            " [ 12 305 524 794   0]]\n",
            "[[ 10   2 197 204   2]]\n",
            "[[  18   26 1198  492    1]]\n",
            "epoch:15 step:   45/60, lr:0.000014, giou_loss:   1.06, conf_loss:  17.48, prob_loss:   1.65, total_loss:  20.18\n",
            "[[  6   9 303 296   0]]\n",
            "[[279 129 503 360   1]\n",
            " [ 10 155 383 341   1]\n",
            " [ 43  80 418 228   1]]\n",
            "[[117 258 587 700   0]]\n",
            "[[165  80 743 592   2]]\n",
            "epoch:15 step:   46/60, lr:0.000014, giou_loss:   1.62, conf_loss:  18.56, prob_loss:   1.58, total_loss:  21.76\n",
            "[[  3   1 227 243   2]]\n",
            "[[ 26  39 313 325   0]]\n",
            "[[ 54  73 428 451   2]\n",
            " [196  44 853 258   1]\n",
            " [250 177 836 461   1]]\n",
            "[[ 11 152 614 763   2]]\n",
            "epoch:15 step:   47/60, lr:0.000014, giou_loss:   1.47, conf_loss:  17.69, prob_loss:   0.71, total_loss:  19.88\n",
            "[[ 29 147 586 381   1]]\n",
            "[[254 231 617 720   1]]\n",
            "[[110 108 662 382   1]]\n",
            "[[ 32  16 520 323   1]]\n",
            "epoch:15 step:   48/60, lr:0.000014, giou_loss:   0.90, conf_loss:  18.22, prob_loss:   2.37, total_loss:  21.49\n",
            "[[  5  44 318 170   1]\n",
            " [157  63 380 278   1]\n",
            " [ 42  72 334 221   1]]\n",
            "[[ 39  16 125 104   2]\n",
            " [ 71   3 149  94   2]]\n",
            "[[201  48 627 379   1]]\n",
            "[[ 10  12 494 302   1]]\n",
            "epoch:15 step:   49/60, lr:0.000014, giou_loss:   1.64, conf_loss:  18.89, prob_loss:   1.96, total_loss:  22.50\n",
            "[[370   7 835 463   2]]\n",
            "[[ 17  79 410 481   2]]\n",
            "[[ 74 178 468 559   2]\n",
            " [550 164 951 550   0]\n",
            " [166 604 847 966   1]]\n",
            "[[ 35 107 226 296   2]\n",
            " [148  99 308 277   2]]\n",
            "epoch:15 step:   50/60, lr:0.000014, giou_loss:   1.61, conf_loss:  17.31, prob_loss:   1.90, total_loss:  20.82\n",
            "[[  9  20 413 164   1]]\n",
            "[[ 87 137 325 415   2]\n",
            " [347 127 603 398   2]]\n",
            "[[ 795    2 1218  409    2]\n",
            " [ 367   99  751  526    2]\n",
            " [ 327  485  807  917    2]]\n",
            "[[355 179 531 349   0]\n",
            " [196 186 363 338   0]\n",
            " [434 174 588 314   0]\n",
            " [ 30 129 164 277   0]]\n",
            "epoch:15 step:   51/60, lr:0.000013, giou_loss:   4.45, conf_loss:  24.19, prob_loss:   4.93, total_loss:  33.57\n",
            "[[1554  294 3019 1868    2]]\n",
            "[[ 21   1 270 233   2]]\n",
            "[[204 127 286 215   2]\n",
            " [146 124 219 199   2]\n",
            " [ 16  10 246 106   1]\n",
            " [  5 145  99 236   0]]\n",
            "[[ 65  57 293 290   2]]\n",
            "epoch:15 step:   52/60, lr:0.000013, giou_loss:   2.05, conf_loss:  19.10, prob_loss:   5.75, total_loss:  26.90\n",
            "[[  2  70 170 240   0]]\n",
            "[[  5  26 261 282   0]]\n",
            "[[  7  29 203 212   0]]\n",
            "[[ 58 148 665 751   0]]\n",
            "epoch:15 step:   53/60, lr:0.000013, giou_loss:   0.64, conf_loss:  17.97, prob_loss:   3.40, total_loss:  22.02\n",
            "[[309  52 621 340   2]\n",
            " [ 64 204 889 400   1]\n",
            " [ 36 323 879 531   1]]\n",
            "[[  9 127 428 321   1]\n",
            " [100  64 422 201   1]\n",
            " [106   9 381 144   1]]\n",
            "[[602  16 898 288   1]\n",
            " [141  46 409 389   1]\n",
            " [224  64 513 408   1]\n",
            " [253 144 513 538   1]\n",
            " [467 131 637 557   1]\n",
            " [533 130 824 465   1]\n",
            " [487  45 860 326   1]]\n",
            "[[176 252 688 809   0]]\n",
            "epoch:15 step:   54/60, lr:0.000013, giou_loss:   5.73, conf_loss:  25.40, prob_loss:  10.17, total_loss:  41.31\n",
            "[[180 140 350 318   0]\n",
            " [112  88 278 272   0]]\n",
            "[[ 22  47 132 157   0]\n",
            " [ 99  20 200 115   0]\n",
            " [204  33 308 144   0]]\n",
            "[[  82  391 2538 4281    1]]\n",
            "[[  3   7 691 527   1]\n",
            " [429   7 858 527   1]]\n",
            "epoch:15 step:   55/60, lr:0.000013, giou_loss:   2.35, conf_loss:  19.09, prob_loss:   3.73, total_loss:  25.17\n",
            "[[273 332 438 527   2]\n",
            " [ 87 327 280 550   0]\n",
            " [ 33 545 578 798   1]]\n",
            "[[241  46 437 291   1]]\n",
            "[[ 68  18 275 226   0]]\n",
            "[[ 44   6 318 273   2]]\n",
            "epoch:15 step:   56/60, lr:0.000013, giou_loss:   1.76, conf_loss:  18.23, prob_loss:   2.56, total_loss:  22.55\n",
            "[[ 84  13 391 345   0]]\n",
            "[[145  18 565 394   2]\n",
            " [ 18 271 965 573   1]\n",
            " [521  59 890 371   0]]\n",
            "[[ 40   7 427 200   1]\n",
            " [511  79 660 241   1]\n",
            " [ 31 126 573 315   1]]\n",
            "[[ 289  215 1943 1112    1]\n",
            " [   9  264 1522 1332    1]\n",
            " [ 406  189 1999  768    1]]\n",
            "epoch:15 step:   57/60, lr:0.000013, giou_loss:   3.00, conf_loss:  19.76, prob_loss:   4.37, total_loss:  27.12\n",
            "[[ 50  61 228 239   2]\n",
            " [253  75 421 218   0]\n",
            " [ 50 292 362 416   1]]\n",
            "[[165  86 377 291   2]]\n",
            "[[ 19   1 719 708   0]]\n",
            "[[163  40 606 435   1]]\n",
            "epoch:15 step:   58/60, lr:0.000013, giou_loss:   1.46, conf_loss:  18.11, prob_loss:   0.79, total_loss:  20.36\n",
            "[[155   8 817 711   2]]\n",
            "[[ 493  172 1600  927    1]\n",
            " [ 626  591 1897 1272    1]\n",
            " [ 324    5 1299  615    1]\n",
            " [ 180    5 1044  554    1]]\n",
            "[[ 10   2 302 118   1]]\n",
            "[[332 291 700 680   2]]\n",
            "epoch:15 step:   59/60, lr:0.000013, giou_loss:   1.84, conf_loss:  18.19, prob_loss:   3.18, total_loss:  23.21\n",
            "[[ 93   1 190 106   2]]\n",
            "[[ 65  52 311 313   2]]\n",
            "[[ 57  68 227 356   1]\n",
            " [271  91 383 407   1]\n",
            " [303  51 454 308   1]\n",
            " [175 104 286 421   1]]\n",
            "[[ 36  51 352 344   1]\n",
            " [129  43 501 218   1]\n",
            " [116  39 482 298   1]\n",
            " [148  45 491 249   1]]\n",
            "epoch:15 step:    0/60, lr:0.000013, giou_loss:   3.97, conf_loss:  20.99, prob_loss:   4.24, total_loss:  29.21\n",
            "[[ 52   7 174 130   2]\n",
            " [139   5 275 149   2]]\n",
            "[[ 56  73 314 321   2]\n",
            " [357  35 656 334   2]]\n",
            "[[ 73  15 293 216   0]\n",
            " [ 38 207 256 443   0]\n",
            " [186 167 385 401   0]\n",
            " [608 288 790 503   0]\n",
            " [501 360 678 557   0]\n",
            " [336 229 577 453   0]\n",
            " [194 340 376 533   0]\n",
            " [446 415 658 588   0]]\n",
            "[[ 35  33 371 396   2]]\n",
            "epoch:15 step:    1/60, lr:0.000012, giou_loss:   4.92, conf_loss:  23.55, prob_loss:   4.65, total_loss:  33.12\n",
            "[[111  51 372 277   2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[166  92 638 559   2]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  20.55, prob_val_loss:   3.53, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[ 90   1 401 272   1]\n",
            " [ 64  61 325 349   1]]\n",
            "[[137 254 401 567   2]\n",
            " [128 102 448 357   0]\n",
            " [203  38 752 340   1]]\n",
            "[[  2  94 203 299   2]]\n",
            "[[ 44   6 190 149   2]\n",
            " [ 33 148 339 230   1]\n",
            " [194   1 331 146   0]]\n",
            "epoch:16 step:    2/60, lr:0.000012, giou_loss:   1.92, conf_loss:  19.80, prob_loss:   3.33, total_loss:  25.05\n",
            "[[ 249    8 1355 1035    0]]\n",
            "[[131  27 793 730   2]]\n",
            "[[ 44  33 240 278   1]]\n",
            "[[106  82 573 357   1]\n",
            " [116  21 549 251   1]]\n",
            "epoch:16 step:    3/60, lr:0.000012, giou_loss:   0.92, conf_loss:  17.04, prob_loss:   0.61, total_loss:  18.56\n",
            "[[ 41  16 297 272   0]]\n",
            "[[304  78 773 412   0]\n",
            " [  3  13 475 412   0]]\n",
            "[[ 289  215 1943 1112    1]\n",
            " [   9  264 1522 1332    1]\n",
            " [ 406  189 1999  768    1]]\n",
            "[[  8  83 300 199   1]]\n",
            "epoch:16 step:    4/60, lr:0.000012, giou_loss:   1.60, conf_loss:  17.66, prob_loss:   1.79, total_loss:  21.05\n",
            "[[305  91 817 648   0]]\n",
            "[[444 189 563 304   0]\n",
            " [292 209 423 334   0]\n",
            " [261  92 367 187   0]\n",
            " [165  29 300 133   0]\n",
            " [ 90  74 211 190   0]\n",
            " [193 132 307 239   0]]\n",
            "[[265 162 435 340   0]\n",
            " [197 110 363 294   0]]\n",
            "[[ 27  73 113 161   2]\n",
            " [  3  60  81 151   2]]\n",
            "epoch:16 step:    5/60, lr:0.000012, giou_loss:   5.21, conf_loss:  23.82, prob_loss:  10.33, total_loss:  39.36\n",
            "[[ 135    1 1448 1068    1]]\n",
            "[[106 104 247 345   1]\n",
            " [238  93 322 354   1]\n",
            " [328 110 401 349   1]\n",
            " [404 117 499 354   1]]\n",
            "[[374 200 736 565   0]]\n",
            "[[ 446    1 1251  214    1]]\n",
            "epoch:16 step:    6/60, lr:0.000012, giou_loss:   4.09, conf_loss:  20.84, prob_loss:   5.07, total_loss:  30.00\n",
            "[[368 137 606 415   2]\n",
            " [ 90 127 346 398   2]]\n",
            "[[215   0 719 527   0]]\n",
            "[[113  79 283 367   1]\n",
            " [327 102 439 418   1]\n",
            " [359  62 510 319   1]\n",
            " [231 115 342 432   1]]\n",
            "[[ 90 173 621 678   2]]\n",
            "epoch:16 step:    7/60, lr:0.000012, giou_loss:   4.39, conf_loss:  20.31, prob_loss:   3.40, total_loss:  28.10\n",
            "[[113 208 302 402   0]\n",
            " [ 65 121 230 306   0]\n",
            " [201 132 370 314   0]]\n",
            "[[215 181 406 370   2]\n",
            " [328 173 488 351   2]]\n",
            "[[ 477  718 1103 1856    1]]\n",
            "[[499  51 893 432   2]\n",
            " [ 16  37 417 423   0]\n",
            " [120 477 801 839   1]]\n",
            "epoch:16 step:    8/60, lr:0.000012, giou_loss:   2.55, conf_loss:  19.95, prob_loss:   2.00, total_loss:  24.50\n",
            "[[465 391 890 800   2]]\n",
            "[[  27  247  291  499    2]\n",
            " [ 733  268 1004  535    2]\n",
            " [ 543  213  796  440    2]\n",
            " [ 283  247  517  455    2]]\n",
            "[[ 41  16 269 249   2]]\n",
            "[[219  16 442 230   2]\n",
            " [420   8 647 219   0]\n",
            " [111  43 467 240   1]]\n",
            "epoch:16 step:    9/60, lr:0.000012, giou_loss:   3.84, conf_loss:  21.77, prob_loss:   8.49, total_loss:  34.10\n",
            "[[103 104 224 247   2]\n",
            " [ 97   1 203 115   2]\n",
            " [  1  62 131 187   2]\n",
            " [  1   2 111  70   2]\n",
            " [ 30 201 152 250   2]]\n",
            "[[106 156 586 360   1]]\n",
            "[[241  52 438 822   1]]\n",
            "[[ 58 238 173 337   2]\n",
            " [468 216 548 291   2]\n",
            " [442 159 540 236   2]\n",
            " [ 72 126 329 226   1]\n",
            " [110 168 344 263   1]\n",
            " [246 125 403 270   1]\n",
            " [274 175 410 304   1]\n",
            " [251  50 360 153   0]\n",
            " [361  83 475 188   0]]\n",
            "epoch:16 step:   10/60, lr:0.000012, giou_loss:   8.17, conf_loss:  27.71, prob_loss:  12.52, total_loss:  48.40\n",
            "[[194  10 336 155   0]\n",
            " [124 133 246 254   0]\n",
            " [131 249 283 373   0]\n",
            " [298 119 464 276   0]\n",
            " [ 57  39 156 129   0]\n",
            " [ 14 186  88 261   0]\n",
            " [  2  15  63  76   0]\n",
            " [  5  90  70 157   0]]\n",
            "[[  19  135 1199  601    1]]\n",
            "[[100  21 407 353   0]]\n",
            "[[ 37 104 470 533   0]]\n",
            "epoch:16 step:   11/60, lr:0.000012, giou_loss:   5.03, conf_loss:  23.69, prob_loss:   8.43, total_loss:  37.16\n",
            "[[ 47  52 379 381   2]]\n",
            "[[110  94 950 930   2]]\n",
            "[[ 58   4 269 200   2]\n",
            " [ 11 243 220 461   2]\n",
            " [188 323 400 522   2]\n",
            " [123 408 325 578   2]]\n",
            "[[ 90  92 709 706   0]]\n",
            "epoch:16 step:   12/60, lr:0.000011, giou_loss:   2.11, conf_loss:  19.30, prob_loss:   7.48, total_loss:  28.90\n",
            "[[   1  193 1043  684    1]\n",
            " [ 216  196 1159  723    1]]\n",
            "[[ 139  844  942 1665    0]\n",
            " [ 645  115 1051  731    0]\n",
            " [ 428  118  948  671    0]]\n",
            "[[204  31 500 303   1]\n",
            " [693  61 961 404   1]\n",
            " [589  79 878 423   1]\n",
            " [589 159 849 553   1]\n",
            " [465 146 635 572   1]\n",
            " [278 145 569 480   1]\n",
            " [242  60 615 341   1]]\n",
            "[[289 130 647 488   2]\n",
            " [114 108 711 565   1]]\n",
            "epoch:16 step:   13/60, lr:0.000011, giou_loss:   5.24, conf_loss:  23.64, prob_loss:   7.15, total_loss:  36.03\n",
            "[[128  16 456 318   1]\n",
            " [174  93 572 350   1]\n",
            " [188  10 500 205   1]]\n",
            "[[ 65 260 967 738   1]]\n",
            "[[ 34  55 457 384   1]]\n",
            "[[ 70  25 290 226   0]\n",
            " [ 35 217 253 453   0]\n",
            " [183 177 382 411   0]\n",
            " [605 298 787 513   0]\n",
            " [498 370 675 567   0]\n",
            " [333 239 574 463   0]\n",
            " [191 350 373 543   0]\n",
            " [443 425 655 598   0]]\n",
            "epoch:16 step:   14/60, lr:0.000011, giou_loss:   4.87, conf_loss:  22.21, prob_loss:   4.71, total_loss:  31.80\n",
            "[[ 123  221 1102 1216    0]]\n",
            "[[162 113 384 332   2]\n",
            " [ 27  98 227 320   2]]\n",
            "[[  6  51 202 234   0]]\n",
            "[[ 596   69 1174  581    2]]\n",
            "epoch:16 step:   15/60, lr:0.000011, giou_loss:   0.83, conf_loss:  17.32, prob_loss:   1.47, total_loss:  19.61\n",
            "[[ 80  67 313 286   2]]\n",
            "[[ 37  11 356 123   1]]\n",
            "[[ 41   1 543 204   1]]\n",
            "[[ 31  53 300 317   0]]\n",
            "epoch:16 step:   16/60, lr:0.000011, giou_loss:   0.95, conf_loss:  16.76, prob_loss:   0.28, total_loss:  17.99\n",
            "[[  7 163 433 377   1]]\n",
            "[[  1  11 155 156   2]]\n",
            "[[  9  41 327 345   1]]\n",
            "[[ 78  53 514 290   1]]\n",
            "epoch:16 step:   17/60, lr:0.000011, giou_loss:   0.49, conf_loss:  17.05, prob_loss:   0.33, total_loss:  17.86\n",
            "[[164  36 595 477   2]]\n",
            "[[ 61  26 494 351   1]\n",
            " [209  41 583 403   1]\n",
            " [  3  12 442 257   1]]\n",
            "[[366 133 702 503   2]\n",
            " [ 19 122 348 444   2]]\n",
            "[[ 54  72 604 624   0]\n",
            " [446  78 887 546   0]\n",
            " [683  88 960 487   0]]\n",
            "epoch:16 step:   18/60, lr:0.000011, giou_loss:   2.36, conf_loss:  19.07, prob_loss:   1.78, total_loss:  23.21\n",
            "[[ 58  77 270 282   2]]\n",
            "[[ 37  71 206 179   1]]\n",
            "[[ 15 107 503 414   1]]\n",
            "[[ 11  70 269 318   2]\n",
            " [312  32 611 331   2]]\n",
            "epoch:16 step:   19/60, lr:0.000011, giou_loss:   1.06, conf_loss:  17.97, prob_loss:   0.53, total_loss:  19.56\n",
            "[[ 108   75  680 1075    1]]\n",
            "[[115  51 441 326   0]]\n",
            "[[ 470   71  893  497    2]\n",
            " [ 158  155  638  639    0]\n",
            " [ 268  243 1157  792    1]]\n",
            "[[  1  12 337 375   2]]\n",
            "epoch:16 step:   20/60, lr:0.000011, giou_loss:   1.42, conf_loss:  18.35, prob_loss:   4.39, total_loss:  24.15\n",
            "[[ 73   4 499 335   1]]\n",
            "[[ 102   99 1969 1919    2]]\n",
            "[[  4  11 252 267   2]]\n",
            "[[129 109 632 355   1]]\n",
            "epoch:16 step:   21/60, lr:0.000011, giou_loss:   0.64, conf_loss:  17.41, prob_loss:   0.71, total_loss:  18.76\n",
            "[[ 543  276 1276 1051    2]\n",
            " [  11  239  704  971    2]]\n",
            "[[ 18  64 599 469   1]\n",
            " [ 11 195 586 678   1]]\n",
            "[[ 51   3 414 350   0]]\n",
            "[[ 315  168 1422  923    1]\n",
            " [ 448  587 1719 1268    1]\n",
            " [ 146    1 1121  611    1]\n",
            " [   2    1  866  550    1]]\n",
            "epoch:16 step:   22/60, lr:0.000011, giou_loss:   2.54, conf_loss:  20.40, prob_loss:   6.04, total_loss:  28.97\n",
            "[[196 317 575 666   0]]\n",
            "[[247  34 572 363   0]\n",
            " [ 31   1 302 292   0]]\n",
            "[[ 19  54 259 298   2]\n",
            " [268  49 522 316   2]]\n",
            "[[110   7 863 689   0]]\n",
            "epoch:16 step:   23/60, lr:0.000011, giou_loss:   1.17, conf_loss:  17.89, prob_loss:   2.34, total_loss:  21.40\n",
            "[[  49  366 2505 4256    1]]\n",
            "[[230  34 837 637   0]]\n",
            "[[307  49 570 337   0]\n",
            " [ 67  16 326 268   0]]\n",
            "[[ 57  50 239 261   0]]\n",
            "epoch:16 step:   24/60, lr:0.000010, giou_loss:   0.86, conf_loss:  17.41, prob_loss:   3.94, total_loss:  22.22\n",
            "[[ 61  36 526 492   2]]\n",
            "[[253 109 581 433   0]\n",
            " [216 394 534 659   0]\n",
            " [602 416 799 662   0]\n",
            " [467 125 726 413   0]\n",
            " [  0   9 307 360   0]]\n",
            "[[313 153 478 348   2]\n",
            " [127 148 320 371   0]\n",
            " [ 73 366 618 619   1]]\n",
            "[[  62  394 1527 1968    2]]\n",
            "epoch:16 step:   25/60, lr:0.000010, giou_loss:   3.00, conf_loss:  19.50, prob_loss:   3.97, total_loss:  26.47\n",
            "[[  3  13 285 258   0]]\n",
            "[[ 573  489 1207 1489    1]\n",
            " [ 266  310  791 1368    1]]\n",
            "[[ 184   42 1155  826    1]\n",
            " [ 497  101 1121  700    0]]\n",
            "[[  77    1 1891  924    1]]\n",
            "epoch:16 step:   26/60, lr:0.000010, giou_loss:   1.43, conf_loss:  18.12, prob_loss:   3.24, total_loss:  22.80\n",
            "[[114  48 444 380   2]]\n",
            "[[ 82  43 231 258   1]]\n",
            "[[315 197 918 808   2]]\n",
            "[[ 708   81 1253  598    2]]\n",
            "epoch:16 step:   27/60, lr:0.000010, giou_loss:   0.73, conf_loss:  17.05, prob_loss:   1.89, total_loss:  19.67\n",
            "[[369  96 825 465   2]]\n",
            "[[202  61 445 284   2]]\n",
            "[[254 231 617 720   1]]\n",
            "[[293  23 680 216   1]\n",
            " [ 60  95 209 257   1]\n",
            " [147 142 689 331   1]]\n",
            "epoch:16 step:   28/60, lr:0.000010, giou_loss:   1.95, conf_loss:  19.74, prob_loss:   2.78, total_loss:  24.47\n",
            "[[ 36  48 323 334   0]]\n",
            "[[ 27   4 204 171   0]]\n",
            "[[ 76  24 519 419   1]]\n",
            "[[216   1 916 708   0]]\n",
            "epoch:16 step:   29/60, lr:0.000010, giou_loss:   0.83, conf_loss:  17.95, prob_loss:   3.76, total_loss:  22.54\n",
            "[[263  81 912 785   0]]\n",
            "[[ 14   1 312 289   0]]\n",
            "[[118  52 520 141   1]\n",
            " [125  60 521 212   1]\n",
            " [134  96 531 305   1]\n",
            " [257 116 608 387   1]]\n",
            "[[  1  57 170 212   2]\n",
            " [120  49 280 212   2]\n",
            " [182   2 324 143   2]]\n",
            "epoch:16 step:   30/60, lr:0.000010, giou_loss:   2.24, conf_loss:  18.59, prob_loss:   1.68, total_loss:  22.51\n",
            "[[113 258 583 700   0]]\n",
            "[[104  79 463 412   1]\n",
            " [191  35 629 378   1]\n",
            " [210   4 675 222   1]]\n",
            "[[ 500  114 1179  862    0]]\n",
            "[[ 18  77 258 281   0]]\n",
            "epoch:16 step:   31/60, lr:0.000010, giou_loss:   1.19, conf_loss:  17.22, prob_loss:   1.28, total_loss:  19.69\n",
            "[[ 45  16 673 190   1]\n",
            " [100 104 687 414   1]\n",
            " [259  12 700 306   1]]\n",
            "[[  2  18 341 220   1]]\n",
            "[[ 29 107 275 332   0]\n",
            " [300 104 487 354   0]\n",
            " [151  79 372 294   0]]\n",
            "[[145 210 697 484   1]]\n",
            "epoch:16 step:   32/60, lr:0.000010, giou_loss:   2.25, conf_loss:  19.02, prob_loss:   1.05, total_loss:  22.33\n",
            "[[176  87 440 359   2]]\n",
            "[[  87   99 1444 1419    0]]\n",
            "[[ 248  368 1649 1759    2]]\n",
            "[[ 59   2 543 292   1]]\n",
            "epoch:16 step:   33/60, lr:0.000010, giou_loss:   0.68, conf_loss:  16.90, prob_loss:   0.92, total_loss:  18.50\n",
            "[[ 26  74 480 530   2]]\n",
            "[[399 238 678 519   2]\n",
            " [559  81 869 339   2]\n",
            " [583 328 916 565   2]]\n",
            "[[ 20  40 455 482   0]]\n",
            "[[ 43  11 404 302   2]]\n",
            "epoch:16 step:   34/60, lr:0.000010, giou_loss:   1.84, conf_loss:  19.70, prob_loss:   3.41, total_loss:  24.95\n",
            "[[  1  18 230 242   2]]\n",
            "[[373 181 685 469   2]\n",
            " [105 333 930 529   1]\n",
            " [115 452 958 660   1]]\n",
            "[[253  87 426 259   2]\n",
            " [ 25  93 310 376   1]\n",
            " [103   5 267 166   0]]\n",
            "[[ 18  15 341 349   0]]\n",
            "epoch:16 step:   35/60, lr:0.000010, giou_loss:   2.29, conf_loss:  19.96, prob_loss:   3.24, total_loss:  25.49\n",
            "[[190  12 422 182   1]\n",
            " [170  43 355 216   1]\n",
            " [140  56 290 246   1]\n",
            " [ 86  75 172 290   1]]\n",
            "[[117 193 422 499   0]\n",
            " [444 358 732 623   0]\n",
            " [360 222 643 477   0]]\n",
            "[[  0  76 296 394   0]]\n",
            "[[  2  15 295 131   1]]\n",
            "epoch:16 step:   36/60, lr:0.000009, giou_loss:   2.62, conf_loss:  19.74, prob_loss:   2.64, total_loss:  25.01\n",
            "[[423  84 761 445   2]\n",
            " [113  44 465 407   2]]\n",
            "[[  58   85 2790 2568    1]]\n",
            "[[  1  34 194 236   0]]\n",
            "[[ 49  12 236 214   2]]\n",
            "epoch:16 step:   37/60, lr:0.000009, giou_loss:   0.50, conf_loss:  16.80, prob_loss:   0.88, total_loss:  18.19\n",
            "[[ 15  66 383 455   2]]\n",
            "[[248  13 564 306   1]\n",
            " [ 99   5 471 180   1]\n",
            " [118   1 484 260   1]\n",
            " [109   7 452 211   1]]\n",
            "[[ 50 127 563 639   2]]\n",
            "[[ 13 106 237 337   1]\n",
            " [133 132 506 318   1]\n",
            " [ 98  57 473 205   1]]\n",
            "epoch:16 step:   38/60, lr:0.000009, giou_loss:   2.19, conf_loss:  18.78, prob_loss:   2.44, total_loss:  23.41\n",
            "[[ 12  25 614 478   1]\n",
            " [ 19   1 590 298   1]\n",
            " [ 42   5 553 214   1]\n",
            " [445 145 644 478   1]]\n",
            "[[107 148 527 590   0]]\n",
            "[[ 299  187 1872  810    1]]\n",
            "[[177  53 287 163   0]\n",
            " [109  26 210 121   0]\n",
            " [  1  39 105 150   0]]\n",
            "epoch:16 step:   39/60, lr:0.000009, giou_loss:   2.52, conf_loss:  19.10, prob_loss:   5.06, total_loss:  26.68\n",
            "[[153  48 294 205   0]\n",
            " [ 52  43 154 152   0]\n",
            " [ 92 111 203 220   0]]\n",
            "[[ 12  13 247 257   0]]\n",
            "[[ 30  33 701 290   1]]\n",
            "[[403  18 823 394   2]\n",
            " [  3 271 950 573   1]\n",
            " [ 78  59 447 371   0]]\n",
            "epoch:16 step:   40/60, lr:0.000009, giou_loss:   2.27, conf_loss:  18.93, prob_loss:   1.46, total_loss:  22.66\n",
            "[[276  18 518 273   2]\n",
            " [ 73  83 299 339   0]\n",
            " [112 163 685 463   1]]\n",
            "[[513 152 887 530   2]\n",
            " [ 88 123 745 337   1]\n",
            " [105 256 691 540   1]]\n",
            "[[ 96  47 200 154   2]]\n",
            "[[ 52   7 174 130   2]\n",
            " [139   5 275 149   2]]\n",
            "epoch:16 step:   41/60, lr:0.000009, giou_loss:   2.73, conf_loss:  18.29, prob_loss:   1.92, total_loss:  22.94\n",
            "[[  5 174 562 408   1]]\n",
            "[[ 16   1 266 256   0]]\n",
            "[[263  43 564 363   2]]\n",
            "[[ 24 152 233 373   2]\n",
            " [226 114 431 366   2]\n",
            " [102  16 321 186   2]]\n",
            "epoch:16 step:   42/60, lr:0.000009, giou_loss:   1.01, conf_loss:  17.30, prob_loss:   1.77, total_loss:  20.08\n",
            "[[ 52 131 228 320   0]]\n",
            "[[375 102 726 475   0]\n",
            " [  2 126 409 557   0]]\n",
            "[[ 28  33 277 265   2]]\n",
            "[[ 10  17 157 161   0]]\n",
            "epoch:16 step:   43/60, lr:0.000009, giou_loss:   0.49, conf_loss:  16.60, prob_loss:   1.96, total_loss:  19.04\n",
            "[[ 29  43 155 183   0]]\n",
            "[[ 55  55 461 474   0]]\n",
            "[[ 645  456 1600 1092    1]\n",
            " [ 819  660 1600 1168    1]\n",
            " [ 101  171 1281 1044    1]]\n",
            "[[184 110 582 525   0]]\n",
            "epoch:16 step:   44/60, lr:0.000009, giou_loss:   1.07, conf_loss:  17.22, prob_loss:   1.46, total_loss:  19.75\n",
            "[[  3  89 462 339   1]]\n",
            "[[ 41 110 429 285   1]]\n",
            "[[ 19  38 196 201   0]]\n",
            "[[ 58  67 822 409   1]\n",
            " [344  48 994 591   1]\n",
            " [ 18  24 774 322   1]]\n",
            "epoch:16 step:   45/60, lr:0.000009, giou_loss:   1.09, conf_loss:  16.71, prob_loss:   2.64, total_loss:  20.44\n",
            "[[190  80 375 172   1]\n",
            " [  3  79 187 173   1]]\n",
            "[[ 29   8 215 190   0]]\n",
            "[[386  96 523 255   2]\n",
            " [396  21 532 160   2]\n",
            " [ 57  91 189 236   2]\n",
            " [ 15  26 164 156   2]\n",
            " [153  48 296 192   2]\n",
            " [220 100 371 242   2]\n",
            " [302   5 435 131   2]]\n",
            "[[  7  46 190 236   2]]\n",
            "epoch:16 step:   46/60, lr:0.000009, giou_loss:   5.93, conf_loss:  23.87, prob_loss:   9.34, total_loss:  39.14\n",
            "[[ 98  33 366 310   0]]\n",
            "[[  4  29 183 201   0]]\n",
            "[[ 118   21 1625  797    1]]\n",
            "[[ 15  24 225 286   1]]\n",
            "epoch:16 step:   47/60, lr:0.000009, giou_loss:   0.73, conf_loss:  16.83, prob_loss:   2.33, total_loss:  19.88\n",
            "[[ 10  15 414 159   1]]\n",
            "[[  3 120 422 314   1]\n",
            " [ 94  57 416 194   1]\n",
            " [100   2 375 137   1]]\n",
            "[[ 85 137 488 545   2]]\n",
            "[[518 161 820 475   0]\n",
            " [121 247 400 500   0]\n",
            " [430 308 707 550   0]\n",
            " [ 20 221 260 489   0]]\n",
            "epoch:16 step:   48/60, lr:0.000009, giou_loss:   2.69, conf_loss:  19.72, prob_loss:   1.15, total_loss:  23.56\n",
            "[[ 40  10 347 308   2]]\n",
            "[[ 168    1 1126  741    2]\n",
            " [   0  643  798 1066    2]]\n",
            "[[ 60 275 293 542   0]\n",
            " [230 363 469 587   0]\n",
            " [594 257 798 489   0]\n",
            " [385 209 615 424   0]\n",
            " [173 194 366 345   0]\n",
            " [275  40 507 234   0]\n",
            " [108  73 273 238   0]]\n",
            "[[144  97 323 267   2]]\n",
            "epoch:16 step:   49/60, lr:0.000008, giou_loss:   3.45, conf_loss:  22.75, prob_loss:   5.00, total_loss:  31.20\n",
            "[[  7  14 281 281   2]]\n",
            "[[ 46  40 408 367   2]]\n",
            "[[  6  32 399 434   2]]\n",
            "[[ 89  48 613 406   1]]\n",
            "epoch:16 step:   50/60, lr:0.000008, giou_loss:   0.69, conf_loss:  16.44, prob_loss:   3.80, total_loss:  20.93\n",
            "[[  27  575  834 1514    1]\n",
            " [ 189  524 1154 1202    1]\n",
            " [ 301  399 1199  889    1]\n",
            " [ 255  212 1036  791    1]]\n",
            "[[ 63  99 261 290   2]\n",
            " [227  76 396 249   2]]\n",
            "[[ 38 146 205 323   0]\n",
            " [172 138 349 295   0]\n",
            " [112  47 291 216   0]]\n",
            "[[202 147 284 235   2]\n",
            " [144 144 217 219   2]\n",
            " [ 14  30 244 126   1]\n",
            " [  3 165  97 256   0]]\n",
            "epoch:16 step:   51/60, lr:0.000008, giou_loss:   3.56, conf_loss:  20.82, prob_loss:   2.56, total_loss:  26.95\n",
            "[[ 298   99 1032  820    2]\n",
            " [ 878   23 1566  685    2]]\n",
            "[[ 607  133 1030  540    2]\n",
            " [1074  230 1458  657    2]\n",
            " [1018  616 1498 1048    2]]\n",
            "[[477 327 787 643   2]\n",
            " [ 20 190 626 407   1]\n",
            " [ 26 248 676 503   1]\n",
            " [ 74  25 336 318   0]]\n",
            "[[  5  39 499 286   1]\n",
            " [ 28  47 254 273   1]]\n",
            "epoch:16 step:   52/60, lr:0.000008, giou_loss:   2.99, conf_loss:  21.14, prob_loss:   7.34, total_loss:  31.47\n",
            "[[ 17  10 172 157   0]]\n",
            "[[ 89  37 402 163   1]\n",
            " [ 27  56 250 271   1]\n",
            " [ 73  65 365 214   1]]\n",
            "[[ 66  20 151 114   1]\n",
            " [  1  49 134 129   1]\n",
            " [149  46 195 118   1]\n",
            " [119  26 179 110   1]]\n",
            "[[ 121  394  685  974    0]\n",
            " [ 492  357 1004  846    0]]\n",
            "epoch:16 step:   53/60, lr:0.000008, giou_loss:   2.37, conf_loss:  19.66, prob_loss:   5.90, total_loss:  27.93\n",
            "[[ 14  18 214 206   0]]\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[125 425 408 695   0]\n",
            " [252 128 500 381   0]\n",
            " [502 186 816 453   0]\n",
            " [373   4 625 227   0]\n",
            " [ 85  22 350 256   0]]\n",
            "[[ 35  26 209 201   0]\n",
            " [182  13 332 181   0]]\n",
            "epoch:16 step:   54/60, lr:0.000008, giou_loss:   5.18, conf_loss:  27.41, prob_loss:  10.67, total_loss:  43.26\n",
            "[[ 37  52 205 222   0]]\n",
            "[[108  37 405 324   0]]\n",
            "[[ 83  40 975 527   1]]\n",
            "[[ 93 111 689 778   1]]\n",
            "epoch:16 step:   55/60, lr:0.000008, giou_loss:   0.75, conf_loss:  16.39, prob_loss:   0.54, total_loss:  17.67\n",
            "[[125 133 772 497   1]]\n",
            "[[207  30 385 208   2]\n",
            " [ 14  44 182 187   0]\n",
            " [ 73 261 385 385   1]]\n",
            "[[231  11 919 531   1]\n",
            " [ 64  11 493 531   1]]\n",
            "[[ 45  39 297 298   2]]\n",
            "epoch:16 step:   56/60, lr:0.000008, giou_loss:   1.76, conf_loss:  18.16, prob_loss:   1.35, total_loss:  21.27\n",
            "[[  3   1 283 302   2]]\n",
            "[[ 53  13 150 118   2]]\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[ 29 303 513 779   0]\n",
            " [312 101 679 574   0]]\n",
            "epoch:16 step:   57/60, lr:0.000008, giou_loss:   2.81, conf_loss:  20.45, prob_loss:   9.88, total_loss:  33.14\n",
            "[[ 21 173 444 595   0]\n",
            " [289 115 613 441   0]]\n",
            "[[ 357  187 1211 1065    0]]\n",
            "[[ 900  173 1517  793    2]\n",
            " [ 354  261  942  865    2]]\n",
            "[[ 242  150 1121 1036    2]]\n",
            "epoch:16 step:   58/60, lr:0.000008, giou_loss:   1.08, conf_loss:  16.20, prob_loss:   0.87, total_loss:  18.15\n",
            "[[ 29 261 378 629   2]\n",
            " [278 298 707 649   2]\n",
            " [510 238 854 581   2]\n",
            " [254  22 694 380   2]]\n",
            "[[307 114 556 366   0]\n",
            " [ 59  99 339 372   0]]\n",
            "[[297 202 716 600   2]\n",
            " [ 41 128 296 369   2]]\n",
            "[[ 38  38 245 246   0]]\n",
            "epoch:16 step:   59/60, lr:0.000008, giou_loss:   2.67, conf_loss:  21.02, prob_loss:   8.12, total_loss:  31.82\n",
            "[[380 235 544 385   2]\n",
            " [327  17 518 213   0]\n",
            " [211  12 337 399   1]\n",
            " [ 31 130 295 458   1]\n",
            " [130  11 284 388   1]]\n",
            "[[ 65  52 311 313   2]]\n",
            "[[ 859  328 1237  739    2]\n",
            " [ 211    7  933  435    1]\n",
            " [ 233  139  903  757    1]]\n",
            "[[ 401  297 1163 1032    2]]\n",
            "epoch:16 step:    0/60, lr:0.000008, giou_loss:   3.87, conf_loss:  19.77, prob_loss:   7.59, total_loss:  31.24\n",
            "[[355 289 531 459   0]\n",
            " [196 296 363 448   0]\n",
            " [434 284 588 424   0]\n",
            " [ 30 239 164 387   0]]\n",
            "[[  1  70 406 412   1]]\n",
            "[[ 18   1 474 487   2]]\n",
            "[[ 27  55 251 297   2]]\n",
            "epoch:16 step:    1/60, lr:0.000008, giou_loss:   2.37, conf_loss:  19.20, prob_loss:   1.85, total_loss:  23.42\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[203 115 584 452   1]]\n",
            "[[150 165 923 983   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[111  51 372 277   2]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[227  62 723 500   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[145  36 421 286   2]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[279  14 562 295   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.88, prob_val_loss:   4.39, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[265 131 688 553   0]\n",
            " [ 96  73 420 399   0]]\n",
            "[[ 34  82 246 287   2]]\n",
            "[[   4   37 1184  503    1]]\n",
            "[[138  32 434 304   1]\n",
            " [627  62 895 405   1]\n",
            " [523  80 812 424   1]\n",
            " [523 160 783 554   1]\n",
            " [399 147 569 573   1]\n",
            " [212 146 503 481   1]\n",
            " [176  61 549 342   1]]\n",
            "epoch:17 step:    2/60, lr:0.000007, giou_loss:   4.32, conf_loss:  22.34, prob_loss:   4.21, total_loss:  30.87\n",
            "[[133  36 566 361   1]\n",
            " [ 44  51 418 413   1]\n",
            " [185  22 624 267   1]]\n",
            "[[  1  25 603 478   1]\n",
            " [  8   1 579 298   1]\n",
            " [ 31   5 542 214   1]\n",
            " [434 145 633 478   1]]\n",
            "[[134  75 570 312   1]]\n",
            "[[263  14 719 383   2]]\n",
            "epoch:17 step:    3/60, lr:0.000007, giou_loss:   2.26, conf_loss:  19.76, prob_loss:   4.51, total_loss:  26.53\n",
            "[[ 50  87 520 529   0]]\n",
            "[[ 446    1 1251  214    1]]\n",
            "[[  1  10 324 344   0]]\n",
            "[[  5  94 474 428   0]\n",
            " [303  29 775 428   0]]\n",
            "epoch:17 step:    4/60, lr:0.000007, giou_loss:   0.88, conf_loss:  17.56, prob_loss:   1.18, total_loss:  19.62\n",
            "[[196 317 575 666   0]]\n",
            "[[ 13  18 326 144   1]\n",
            " [165  37 388 252   1]\n",
            " [ 50  46 342 195   1]]\n",
            "[[  4  14 458 470   2]]\n",
            "[[126   2 630 529   0]]\n",
            "epoch:17 step:    5/60, lr:0.000007, giou_loss:   1.22, conf_loss:  16.50, prob_loss:   0.43, total_loss:  18.15\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[ 62   2 314 261   2]]\n",
            "[[ 32   2 181 217   1]]\n",
            "[[ 55  55 461 474   0]]\n",
            "epoch:17 step:    6/60, lr:0.000007, giou_loss:   1.85, conf_loss:  19.14, prob_loss:   5.15, total_loss:  26.14\n",
            "[[334 109 639 415   0]\n",
            " [ 24 274 312 539   0]\n",
            " [113 138 396 393   0]]\n",
            "[[  2  28 294 144   1]]\n",
            "[[ 102   99 1969 1919    2]]\n",
            "[[ 411  129 1876 1703    2]]\n",
            "epoch:17 step:    7/60, lr:0.000007, giou_loss:   1.14, conf_loss:  17.63, prob_loss:   0.64, total_loss:  19.41\n",
            "[[229 169 399 457   1]\n",
            " [ 73 192 185 508   1]\n",
            " [  2 152 153 409   1]\n",
            " [170 205 281 522   1]]\n",
            "[[120  45 481 336   2]]\n",
            "[[  61   55 1715  952    1]\n",
            " [ 482  104 1995 1172    1]\n",
            " [   5   29 1598  608    1]]\n",
            "[[  5  12 152 156   0]]\n",
            "epoch:17 step:    8/60, lr:0.000007, giou_loss:   3.67, conf_loss:  21.73, prob_loss:   5.86, total_loss:  31.27\n",
            "[[ 364 1068  998 2068    1]\n",
            " [ 780  889 1305 1947    1]]\n",
            "[[ 415  282 1032  902    2]\n",
            " [ 990  370 1578  974    2]]\n",
            "[[329 265 936 868   0]]\n",
            "[[ 177   27 1056  913    2]]\n",
            "epoch:17 step:    9/60, lr:0.000007, giou_loss:   1.79, conf_loss:  17.38, prob_loss:   1.23, total_loss:  20.39\n",
            "[[ 538  262 1271 1037    2]\n",
            " [   6  225  699  957    2]]\n",
            "[[228  82 524 400   0]]\n",
            "[[ 78  57 394 350   1]\n",
            " [171  49 543 224   1]\n",
            " [158  45 524 304   1]\n",
            " [190  51 533 255   1]]\n",
            "[[140   3 451 274   1]\n",
            " [114  63 375 351   1]]\n",
            "epoch:17 step:   10/60, lr:0.000007, giou_loss:   1.68, conf_loss:  18.17, prob_loss:   1.35, total_loss:  21.20\n",
            "[[ 63 149 519 635   2]]\n",
            "[[166 153 357 342   2]\n",
            " [279 145 439 323   2]]\n",
            "[[ 10  46 268 294   2]\n",
            " [311   8 610 307   2]]\n",
            "[[113  10 341 243   2]]\n",
            "epoch:17 step:   11/60, lr:0.000007, giou_loss:   1.23, conf_loss:  17.12, prob_loss:   4.43, total_loss:  22.78\n",
            "[[   0  456  955 1092    1]\n",
            " [   0  660  781 1168    1]\n",
            " [ 319  171 1499 1044    1]]\n",
            "[[ 12   2 281 266   0]]\n",
            "[[ 436  278 1039  889    2]]\n",
            "[[ 57  87 676 701   0]]\n",
            "epoch:17 step:   12/60, lr:0.000007, giou_loss:   1.13, conf_loss:  17.29, prob_loss:   0.64, total_loss:  19.06\n",
            "[[ 383   24  806  450    2]\n",
            " [  71  108  551  592    0]\n",
            " [ 181  196 1070  745    1]]\n",
            "[[ 93  84 263 262   0]\n",
            " [ 25  32 191 216   0]]\n",
            "[[ 21  19 190 127   1]]\n",
            "[[226 208 393 385   0]\n",
            " [ 82 200 259 357   0]\n",
            " [140 109 319 278   0]]\n",
            "epoch:17 step:   13/60, lr:0.000007, giou_loss:   2.25, conf_loss:  18.62, prob_loss:   2.92, total_loss:  23.79\n",
            "[[ 17  28 291 295   2]]\n",
            "[[  8 251 492 727   0]\n",
            " [291  49 658 522   0]]\n",
            "[[258  97 423 292   2]\n",
            " [ 72  92 265 315   0]\n",
            " [ 18 310 563 563   1]]\n",
            "[[ 72  86 912 922   2]]\n",
            "epoch:17 step:   14/60, lr:0.000007, giou_loss:   1.71, conf_loss:  18.18, prob_loss:   4.07, total_loss:  23.96\n",
            "[[406 297 521 396   2]\n",
            " [ 31 275 111 350   2]\n",
            " [ 39 218 137 295   2]\n",
            " [250 185 507 285   1]\n",
            " [235 227 469 322   1]\n",
            " [176 184 333 329   1]\n",
            " [169 234 305 363   1]\n",
            " [219 109 328 212   0]\n",
            " [104 142 218 247   0]]\n",
            "[[  6  43 303 330   0]]\n",
            "[[407 161 526 276   0]\n",
            " [255 181 386 306   0]\n",
            " [224  64 330 159   0]\n",
            " [128   1 263 105   0]\n",
            " [ 53  46 174 162   0]\n",
            " [156 104 270 211   0]]\n",
            "[[ 532    1 1044  558    0]]\n",
            "epoch:17 step:   15/60, lr:0.000007, giou_loss:  11.13, conf_loss:  33.51, prob_loss:  16.83, total_loss:  61.48\n",
            "[[ 16   8 171 155   0]]\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "[[ 80  11 972 498   1]]\n",
            "[[318  34 581 322   0]\n",
            " [ 78   1 337 253   0]]\n",
            "epoch:17 step:   16/60, lr:0.000007, giou_loss:   2.34, conf_loss:  18.88, prob_loss:   4.94, total_loss:  26.17\n",
            "[[  1  17 427 231   1]]\n",
            "[[ 297  178 1698 1569    2]]\n",
            "[[434  36 899 492   2]]\n",
            "[[382 104 519 263   2]\n",
            " [392  29 528 168   2]\n",
            " [ 53  99 185 244   2]\n",
            " [ 11  34 160 164   2]\n",
            " [149  56 292 200   2]\n",
            " [216 108 367 250   2]\n",
            " [298  13 431 139   2]]\n",
            "epoch:17 step:   17/60, lr:0.000006, giou_loss:   4.62, conf_loss:  22.91, prob_loss:   9.48, total_loss:  37.01\n",
            "[[  27  208 1600  831    1]]\n",
            "[[ 124   71 1230 1098    0]]\n",
            "[[ 57  15 393 378   2]]\n",
            "[[ 13  24 167 169   2]]\n",
            "epoch:17 step:   18/60, lr:0.000006, giou_loss:   0.58, conf_loss:  16.62, prob_loss:   2.09, total_loss:  19.29\n",
            "[[ 51 271 284 538   0]\n",
            " [221 359 460 583   0]\n",
            " [585 253 789 485   0]\n",
            " [376 205 606 420   0]\n",
            " [164 190 357 341   0]\n",
            " [266  36 498 230   0]\n",
            " [ 99  69 264 234   0]]\n",
            "[[124 186 347 400   2]\n",
            " [325 178 552 389   0]\n",
            " [ 16 213 372 410   1]]\n",
            "[[304  82 553 334   0]\n",
            " [ 56  67 336 340   0]]\n",
            "[[167  42 391 284   2]]\n",
            "epoch:17 step:   19/60, lr:0.000006, giou_loss:   4.37, conf_loss:  22.19, prob_loss:   4.96, total_loss:  31.51\n",
            "[[ 963  104 1386  511    2]\n",
            " [ 535  201  919  628    2]\n",
            " [ 495  587  975 1019    2]]\n",
            "[[164  45 607 440   1]]\n",
            "[[ 337  142 1016  890    0]]\n",
            "[[ 38  43 339 363   2]]\n",
            "epoch:17 step:   20/60, lr:0.000006, giou_loss:   1.80, conf_loss:  18.53, prob_loss:   4.74, total_loss:  25.07\n",
            "[[ 11  43 592 448   1]\n",
            " [ 24 174 599 657   1]]\n",
            "[[264  83 437 255   2]\n",
            " [ 36  89 321 372   1]\n",
            " [114   1 278 162   0]]\n",
            "[[ 63  48 273 310   1]]\n",
            "[[   2   77 2734 2560    1]]\n",
            "epoch:17 step:   21/60, lr:0.000006, giou_loss:   1.15, conf_loss:  18.87, prob_loss:   1.11, total_loss:  21.13\n",
            "[[ 71  13 291 214   0]\n",
            " [ 36 205 254 441   0]\n",
            " [184 165 383 399   0]\n",
            " [606 286 788 501   0]\n",
            " [499 358 676 555   0]\n",
            " [334 227 575 451   0]\n",
            " [192 338 374 531   0]\n",
            " [444 413 656 586   0]]\n",
            "[[ 43  10 441 425   0]]\n",
            "[[  3  40 189 222   0]]\n",
            "[[106 169 295 363   0]\n",
            " [178  82 343 267   0]\n",
            " [ 38  93 207 275   0]]\n",
            "epoch:17 step:   22/60, lr:0.000006, giou_loss:   4.55, conf_loss:  23.26, prob_loss:  10.67, total_loss:  38.48\n",
            "[[ 75  32 271 277   1]]\n",
            "[[  1   4 551 556   0]\n",
            " [393  10 834 478   0]\n",
            " [630  20 907 419   0]]\n",
            "[[106 104 247 345   1]\n",
            " [238  93 322 354   1]\n",
            " [328 110 401 349   1]\n",
            " [404 117 499 354   1]]\n",
            "[[ 29   8 262 227   2]]\n",
            "epoch:17 step:   23/60, lr:0.000006, giou_loss:   4.14, conf_loss:  21.09, prob_loss:   3.11, total_loss:  28.35\n",
            "[[  7  91 369 418   2]]\n",
            "[[324 237 888 817   0]\n",
            " [  5 200 517 689   0]]\n",
            "[[172  42 369 812   1]]\n",
            "[[ 64 101 466 190   1]\n",
            " [ 71 109 467 261   1]\n",
            " [ 80 145 477 354   1]\n",
            " [203 165 554 436   1]]\n",
            "epoch:17 step:   24/60, lr:0.000006, giou_loss:   1.85, conf_loss:  18.07, prob_loss:   0.80, total_loss:  20.73\n",
            "[[  7   5 287 306   2]]\n",
            "[[158  27 422 299   2]]\n",
            "[[105   3 227 126   2]\n",
            " [  4   1 140 145   2]]\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "epoch:17 step:   25/60, lr:0.000006, giou_loss:   1.83, conf_loss:  18.87, prob_loss:   6.86, total_loss:  27.56\n",
            "[[113  46 254 203   0]\n",
            " [ 12  41 114 150   0]\n",
            " [ 52 109 163 218   0]]\n",
            "[[210  30 872 733   2]]\n",
            "[[498 100 923 509   2]]\n",
            "[[  2  53 395 455   2]]\n",
            "epoch:17 step:   26/60, lr:0.000006, giou_loss:   1.61, conf_loss:  17.91, prob_loss:   2.76, total_loss:  22.28\n",
            "[[ 76  69 412 439   2]\n",
            " [430  58 759 380   2]]\n",
            "[[ 75  21 563 328   1]]\n",
            "[[261  89 623 454   0]]\n",
            "[[ 58  54 654 721   1]]\n",
            "epoch:17 step:   27/60, lr:0.000006, giou_loss:   1.69, conf_loss:  18.96, prob_loss:   0.88, total_loss:  21.53\n",
            "[[185  53 949 395   1]\n",
            " [ 13  34 663 577   1]\n",
            " [233  10 989 308   1]]\n",
            "[[215 209 494 490   2]\n",
            " [375  52 685 310   2]\n",
            " [399 299 732 536   2]]\n",
            "[[ 64  19 415 392   0]\n",
            " [381  43 788 474   0]]\n",
            "[[ 84 132 266 343   0]]\n",
            "epoch:17 step:   28/60, lr:0.000006, giou_loss:   2.57, conf_loss:  19.73, prob_loss:   2.90, total_loss:  25.20\n",
            "[[ 34  81 397 570   1]]\n",
            "[[ 16  98 663 462   1]]\n",
            "[[  8 121 254 346   0]\n",
            " [279 118 466 368   0]\n",
            " [130  93 351 308   0]]\n",
            "[[ 117   13 1430 1080    1]]\n",
            "epoch:17 step:   29/60, lr:0.000006, giou_loss:   1.71, conf_loss:  19.24, prob_loss:   1.81, total_loss:  22.77\n",
            "[[  1  48 532 553   2]]\n",
            "[[ 83 191 477 572   2]\n",
            " [559 177 960 563   0]\n",
            " [175 617 856 979   1]]\n",
            "[[ 170  180 1677  956    1]]\n",
            "[[  9  16 205 199   0]]\n",
            "epoch:17 step:   30/60, lr:0.000006, giou_loss:   1.08, conf_loss:  16.94, prob_loss:   2.58, total_loss:  20.61\n",
            "[[ 80  40 632 314   1]]\n",
            "[[ 58 137 267 358   2]\n",
            " [260  99 465 351   2]\n",
            " [136   1 355 171   2]]\n",
            "[[203  34 561 392   2]\n",
            " [139  12 736 469   1]]\n",
            "[[  1  93 406 435   1]]\n",
            "epoch:17 step:   31/60, lr:0.000006, giou_loss:   1.25, conf_loss:  17.91, prob_loss:   2.15, total_loss:  21.31\n",
            "[[305 252 673 641   2]]\n",
            "[[337  83 579 338   2]\n",
            " [134 148 360 404   0]\n",
            " [173 228 746 528   1]]\n",
            "[[  4  35 343 237   1]]\n",
            "[[ 48  58 225 221   0]]\n",
            "epoch:17 step:   32/60, lr:0.000006, giou_loss:   1.51, conf_loss:  16.80, prob_loss:   0.91, total_loss:  19.23\n",
            "[[ 84   6 507 335   1]]\n",
            "[[ 99 156 323 387   1]\n",
            " [219 182 592 368   1]\n",
            " [184 107 559 255   1]]\n",
            "[[253 153 581 477   0]\n",
            " [216 438 534 703   0]\n",
            " [602 460 799 706   0]\n",
            " [467 169 726 457   0]\n",
            " [  0  53 307 404   0]]\n",
            "[[ 91  54 585 301   1]\n",
            " [336  62 562 288   1]]\n",
            "epoch:17 step:   33/60, lr:0.000005, giou_loss:   3.08, conf_loss:  19.27, prob_loss:   8.68, total_loss:  31.04\n",
            "[[ 52 122 565 634   2]]\n",
            "[[  10   19 1367 1339    0]]\n",
            "[[ 36  29 213 196   0]]\n",
            "[[  1  32 672 289   1]]\n",
            "epoch:17 step:   34/60, lr:0.000005, giou_loss:   0.60, conf_loss:  16.66, prob_loss:   0.36, total_loss:  17.63\n",
            "[[  8  48 206 239   2]\n",
            " [172  25 341 198   2]]\n",
            "[[270 116 595 445   0]\n",
            " [ 54  83 325 374   0]]\n",
            "[[167  29 346 201   0]]\n",
            "[[201 124 283 212   2]\n",
            " [143 121 216 196   2]\n",
            " [ 13   7 243 103   1]\n",
            " [  2 142  96 233   0]]\n",
            "epoch:17 step:   35/60, lr:0.000005, giou_loss:   2.29, conf_loss:  18.49, prob_loss:   4.80, total_loss:  25.58\n",
            "[[140 300 489 668   2]\n",
            " [389 337 818 688   2]\n",
            " [621 277 965 620   2]\n",
            " [365  61 805 419   2]]\n",
            "[[121 161 588 436   1]\n",
            " [145 100 578 330   1]]\n",
            "[[  6  18 634 192   1]\n",
            " [ 61 106 648 416   1]\n",
            " [220  14 661 308   1]]\n",
            "[[ 12 103 133 246   2]\n",
            " [ 33   0 139 114   2]\n",
            " [105  61 235 186   2]\n",
            " [125   1 235  69   2]\n",
            " [ 84 200 206 249   2]]\n",
            "epoch:17 step:   36/60, lr:0.000005, giou_loss:   3.92, conf_loss:  21.97, prob_loss:   7.29, total_loss:  33.18\n",
            "[[  27  247  291  499    2]\n",
            " [ 733  268 1004  535    2]\n",
            " [ 543  213  796  440    2]\n",
            " [ 283  247  517  455    2]]\n",
            "[[  2  26 284 271   0]]\n",
            "[[ 31   9 280 241   2]]\n",
            "[[214  68 759 585   2]]\n",
            "epoch:17 step:   37/60, lr:0.000005, giou_loss:   2.63, conf_loss:  20.21, prob_loss:   6.56, total_loss:  29.41\n",
            "[[  4  85 757 767   0]]\n",
            "[[ 147  843  950 1664    0]\n",
            " [  38  114  444  730    0]\n",
            " [ 141  117  661  670    0]]\n",
            "[[ 13  18 311 306   0]]\n",
            "[[  3  73 483 277   1]]\n",
            "epoch:17 step:   38/60, lr:0.000005, giou_loss:   1.52, conf_loss:  18.31, prob_loss:   3.43, total_loss:  23.26\n",
            "[[ 18   5 247 229   2]]\n",
            "[[  2 119 421 313   1]\n",
            " [  8  56 330 193   1]\n",
            " [ 49   1 324 136   1]]\n",
            "[[ 103  625 2559 4515    1]]\n",
            "[[132  98 591 348   1]]\n",
            "epoch:17 step:   39/60, lr:0.000005, giou_loss:   1.23, conf_loss:  18.21, prob_loss:   0.79, total_loss:  20.23\n",
            "[[ 76  20 255 190   2]]\n",
            "[[ 283  189 1262 1184    0]]\n",
            "[[302  53 542 297   2]\n",
            " [ 39  48 293 315   2]]\n",
            "[[407  91 645 369   2]\n",
            " [129  81 385 352   2]]\n",
            "epoch:17 step:   40/60, lr:0.000005, giou_loss:   1.23, conf_loss:  17.48, prob_loss:   1.78, total_loss:  20.49\n",
            "[[ 16   6 216 194   0]]\n",
            "[[  7  63 117 173   0]\n",
            " [ 84  36 185 131   0]\n",
            " [189  49 293 160   0]]\n",
            "[[126  55 888 790   2]]\n",
            "[[ 207  160  729  494    1]\n",
            " [  30    0  571  297    1]\n",
            " [ 787    2 1198  343    1]\n",
            " [ 939  248 1198  668    1]\n",
            " [ 489  448  970  673    1]\n",
            " [   1  479  377  673    1]]\n",
            "epoch:17 step:   41/60, lr:0.000005, giou_loss:   4.10, conf_loss:  22.24, prob_loss:   5.64, total_loss:  31.99\n",
            "[[170  37 498 339   1]\n",
            " [ 54 114 452 371   1]\n",
            " [126  31 438 226   1]]\n",
            "[[ 22  59 244 278   2]\n",
            " [179  44 379 266   2]]\n",
            "[[158  54 488 386   2]]\n",
            "[[  9  38 177 208   0]]\n",
            "epoch:17 step:   42/60, lr:0.000005, giou_loss:   1.19, conf_loss:  17.41, prob_loss:   1.14, total_loss:  19.74\n",
            "[[ 10  68 348 429   2]\n",
            " [306  28 658 391   2]]\n",
            "[[ 21  21 261 225   0]]\n",
            "[[ 404   41 1092  561    1]\n",
            " [ 237   41  666  561    1]]\n",
            "[[ 75 428 358 698   0]\n",
            " [202 131 450 384   0]\n",
            " [452 189 766 456   0]\n",
            " [323   7 575 230   0]\n",
            " [ 35  25 300 259   0]]\n",
            "epoch:17 step:   43/60, lr:0.000005, giou_loss:   2.73, conf_loss:  19.96, prob_loss:   3.41, total_loss:  26.10\n",
            "[[ 36  35 210 210   0]\n",
            " [183  22 333 190   0]]\n",
            "[[141  13 384 236   2]]\n",
            "[[ 51  29 244 231   0]]\n",
            "[[162  15 266 122   2]]\n",
            "epoch:17 step:   44/60, lr:0.000005, giou_loss:   0.59, conf_loss:  15.83, prob_loss:   1.02, total_loss:  17.45\n",
            "[[196  26 338 171   0]\n",
            " [126 149 248 270   0]\n",
            " [133 265 285 389   0]\n",
            " [300 135 466 292   0]\n",
            " [ 59  55 158 145   0]\n",
            " [ 16 202  90 277   0]\n",
            " [  4  31  65  92   0]\n",
            " [  7 106  72 173   0]]\n",
            "[[ 141   57 1183  548    1]\n",
            " [  25   60  968  587    1]]\n",
            "[[ 27   9 359 338   2]]\n",
            "[[ 53   1 299 262   2]]\n",
            "epoch:17 step:   45/60, lr:0.000005, giou_loss:   5.28, conf_loss:  23.76, prob_loss:   3.84, total_loss:  32.89\n",
            "[[ 92   6 279 208   2]]\n",
            "[[131   1 438 299   2]]\n",
            "[[  91  189 1062  973    1]\n",
            " [ 404  248 1028  847    0]]\n",
            "[[188  27 514 302   0]]\n",
            "epoch:17 step:   46/60, lr:0.000005, giou_loss:   0.76, conf_loss:  16.17, prob_loss:   0.98, total_loss:  17.91\n",
            "[[130   7 550 383   2]\n",
            " [  3 260 950 562   1]\n",
            " [506  48 875 360   0]]\n",
            "[[ 36   9 343 341   0]]\n",
            "[[ 87  66 272 158   1]\n",
            " [275  65 459 159   1]]\n",
            "[[147  20 573 351   1]]\n",
            "epoch:17 step:   47/60, lr:0.000005, giou_loss:   2.35, conf_loss:  18.25, prob_loss:   2.66, total_loss:  23.26\n",
            "[[506  79 880 457   2]\n",
            " [ 81  50 738 264   1]\n",
            " [ 98 183 684 467   1]]\n",
            "[[  6  60 299 176   1]]\n",
            "[[  2  25 437 467   0]]\n",
            "[[  3  27 581 539   2]]\n",
            "epoch:17 step:   48/60, lr:0.000005, giou_loss:   1.63, conf_loss:  17.21, prob_loss:   1.05, total_loss:  19.89\n",
            "[[ 76  47 277 252   2]]\n",
            "[[ 22  71 579 305   1]]\n",
            "[[ 14  58 111 163   2]]\n",
            "[[112 137 515 545   2]]\n",
            "epoch:17 step:   49/60, lr:0.000005, giou_loss:   0.83, conf_loss:  16.43, prob_loss:   2.38, total_loss:  19.64\n",
            "[[ 57  42 292 286   0]]\n",
            "[[385  75 697 363   2]\n",
            " [117 227 942 423   1]\n",
            " [127 346 970 554   1]]\n",
            "[[205  57 416 253   2]\n",
            " [254 296 463 514   2]\n",
            " [ 74 376 286 575   2]\n",
            " [149 461 351 631   2]]\n",
            "[[ 23   7 454 448   2]]\n",
            "epoch:17 step:   50/60, lr:0.000004, giou_loss:   3.16, conf_loss:  19.07, prob_loss:   5.18, total_loss:  27.41\n",
            "[[368 229 632 542   2]\n",
            " [321  77 641 332   0]\n",
            " [ 17  13 566 315   1]]\n",
            "[[166   9 312 152   2]\n",
            " [ 17 151 323 233   1]\n",
            " [ 25   4 162 149   0]]\n",
            "[[  20   11  978  751    2]\n",
            " [ 348  653 1146 1076    2]]\n",
            "[[113  56 546 485   0]]\n",
            "epoch:17 step:   51/60, lr:0.000004, giou_loss:   1.87, conf_loss:  18.78, prob_loss:   2.74, total_loss:  23.39\n",
            "[[ 67  27 386 139   1]]\n",
            "[[ 315   64  941 1202    1]]\n",
            "[[ 650   61 1222 1061    1]]\n",
            "[[ 45 326 947 804   1]]\n",
            "epoch:17 step:   52/60, lr:0.000004, giou_loss:   1.61, conf_loss:  17.90, prob_loss:   3.03, total_loss:  22.55\n",
            "[[267   2 654 195   1]\n",
            " [ 34  74 183 236   1]\n",
            " [121 121 663 310   1]]\n",
            "[[ 48   3 411 350   0]]\n",
            "[[ 661  111 1310  815    0]]\n",
            "[[ 43 135 219 324   0]]\n",
            "epoch:17 step:   53/60, lr:0.000004, giou_loss:   1.85, conf_loss:  17.75, prob_loss:   4.84, total_loss:  24.44\n",
            "[[  5  39 253 295   2]]\n",
            "[[ 803  419 1181  830    2]\n",
            " [ 155   98  877  526    1]\n",
            " [ 177  230  847  848    1]]\n",
            "[[135  24 619 314   1]]\n",
            "[[ 28  51 154 191   0]]\n",
            "epoch:17 step:   54/60, lr:0.000004, giou_loss:   0.90, conf_loss:  16.50, prob_loss:   0.94, total_loss:  18.34\n",
            "[[ 499    2 1199  709    0]]\n",
            "[[ 18  21 336 325   1]]\n",
            "[[ 63 227 239 397   0]\n",
            " [231 234 398 386   0]\n",
            " [  6 222 160 362   0]\n",
            " [430 177 564 325   0]]\n",
            "[[342  83 701 416   1]\n",
            " [176  39 614 382   1]\n",
            " [130   8 595 226   1]]\n",
            "epoch:17 step:   55/60, lr:0.000004, giou_loss:   2.96, conf_loss:  20.12, prob_loss:   3.44, total_loss:  26.51\n",
            "[[  92    3 1906  926    1]]\n",
            "[[190  12 422 182   1]\n",
            " [170  43 355 216   1]\n",
            " [140  56 290 246   1]\n",
            " [ 86  75 172 290   1]]\n",
            "[[213  44 391 222   2]\n",
            " [ 20  58 188 201   0]\n",
            " [ 79 275 391 399   1]]\n",
            "[[269 233 688 631   2]\n",
            " [689 159 944 400   2]]\n",
            "epoch:17 step:   56/60, lr:0.000004, giou_loss:   3.03, conf_loss:  19.16, prob_loss:   3.12, total_loss:  25.32\n",
            "[[ 366  575 1173 1514    1]\n",
            " [  46  524 1011 1202    1]\n",
            " [   1  399  899  889    1]\n",
            " [ 164  212  945  791    1]]\n",
            "[[ 11  10 298 296   0]]\n",
            "[[ 36  28 292 284   0]]\n",
            "[[ 45  20 295 275   0]]\n",
            "epoch:17 step:   57/60, lr:0.000004, giou_loss:   1.43, conf_loss:  18.16, prob_loss:   1.49, total_loss:  21.07\n",
            "[[212  57 381 212   2]\n",
            " [102  49 262 212   2]\n",
            " [ 58   2 200 143   2]]\n",
            "[[ 33  33 240 241   0]]\n",
            "[[230  38 733 284   1]]\n",
            "[[ 75  50 577 253   1]]\n",
            "epoch:17 step:   58/60, lr:0.000004, giou_loss:   1.47, conf_loss:  17.27, prob_loss:   1.24, total_loss:  19.97\n",
            "[[ 60  69 243 259   2]]\n",
            "[[202  37 470 314   0]]\n",
            "[[404 265 568 415   2]\n",
            " [351  47 542 243   0]\n",
            " [235  42 361 429   1]\n",
            " [ 55 160 319 488   1]\n",
            " [154  41 308 418   1]]\n",
            "[[262 114 682 556   0]]\n",
            "epoch:17 step:   59/60, lr:0.000004, giou_loss:   3.22, conf_loss:  18.83, prob_loss:   6.87, total_loss:  28.92\n",
            "[[ 66  46 151 140   1]\n",
            " [  1  75 134 155   1]\n",
            " [149  72 195 144   1]\n",
            " [119  52 179 136   1]]\n",
            "[[  7  27 411 171   1]]\n",
            "[[ 28 115 114 203   2]\n",
            " [ 60 102 138 193   2]]\n",
            "[[103 138 491 313   1]]\n",
            "epoch:17 step:    0/60, lr:0.000004, giou_loss:   2.41, conf_loss:  20.16, prob_loss:   3.40, total_loss:  25.97\n",
            "[[ 379  168 1486  923    1]\n",
            " [ 512  587 1783 1268    1]\n",
            " [ 210    1 1185  611    1]\n",
            " [  66    1  930  550    1]]\n",
            "[[ 190  118 1044  996    0]]\n",
            "[[ 17  25 541 383   1]]\n",
            "[[ 595  103 1329  824    2]\n",
            " [  61   27  749  689    2]]\n",
            "epoch:17 step:    1/60, lr:0.000004, giou_loss:   1.82, conf_loss:  18.25, prob_loss:   1.39, total_loss:  21.46\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[133 165 922 525   1]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[279  14 562 295   2]]\n",
            "[[155 105 453 436   0]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[143  40 415 346   0]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.46, prob_val_loss:   3.87, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[270 370 695 779   2]]\n",
            "[[  1 183 427 397   1]]\n",
            "[[ 92  11 388 283   1]\n",
            " [581  41 849 384   1]\n",
            " [477  59 766 403   1]\n",
            " [477 139 737 533   1]\n",
            " [353 126 523 552   1]\n",
            " [166 125 457 460   1]\n",
            " [130  40 503 321   1]]\n",
            "[[510 243 743 510   0]\n",
            " [334 331 573 555   0]\n",
            " [  5 225 209 457   0]\n",
            " [188 177 418 392   0]\n",
            " [437 162 630 313   0]\n",
            " [296   8 528 202   0]\n",
            " [530  41 695 206   0]]\n",
            "epoch:18 step:    2/60, lr:0.000004, giou_loss:   6.26, conf_loss:  25.37, prob_loss:   7.69, total_loss:  39.32\n",
            "[[  63   18 1420 1338    0]]\n",
            "[[197  94 398 299   2]]\n",
            "[[ 544  250 2009 1824    2]]\n",
            "[[ 82  43 231 258   1]]\n",
            "epoch:18 step:    3/60, lr:0.000004, giou_loss:   0.63, conf_loss:  17.01, prob_loss:   0.46, total_loss:  18.10\n",
            "[[   4    1 1818  924    1]]\n",
            "[[105 134 575 576   0]]\n",
            "[[ 71  33 584 545   2]]\n",
            "[[388  80 585 850   1]]\n",
            "epoch:18 step:    4/60, lr:0.000004, giou_loss:   0.82, conf_loss:  16.48, prob_loss:   0.25, total_loss:  17.56\n",
            "[[222   8 486 280   2]]\n",
            "[[ 16  87 256 291   0]]\n",
            "[[ 84  50 333 302   0]\n",
            " [301  35 581 308   0]]\n",
            "[[120  38 563 433   1]]\n",
            "epoch:18 step:    5/60, lr:0.000004, giou_loss:   0.69, conf_loss:  16.79, prob_loss:   0.58, total_loss:  18.05\n",
            "[[ 17   1 203 183   0]]\n",
            "[[242 140 451 361   2]\n",
            " [ 44 102 249 354   2]\n",
            " [154   4 373 174   2]]\n",
            "[[ 75  96 531 465   2]]\n",
            "[[ 85  18 396 289   1]\n",
            " [ 59  78 320 366   1]]\n",
            "epoch:18 step:    6/60, lr:0.000004, giou_loss:   1.33, conf_loss:  17.25, prob_loss:   0.95, total_loss:  19.53\n",
            "[[  0  92 405 434   1]]\n",
            "[[220  50 462 305   2]\n",
            " [ 17 115 243 371   0]\n",
            " [ 56 195 629 495   1]]\n",
            "[[ 74 178 468 559   2]\n",
            " [550 164 951 550   0]\n",
            " [166 604 847 966   1]]\n",
            "[[ 53  56 222 164   1]]\n",
            "epoch:18 step:    7/60, lr:0.000004, giou_loss:   1.82, conf_loss:  17.79, prob_loss:   0.95, total_loss:  20.55\n",
            "[[ 89 105 258 260   2]\n",
            " [208  97 368 260   2]\n",
            " [270  50 412 191   2]]\n",
            "[[ 89   7 341 266   2]]\n",
            "[[ 78 115 290 320   2]]\n",
            "[[297 202 716 600   2]\n",
            " [ 41 128 296 369   2]]\n",
            "epoch:18 step:    8/60, lr:0.000004, giou_loss:   1.94, conf_loss:  17.87, prob_loss:   6.84, total_loss:  26.65\n",
            "[[437 162 949 719   0]]\n",
            "[[  6   8 238 178   1]\n",
            " [ 73  39 258 212   1]\n",
            " [138  52 288 242   1]\n",
            " [256  71 342 286   1]]\n",
            "[[ 76   3 287 199   2]\n",
            " [ 29 242 238 460   2]\n",
            " [206 322 418 521   2]\n",
            " [141 407 343 577   2]]\n",
            "[[ 699  408 1433 1129    2]\n",
            " [ 165  332  853  994    2]]\n",
            "epoch:18 step:    9/60, lr:0.000004, giou_loss:   3.81, conf_loss:  20.62, prob_loss:   4.56, total_loss:  28.98\n",
            "[[  6  60 299 176   1]]\n",
            "[[ 36  44 429 446   2]]\n",
            "[[  6  27 412 446   0]]\n",
            "[[ 54  66 233 236   2]]\n",
            "epoch:18 step:   10/60, lr:0.000004, giou_loss:   0.41, conf_loss:  16.13, prob_loss:   0.51, total_loss:  17.05\n",
            "[[214 149 296 237   2]\n",
            " [156 146 229 221   2]\n",
            " [ 26  32 256 128   1]\n",
            " [ 15 167 109 258   0]]\n",
            "[[  5  41 109 148   2]]\n",
            "[[ 56  73 314 321   2]\n",
            " [357  35 656 334   2]]\n",
            "[[ 38 112 458 554   0]]\n",
            "epoch:18 step:   11/60, lr:0.000003, giou_loss:   1.91, conf_loss:  18.07, prob_loss:   4.99, total_loss:  24.98\n",
            "[[ 87 145 276 339   0]\n",
            " [159  58 324 243   0]\n",
            " [ 19  69 188 251   0]]\n",
            "[[214  64 437 278   2]\n",
            " [415  56 642 267   0]\n",
            " [106  91 462 288   1]]\n",
            "[[ 26  75 259 294   2]]\n",
            "[[139 125 441 439   0]\n",
            " [559 211 838 464   0]\n",
            " [252 272 529 514   0]\n",
            " [699 185 939 453   0]]\n",
            "epoch:18 step:   12/60, lr:0.000003, giou_loss:   3.03, conf_loss:  19.29, prob_loss:   3.94, total_loss:  26.27\n",
            "[[ 35  15 333 303   0]]\n",
            "[[  5 116 251 341   0]\n",
            " [276 113 463 363   0]\n",
            " [127  88 348 303   0]]\n",
            "[[ 44 120 370 395   0]]\n",
            "[[ 404  175 1511  930    1]\n",
            " [ 107  594 1378 1275    1]\n",
            " [ 705    8 1680  618    1]\n",
            " [ 960    8 1824  557    1]]\n",
            "epoch:18 step:   13/60, lr:0.000003, giou_loss:   2.23, conf_loss:  18.35, prob_loss:   4.76, total_loss:  25.34\n",
            "[[ 66  14 151 108   1]\n",
            " [  1  43 134 123   1]\n",
            " [149  40 195 112   1]\n",
            " [119  20 179 104   1]]\n",
            "[[ 26  16 180 161   2]]\n",
            "[[ 222  140 1328 1167    0]]\n",
            "[[  77  230  841  572    1]\n",
            " [ 363  211 1013  754    1]\n",
            " [  37  187  793  485    1]]\n",
            "epoch:18 step:   14/60, lr:0.000003, giou_loss:   2.22, conf_loss:  18.66, prob_loss:   3.05, total_loss:  23.93\n",
            "[[274  50 470 295   1]]\n",
            "[[329  66 667 427   2]\n",
            " [ 19  26 371 389   2]]\n",
            "[[  9   7 135 147   0]]\n",
            "[[ 320  196 1082  931    2]]\n",
            "epoch:18 step:   15/60, lr:0.000003, giou_loss:   0.80, conf_loss:  16.73, prob_loss:   1.88, total_loss:  19.41\n",
            "[[   5    1 1578  624    1]]\n",
            "[[200 111 391 300   2]\n",
            " [313 103 473 281   2]]\n",
            "[[   1   53 1181  519    1]]\n",
            "[[124  62 393 326   0]]\n",
            "epoch:18 step:   16/60, lr:0.000003, giou_loss:   1.17, conf_loss:  17.05, prob_loss:   1.11, total_loss:  19.33\n",
            "[[ 80 421 359 702   2]\n",
            " [240 264 550 522   2]\n",
            " [264 511 597 748   2]]\n",
            "[[ 28 167 580 441   1]]\n",
            "[[ 27  40 453 371   1]]\n",
            "[[199 162 423 404   2]]\n",
            "epoch:18 step:   17/60, lr:0.000003, giou_loss:   2.05, conf_loss:  19.30, prob_loss:   2.34, total_loss:  23.69\n",
            "[[ 49  10 297 266   2]]\n",
            "[[  8  43 347 245   1]]\n",
            "[[ 15  12 264 244   2]]\n",
            "[[ 10  39 189 211   0]]\n",
            "epoch:18 step:   18/60, lr:0.000003, giou_loss:   0.55, conf_loss:  16.87, prob_loss:   0.81, total_loss:  18.24\n",
            "[[ 61 138 435 516   2]\n",
            " [203 109 860 323   1]\n",
            " [257 242 843 526   1]]\n",
            "[[ 38 380 387 748   2]\n",
            " [287 417 716 768   2]\n",
            " [519 357 863 700   2]\n",
            " [263 141 703 499   2]]\n",
            "[[ 110  730  913 1551    0]\n",
            " [   1    1  407  617    0]\n",
            " [ 104    4  624  557    0]]\n",
            "[[167 269 651 745   0]\n",
            " [  1  67 368 540   0]]\n",
            "epoch:18 step:   19/60, lr:0.000003, giou_loss:   3.69, conf_loss:  20.68, prob_loss:   3.98, total_loss:  28.35\n",
            "[[  26  179  290  431    2]\n",
            " [ 732  200 1003  467    2]\n",
            " [ 542  145  795  372    2]\n",
            " [ 282  179  516  387    2]]\n",
            "[[ 18  32 128 142   0]\n",
            " [ 95   5 196 100   0]\n",
            " [200  18 304 129   0]]\n",
            "[[162 153 327 348   2]\n",
            " [320 148 513 371   0]\n",
            " [ 22 366 567 619   1]]\n",
            "[[ 35  15 422 208   1]\n",
            " [506  87 655 249   1]\n",
            " [ 26 134 568 323   1]]\n",
            "epoch:18 step:   20/60, lr:0.000003, giou_loss:   5.40, conf_loss:  23.15, prob_loss:   8.27, total_loss:  36.82\n",
            "[[ 96 234 360 547   2]\n",
            " [ 87  82 407 337   0]\n",
            " [162  18 711 320   1]]\n",
            "[[ 353  305 1232 1191    2]]\n",
            "[[107 120 193 208   2]\n",
            " [ 83 107 161 198   2]]\n",
            "[[389  77 748 410   1]\n",
            " [223  33 661 376   1]\n",
            " [177   2 642 220   1]]\n",
            "epoch:18 step:   21/60, lr:0.000003, giou_loss:   1.99, conf_loss:  18.24, prob_loss:   2.40, total_loss:  22.63\n",
            "[[ 57  35 445 210   1]]\n",
            "[[ 110   74  682 1074    1]]\n",
            "[[103 104 224 247   2]\n",
            " [ 97   1 203 115   2]\n",
            " [  1  62 131 187   2]\n",
            " [  1   2 111  70   2]\n",
            " [ 30 201 152 250   2]]\n",
            "[[ 163   61 1134  845    1]\n",
            " [ 197  120  821  719    0]]\n",
            "epoch:18 step:   22/60, lr:0.000003, giou_loss:   2.27, conf_loss:  17.84, prob_loss:   3.43, total_loss:  23.54\n",
            "[[ 39   6 161 129   2]\n",
            " [126   4 262 148   2]]\n",
            "[[  8   7 412 151   1]]\n",
            "[[ 39  97 390 470   0]\n",
            " [356 121 763 552   0]]\n",
            "[[  3  31 196 233   0]]\n",
            "epoch:18 step:   23/60, lr:0.000003, giou_loss:   0.78, conf_loss:  16.35, prob_loss:   0.53, total_loss:  17.66\n",
            "[[356  72 906 624   0]\n",
            " [ 73  78 514 546   0]\n",
            " [  0  88 277 487   0]]\n",
            "[[ 47  52 379 381   2]]\n",
            "[[  4   1 284 302   2]]\n",
            "[[134 136 741 739   0]]\n",
            "epoch:18 step:   24/60, lr:0.000003, giou_loss:   1.58, conf_loss:  19.64, prob_loss:   2.20, total_loss:  23.41\n",
            "[[150  74 378 307   2]]\n",
            "[[ 12  83 185 255   2]\n",
            " [128  89 413 372   1]\n",
            " [171   1 335 162   0]]\n",
            "[[100  21 407 353   0]]\n",
            "[[ 45  53 252 261   0]]\n",
            "epoch:18 step:   25/60, lr:0.000003, giou_loss:   1.32, conf_loss:  16.90, prob_loss:   0.65, total_loss:  18.87\n",
            "[[ 436  278 1039  889    2]]\n",
            "[[147  45 288 202   0]\n",
            " [ 46  40 148 149   0]\n",
            " [ 86 108 197 217   0]]\n",
            "[[ 428  133 1075  497    1]]\n",
            "[[ 29   1 834 214   1]]\n",
            "epoch:18 step:   26/60, lr:0.000003, giou_loss:   1.44, conf_loss:  18.39, prob_loss:   0.83, total_loss:  20.65\n",
            "[[ 99 129 522 551   0]\n",
            " [367  71 691 397   0]]\n",
            "[[ 72  60 373 380   2]]\n",
            "[[106  30 542 267   1]]\n",
            "[[176   6 322 149   2]\n",
            " [ 27 148 333 230   1]\n",
            " [ 35   1 172 146   0]]\n",
            "epoch:18 step:   27/60, lr:0.000003, giou_loss:   1.12, conf_loss:  16.41, prob_loss:   0.64, total_loss:  18.16\n",
            "[[ 82  67 613 572   2]]\n",
            "[[407 148 786 497   0]]\n",
            "[[ 17 154 436 348   1]\n",
            " [108  91 430 228   1]\n",
            " [114  36 389 171   1]]\n",
            "[[ 23  55 458 497   0]]\n",
            "epoch:18 step:   28/60, lr:0.000003, giou_loss:   1.37, conf_loss:  17.31, prob_loss:   1.27, total_loss:  19.94\n",
            "[[ 291   10 1249  750    2]\n",
            " [ 123  652  921 1075    2]]\n",
            "[[222 225 404 436   0]]\n",
            "[[ 553  120 1232  868    0]]\n",
            "[[  3  39 253 294   0]]\n",
            "epoch:18 step:   29/60, lr:0.000003, giou_loss:   0.80, conf_loss:  16.97, prob_loss:   1.90, total_loss:  19.67\n",
            "[[133 438 416 708   0]\n",
            " [260 141 508 394   0]\n",
            " [510 199 824 466   0]\n",
            " [381  17 633 240   0]\n",
            " [ 93  35 358 269   0]]\n",
            "[[ 51   3 505 459   2]]\n",
            "[[321  84 633 372   2]\n",
            " [ 53 236 878 432   1]\n",
            " [ 63 355 906 563   1]]\n",
            "[[ 233  406 1087 1284    0]]\n",
            "epoch:18 step:   30/60, lr:0.000003, giou_loss:   3.49, conf_loss:  20.21, prob_loss:   2.98, total_loss:  26.68\n",
            "[[373 104 514 345   1]\n",
            " [298  93 382 354   1]\n",
            " [219 110 292 349   1]\n",
            " [121 117 216 354   1]]\n",
            "[[158  54 488 386   2]]\n",
            "[[254 125 582 449   0]\n",
            " [217 410 535 675   0]\n",
            " [603 432 800 678   0]\n",
            " [468 141 727 429   0]\n",
            " [  1  25 308 376   0]]\n",
            "[[ 366   74  789  500    2]\n",
            " [  54  158  534  642    0]\n",
            " [ 164  246 1053  795    1]]\n",
            "epoch:18 step:   31/60, lr:0.000003, giou_loss:   5.96, conf_loss:  21.92, prob_loss:   5.00, total_loss:  32.88\n",
            "[[  4  18 151 162   0]]\n",
            "[[ 54  62 534 266   1]]\n",
            "[[ 90  20 752 723   2]]\n",
            "[[ 46  34 309 322   0]\n",
            " [290   1 549 253   0]]\n",
            "epoch:18 step:   32/60, lr:0.000003, giou_loss:   0.74, conf_loss:  16.52, prob_loss:   1.30, total_loss:  18.56\n",
            "[[  46  264 2502 4154    1]]\n",
            "[[318  86 558 330   2]\n",
            " [ 55  81 309 348   2]]\n",
            "[[   8   58  741  833    2]\n",
            " [ 580   21 1273  753    2]]\n",
            "[[ 24 202 316 318   1]]\n",
            "epoch:18 step:   33/60, lr:0.000003, giou_loss:   1.24, conf_loss:  16.76, prob_loss:   1.12, total_loss:  19.12\n",
            "[[   0   99 1867 1919    2]]\n",
            "[[ 72  14 259 216   2]]\n",
            "[[317 156 541 387   1]\n",
            " [ 48 182 421 368   1]\n",
            " [ 81 107 456 255   1]]\n",
            "[[170  37 498 339   1]\n",
            " [ 54 114 452 371   1]\n",
            " [126  31 438 226   1]]\n",
            "epoch:18 step:   34/60, lr:0.000003, giou_loss:   1.94, conf_loss:  18.21, prob_loss:   3.76, total_loss:  23.91\n",
            "[[   7  510  814 1449    1]\n",
            " [ 169  459 1134 1137    1]\n",
            " [ 281  334 1179  824    1]\n",
            " [ 235  147 1016  726    1]]\n",
            "[[ 39  40 401 367   2]]\n",
            "[[ 79  35 707 209   1]\n",
            " [ 65 123 652 433   1]\n",
            " [ 52  31 493 325   1]]\n",
            "[[ 394   36 1147  718    0]]\n",
            "epoch:18 step:   35/60, lr:0.000003, giou_loss:   2.00, conf_loss:  18.01, prob_loss:   1.05, total_loss:  21.06\n",
            "[[ 43  67 220 234   0]]\n",
            "[[  6   7 329 341   0]]\n",
            "[[254 231 617 720   1]]\n",
            "[[177 106 445 383   0]]\n",
            "epoch:18 step:   36/60, lr:0.000002, giou_loss:   0.44, conf_loss:  17.01, prob_loss:   1.75, total_loss:  19.19\n",
            "[[ 95  50 676 455   1]\n",
            " [108 181 683 664   1]]\n",
            "[[ 42  10 262 211   0]\n",
            " [  7 202 225 438   0]\n",
            " [155 162 354 396   0]\n",
            " [577 283 759 498   0]\n",
            " [470 355 647 552   0]\n",
            " [305 224 546 448   0]\n",
            " [163 335 345 528   0]\n",
            " [415 410 627 583   0]]\n",
            "[[555  31 978 438   2]\n",
            " [127 128 511 555   2]\n",
            " [ 87 514 567 946   2]]\n",
            "[[  4  39 172 209   0]]\n",
            "epoch:18 step:   37/60, lr:0.000002, giou_loss:   5.05, conf_loss:  23.92, prob_loss:   3.97, total_loss:  32.95\n",
            "[[  8   1 708 708   0]]\n",
            "[[  4   2 427 331   1]]\n",
            "[[  62   55 1716  952    1]\n",
            " [ 483  104 1996 1172    1]\n",
            " [   6   29 1599  608    1]]\n",
            "[[ 84  43 403 155   1]]\n",
            "epoch:18 step:   38/60, lr:0.000002, giou_loss:   1.37, conf_loss:  17.42, prob_loss:   1.47, total_loss:  20.26\n",
            "[[316 106 554 384   2]\n",
            " [ 38  96 294 367   2]]\n",
            "[[ 201  433 1243  924    1]\n",
            " [  85  436 1028  963    1]]\n",
            "[[  4  13 204 201   0]]\n",
            "[[ 146   13 1459 1080    1]]\n",
            "epoch:18 step:   39/60, lr:0.000002, giou_loss:   0.96, conf_loss:  17.30, prob_loss:   0.62, total_loss:  18.89\n",
            "[[  30  187 1009 1182    0]]\n",
            "[[ 19   2 195 191   0]]\n",
            "[[ 708   81 1253  598    2]]\n",
            "[[ 63  44 350 330   0]]\n",
            "epoch:18 step:   40/60, lr:0.000002, giou_loss:   0.54, conf_loss:  15.83, prob_loss:   0.61, total_loss:  16.98\n",
            "[[ 60 205 175 304   2]\n",
            " [470 183 550 258   2]\n",
            " [444 126 542 203   2]\n",
            " [ 74  93 331 193   1]\n",
            " [112 135 346 230   1]\n",
            " [248  92 405 237   1]\n",
            " [276 142 412 271   1]\n",
            " [253  17 362 120   0]\n",
            " [363  50 477 155   0]]\n",
            "[[ 36  74 655 688   0]]\n",
            "[[  5   4 234 228   2]]\n",
            "[[202  61 445 284   2]]\n",
            "epoch:18 step:   41/60, lr:0.000002, giou_loss:   6.89, conf_loss:  24.86, prob_loss:   8.49, total_loss:  40.24\n",
            "[[  5 211 562 445   1]]\n",
            "[[ 33  30 307 297   2]]\n",
            "[[173  62 606 387   1]\n",
            " [ 84  77 458 439   1]\n",
            " [225  48 664 293   1]]\n",
            "[[406 161 525 276   0]\n",
            " [254 181 385 306   0]\n",
            " [223  64 329 159   0]\n",
            " [127   1 262 105   0]\n",
            " [ 52  46 173 162   0]\n",
            " [155 104 269 211   0]]\n",
            "epoch:18 step:   42/60, lr:0.000002, giou_loss:   4.68, conf_loss:  23.26, prob_loss:   3.06, total_loss:  31.00\n",
            "[[  5   6 366 297   2]]\n",
            "[[145  28 503 386   2]\n",
            " [ 81   6 678 463   1]]\n",
            "[[ 33  49 358 378   0]\n",
            " [303  16 574 307   0]]\n",
            "[[ 48  58 225 221   0]]\n",
            "epoch:18 step:   43/60, lr:0.000002, giou_loss:   0.86, conf_loss:  16.05, prob_loss:   1.01, total_loss:  17.91\n",
            "[[506 262 670 412   2]\n",
            " [453  44 644 240   0]\n",
            " [337  39 463 426   1]\n",
            " [157 157 421 485   1]\n",
            " [256  38 410 415   1]]\n",
            "[[129  73 594 529   2]]\n",
            "[[109  48 633 406   1]]\n",
            "[[ 60  44 157 149   2]]\n",
            "epoch:18 step:   44/60, lr:0.000002, giou_loss:   3.36, conf_loss:  19.33, prob_loss:   4.66, total_loss:  27.34\n",
            "[[460 334 770 650   2]\n",
            " [  3 197 609 414   1]\n",
            " [  9 255 659 510   1]\n",
            " [ 57  32 319 325   0]]\n",
            "[[ 39  10 533 257   1]\n",
            " [284  18 510 244   1]]\n",
            "[[ 822  381 1448 1519    1]]\n",
            "[[132  96 565 525   0]]\n",
            "epoch:18 step:   45/60, lr:0.000002, giou_loss:   2.25, conf_loss:  18.35, prob_loss:   6.95, total_loss:  27.55\n",
            "[[ 36 157 206 445   1]\n",
            " [250 180 362 496   1]\n",
            " [282 140 433 397   1]\n",
            " [154 193 265 510   1]]\n",
            "[[109   3 416 301   2]]\n",
            "[[ 14  44 270 300   0]]\n",
            "[[395 232 959 812   0]\n",
            " [ 76 195 588 684   0]]\n",
            "epoch:18 step:   46/60, lr:0.000002, giou_loss:   3.43, conf_loss:  19.71, prob_loss:   3.21, total_loss:  26.35\n",
            "[[ 349  151 1750 1542    2]]\n",
            "[[ 35  25 231 208   0]]\n",
            "[[117  82 302 174   1]\n",
            " [305  81 489 175   1]]\n",
            "[[ 51   3 414 350   0]]\n",
            "epoch:18 step:   47/60, lr:0.000002, giou_loss:   1.33, conf_loss:  17.58, prob_loss:   1.85, total_loss:  20.75\n",
            "[[  8  20 464 506   2]]\n",
            "[[ 115  171  955 1007    2]]\n",
            "[[ 126  194 1633  970    1]]\n",
            "[[249  46 546 333   0]]\n",
            "epoch:18 step:   48/60, lr:0.000002, giou_loss:   0.70, conf_loss:  16.45, prob_loss:   1.19, total_loss:  18.34\n",
            "[[434   3 854 379   2]\n",
            " [ 34 256 981 558   1]\n",
            " [109  44 478 356   0]]\n",
            "[[  4  72 239 316   0]]\n",
            "[[ 25  15 208 205   2]]\n",
            "[[  7  36 438 477   2]]\n",
            "epoch:18 step:   49/60, lr:0.000002, giou_loss:   1.28, conf_loss:  16.25, prob_loss:   1.39, total_loss:  18.92\n",
            "[[ 19   6 337 310   1]]\n",
            "[[ 31  27 633 480   1]\n",
            " [ 55   3 626 300   1]\n",
            " [ 92   7 603 216   1]\n",
            " [  1 147 200 480   1]]\n",
            "[[ 95  63 597 266   1]]\n",
            "[[ 81  21 394 147   1]\n",
            " [ 19  40 242 255   1]\n",
            " [ 65  49 357 198   1]]\n",
            "epoch:18 step:   50/60, lr:0.000002, giou_loss:   1.89, conf_loss:  18.94, prob_loss:   4.90, total_loss:  25.73\n",
            "[[ 127  369  505  780    2]\n",
            " [ 431   48 1153  476    1]\n",
            " [ 461  180 1131  798    1]]\n",
            "[[130 234 300 412   0]\n",
            " [ 62 182 228 366   0]]\n",
            "[[ 725  336 1342  956    2]\n",
            " [ 179  424  767 1028    2]]\n",
            "[[300  33 616 326   1]\n",
            " [151  25 523 200   1]\n",
            " [170  21 536 280   1]\n",
            " [161  27 504 231   1]]\n",
            "epoch:18 step:   51/60, lr:0.000002, giou_loss:   2.59, conf_loss:  18.27, prob_loss:   1.72, total_loss:  22.58\n",
            "[[193  15 335 160   0]\n",
            " [123 138 245 259   0]\n",
            " [130 254 282 378   0]\n",
            " [297 124 463 281   0]\n",
            " [ 56  44 155 134   0]\n",
            " [ 13 191  87 266   0]\n",
            " [  1  20  62  81   0]\n",
            " [  4  95  69 162   0]]\n",
            "[[111  47 599 354   1]]\n",
            "[[  36  287 2768 2770    1]]\n",
            "[[   0  348  955  984    1]\n",
            " [   0  552  781 1060    1]\n",
            " [ 319   63 1499  936    1]]\n",
            "epoch:18 step:   52/60, lr:0.000002, giou_loss:   5.51, conf_loss:  23.30, prob_loss:   8.33, total_loss:  37.14\n",
            "[[104  98 241 257   2]\n",
            " [ 95  23 231 162   2]\n",
            " [438  93 570 238   2]\n",
            " [463  28 612 158   2]\n",
            " [331  50 474 194   2]\n",
            " [256 102 407 244   2]\n",
            " [192   7 325 133   2]]\n",
            "[[184 110 582 525   0]]\n",
            "[[ 85 137 488 545   2]]\n",
            "[[252 155 719 430   1]\n",
            " [276  94 709 324   1]]\n",
            "epoch:18 step:   53/60, lr:0.000002, giou_loss:   4.40, conf_loss:  23.03, prob_loss:   7.43, total_loss:  34.87\n",
            "[[ 36  10 614 522   2]]\n",
            "[[ 71 101 973 579   1]]\n",
            "[[ 470  160  992  494    1]\n",
            " [ 628    0 1169  297    1]\n",
            " [   1    2  412  343    1]\n",
            " [   1  248  260  668    1]\n",
            " [ 229  448  710  673    1]\n",
            " [ 822  479 1198  673    1]]\n",
            "[[ 82  98 541 348   1]]\n",
            "epoch:18 step:   54/60, lr:0.000002, giou_loss:   3.44, conf_loss:  21.38, prob_loss:  14.39, total_loss:  39.20\n",
            "[[175  39 678 285   1]]\n",
            "[[100  60 584 350   1]]\n",
            "[[ 181  302  830 1006    0]]\n",
            "[[ 16   8 171 155   0]]\n",
            "epoch:18 step:   55/60, lr:0.000002, giou_loss:   0.54, conf_loss:  15.58, prob_loss:   0.39, total_loss:  16.51\n",
            "[[236  96 572 466   2]\n",
            " [590  85 919 407   2]]\n",
            "[[ 91 133 459 522   2]]\n",
            "[[ 439  750 1073 1750    1]\n",
            " [ 132  571  657 1629    1]]\n",
            "[[ 45  80 937 567   1]]\n",
            "epoch:18 step:   56/60, lr:0.000002, giou_loss:   1.99, conf_loss:  19.37, prob_loss:   2.54, total_loss:  23.90\n",
            "[[ 56 113 278 332   2]\n",
            " [213  98 413 320   2]]\n",
            "[[ 53  49 231 227   2]\n",
            " [256  63 424 206   0]\n",
            " [ 53 280 365 404   1]]\n",
            "[[ 50  87 248 278   2]\n",
            " [214  64 383 237   2]]\n",
            "[[507 215 869 580   0]]\n",
            "epoch:18 step:   57/60, lr:0.000002, giou_loss:   1.58, conf_loss:  17.31, prob_loss:   1.92, total_loss:  20.81\n",
            "[[138  99 394 329   2]\n",
            " [  7   1 222 187   2]\n",
            " [384  47 583 297   2]\n",
            " [188  25 400 209   2]\n",
            " [285 272 549 398   2]]\n",
            "[[305  99 774 433   0]\n",
            " [  4  34 476 433   0]]\n",
            "[[  2  77 673 334   1]]\n",
            "[[  3  12 285 257   0]]\n",
            "epoch:18 step:   58/60, lr:0.000002, giou_loss:   2.45, conf_loss:  20.14, prob_loss:   3.04, total_loss:  25.63\n",
            "[[356   1 952 668   1]]\n",
            "[[146  72 442 390   0]]\n",
            "[[ 95 227 262 404   0]\n",
            " [229 219 406 376   0]\n",
            " [169 128 348 297   0]]\n",
            "[[ 10  10 220 272   1]]\n",
            "epoch:18 step:   59/60, lr:0.000002, giou_loss:   1.78, conf_loss:  17.85, prob_loss:   1.41, total_loss:  21.04\n",
            "[[206   4 452 265   2]]\n",
            "[[ 174  148  862  668    1]\n",
            " [ 600  148 1029  668    1]]\n",
            "[[ 86 276 262 446   0]\n",
            " [254 283 421 435   0]\n",
            " [ 29 271 183 411   0]\n",
            " [453 226 587 374   0]]\n",
            "[[141  35 315 210   0]\n",
            " [ 18  22 168 190   0]]\n",
            "epoch:18 step:    0/60, lr:0.000002, giou_loss:   2.53, conf_loss:  19.40, prob_loss:   2.13, total_loss:  24.07\n",
            "[[  9  26 345 389   2]]\n",
            "[[211 100 613 189   1]\n",
            " [210 108 606 260   1]\n",
            " [200 144 597 353   1]\n",
            " [123 164 474 435   1]]\n",
            "[[ 80 261 385 567   0]\n",
            " [407 426 695 691   0]\n",
            " [323 290 606 545   0]]\n",
            "[[ 56   1 560 528   0]]\n",
            "epoch:18 step:    1/60, lr:0.000002, giou_loss:   2.19, conf_loss:  19.33, prob_loss:   1.26, total_loss:  22.78\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[145  36 421 286   2]]\n",
            "[[143  40 415 346   0]]\n",
            "[[227  62 723 500   0]]\n",
            "[[174  20 364 199   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[150 165 923 983   2]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 10   8 344 336   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[166  92 638 559   2]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[203 115 584 452   1]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.32, prob_val_loss:   3.75, total_val_loss:    nan\n",
            "\n",
            "\n",
            "[[121 117 605 407   1]]\n",
            "[[  8  12 157 227   1]]\n",
            "[[ 551   20 1177 1158    1]]\n",
            "[[213  33 459 258   0]\n",
            " [  1  30 188 280   0]\n",
            " [116   5 337 220   0]]\n",
            "epoch:19 step:    2/60, lr:0.000002, giou_loss:   2.20, conf_loss:  20.16, prob_loss:   1.85, total_loss:  24.21\n",
            "[[ 26   9 337 280   1]\n",
            " [102  69 363 357   1]]\n",
            "[[ 19 108 690 365   1]]\n",
            "[[102  66 558 435   2]]\n",
            "[[ 65  18 693 192   1]\n",
            " [120 106 707 416   1]\n",
            " [279  14 720 308   1]]\n",
            "epoch:19 step:    3/60, lr:0.000002, giou_loss:   2.06, conf_loss:  18.51, prob_loss:   1.69, total_loss:  22.26\n",
            "[[ 66  59 392 334   0]]\n",
            "[[  76  367 1031 1003    1]\n",
            " [  76  571  857 1079    1]\n",
            " [ 395   82 1575  955    1]]\n",
            "[[268  15 655 208   1]\n",
            " [ 35  87 184 249   1]\n",
            " [122 134 664 323   1]]\n",
            "[[  0  76 296 394   0]]\n",
            "epoch:19 step:    4/60, lr:0.000002, giou_loss:   1.98, conf_loss:  18.70, prob_loss:   4.95, total_loss:  25.63\n",
            "[[ 23 341 333 657   2]\n",
            " [184 204 790 421   1]\n",
            " [134 262 784 517   1]\n",
            " [474  39 736 332   0]]\n",
            "[[ 37  36 431 417   2]\n",
            " [513  22 914 408   0]\n",
            " [129 462 810 824   1]]\n",
            "[[  2   7 252 262   0]]\n",
            "[[506 262 670 412   2]\n",
            " [453  44 644 240   0]\n",
            " [337  39 463 426   1]\n",
            " [157 157 421 485   1]\n",
            " [256  38 410 415   1]]\n",
            "epoch:19 step:    5/60, lr:0.000002, giou_loss:   3.97, conf_loss:  20.18, prob_loss:   4.64, total_loss:  28.79\n",
            "[[177  52 374 822   1]]\n",
            "[[174  98 409 342   0]]\n",
            "[[ 889  147 1461 1147    1]]\n",
            "[[203  61 372 216   2]\n",
            " [ 93  53 253 216   2]\n",
            " [ 49   6 191 147   2]]\n",
            "epoch:19 step:    6/60, lr:0.000002, giou_loss:   2.23, conf_loss:  18.39, prob_loss:   3.70, total_loss:  24.32\n",
            "[[  2  33 341 235   1]]\n",
            "[[218 128 546 452   0]\n",
            " [265 413 583 678   0]\n",
            " [  0 435 197 681   0]\n",
            " [ 73 144 332 432   0]\n",
            " [492  28 799 379   0]]\n",
            "[[ 90   1 397 299   2]]\n",
            "[[181  44 624 439   1]]\n",
            "epoch:19 step:    7/60, lr:0.000002, giou_loss:   2.20, conf_loss:  17.53, prob_loss:   0.93, total_loss:  20.66\n",
            "[[125 143 307 354   0]]\n",
            "[[ 13  40 417 184   1]]\n",
            "[[264  46 527 334   0]\n",
            " [ 24  13 283 265   0]]\n",
            "[[ 63  63 565 266   1]]\n",
            "epoch:19 step:    8/60, lr:0.000002, giou_loss:   0.91, conf_loss:  15.86, prob_loss:   4.59, total_loss:  21.36\n",
            "[[131 249 320 443   0]\n",
            " [ 83 162 248 347   0]\n",
            " [219 173 388 355   0]]\n",
            "[[ 53 128 389 491   2]]\n",
            "[[ 86 168 256 346   0]\n",
            " [ 18 116 184 300   0]]\n",
            "[[139  23 261 146   2]\n",
            " [ 38  21 174 165   2]]\n",
            "epoch:19 step:    9/60, lr:0.000002, giou_loss:   2.08, conf_loss:  18.22, prob_loss:   2.87, total_loss:  23.18\n",
            "[[  14  196 1056  687    1]\n",
            " [ 229  199 1172  726    1]]\n",
            "[[ 16  11 245 235   2]]\n",
            "[[ 11  21 291 322   2]]\n",
            "[[  66  326  828 1061    2]]\n",
            "epoch:19 step:   10/60, lr:0.000002, giou_loss:   0.83, conf_loss:  16.52, prob_loss:   1.80, total_loss:  19.15\n",
            "[[ 54  72 604 624   0]\n",
            " [446  78 887 546   0]\n",
            " [683  88 960 487   0]]\n",
            "[[ 24  81 527 327   1]]\n",
            "[[165  59 528 548   1]]\n",
            "[[103 104 224 247   2]\n",
            " [ 97   1 203 115   2]\n",
            " [  1  62 131 187   2]\n",
            " [  1   2 111  70   2]\n",
            " [ 30 201 152 250   2]]\n",
            "epoch:19 step:   11/60, lr:0.000002, giou_loss:   2.47, conf_loss:  18.57, prob_loss:   1.84, total_loss:  22.88\n",
            "[[125  58 302 221   0]]\n",
            "[[229 138 438 359   2]\n",
            " [ 31 100 236 352   2]\n",
            " [141   2 360 172   2]]\n",
            "[[  7  75 345 436   2]\n",
            " [303  35 655 398   2]]\n",
            "[[ 41   2 434 404   2]]\n",
            "epoch:19 step:   12/60, lr:0.000001, giou_loss:   1.32, conf_loss:  16.25, prob_loss:   3.45, total_loss:  21.02\n",
            "[[ 136   27 1242 1054    0]]\n",
            "[[ 207  161  729  495    1]\n",
            " [  30    1  571  298    1]\n",
            " [ 787    3 1198  344    1]\n",
            " [ 939  249 1198  669    1]\n",
            " [ 489  449  970  674    1]\n",
            " [   1  480  377  674    1]]\n",
            "[[ 46  67 420 445   2]\n",
            " [188  38 845 252   1]\n",
            " [242 171 828 455   1]]\n",
            "[[ 62  77 245 267   2]]\n",
            "epoch:19 step:   13/60, lr:0.000001, giou_loss:   4.01, conf_loss:  21.59, prob_loss:   7.31, total_loss:  32.91\n",
            "[[ 607   62 1030  469    2]\n",
            " [ 179  159  563  586    2]\n",
            " [ 139  545  619  977    2]]\n",
            "[[347  21 812 477   2]]\n",
            "[[114 289 290 459   0]\n",
            " [282 296 449 448   0]\n",
            " [ 57 284 211 424   0]\n",
            " [481 239 615 387   0]]\n",
            "[[366 225 645 506   2]\n",
            " [526  68 836 326   2]\n",
            " [550 315 883 552   2]]\n",
            "epoch:19 step:   14/60, lr:0.000001, giou_loss:   4.71, conf_loss:  24.34, prob_loss:   6.16, total_loss:  35.21\n",
            "[[   1   13 1181  479    1]]\n",
            "[[295  93 653 451   2]\n",
            " [120  71 717 528   1]]\n",
            "[[  7   5 614 608   0]]\n",
            "[[  7   4 154 148   0]]\n",
            "epoch:19 step:   15/60, lr:0.000001, giou_loss:   0.78, conf_loss:  16.92, prob_loss:   1.37, total_loss:  19.07\n",
            "[[161 170 584 592   0]\n",
            " [429 112 753 438   0]]\n",
            "[[ 13  41 419 460   0]]\n",
            "[[ 16   8 171 155   0]]\n",
            "[[ 32  25 206 200   0]\n",
            " [179  12 329 180   0]]\n",
            "epoch:19 step:   16/60, lr:0.000001, giou_loss:   1.04, conf_loss:  16.08, prob_loss:   7.12, total_loss:  24.24\n",
            "[[  1  52 406 394   1]]\n",
            "[[ 54 105 300 366   2]]\n",
            "[[257  30 573 323   1]\n",
            " [108  22 480 197   1]\n",
            " [127  18 493 277   1]\n",
            " [118  24 461 228   1]]\n",
            "[[ 103  625 2559 4515    1]]\n",
            "epoch:19 step:   17/60, lr:0.000001, giou_loss:   0.69, conf_loss:  16.81, prob_loss:   0.63, total_loss:  18.13\n",
            "[[ 65 169 498 598   0]]\n",
            "[[ 37   1 344 333   0]]\n",
            "[[  67    5 1881  928    1]]\n",
            "[[ 59  72 287 305   2]]\n",
            "epoch:19 step:   18/60, lr:0.000001, giou_loss:   0.68, conf_loss:  16.10, prob_loss:   0.27, total_loss:  17.06\n",
            "[[ 68  59 317 311   0]\n",
            " [285  44 565 317   0]]\n",
            "[[ 261  151 1768  927    1]]\n",
            "[[ 16  11 290 278   2]]\n",
            "[[390 391 815 800   2]]\n",
            "epoch:19 step:   19/60, lr:0.000001, giou_loss:   0.84, conf_loss:  16.82, prob_loss:   0.92, total_loss:  18.59\n",
            "[[ 66   1 151  95   1]\n",
            " [  1  30 134 110   1]\n",
            " [149  27 195  99   1]\n",
            " [119   7 179  91   1]]\n",
            "[[  32    3 1899 1823    2]]\n",
            "[[432 114 783 487   0]\n",
            " [ 59 138 466 569   0]]\n",
            "[[100 181 405 487   0]\n",
            " [427 346 715 611   0]\n",
            " [343 210 626 465   0]]\n",
            "epoch:19 step:   20/60, lr:0.000001, giou_loss:   2.34, conf_loss:  19.74, prob_loss:   2.41, total_loss:  24.49\n",
            "[[ 389  345 1243 1223    0]]\n",
            "[[ 708   81 1253  598    2]]\n",
            "[[ 19  37 215 220   0]]\n",
            "[[625 203 993 592   2]]\n",
            "epoch:19 step:   21/60, lr:0.000001, giou_loss:   0.61, conf_loss:  16.12, prob_loss:   0.89, total_loss:  17.62\n",
            "[[462 256 685 470   2]\n",
            " [257 248 484 459   0]\n",
            " [437 283 793 480   1]]\n",
            "[[384  96 840 582   2]]\n",
            "[[ 27   3 462 445   0]]\n",
            "[[101  65 941 901   2]]\n",
            "epoch:19 step:   22/60, lr:0.000001, giou_loss:   1.38, conf_loss:  16.95, prob_loss:   3.60, total_loss:  21.93\n",
            "[[ 92  48 405 174   1]\n",
            " [ 30  67 253 282   1]\n",
            " [ 76  76 368 225   1]]\n",
            "[[332 126 572 370   2]\n",
            " [ 69 121 323 388   2]]\n",
            "[[252  15 553 335   2]]\n",
            "[[733 247 997 499   2]\n",
            " [ 20 268 291 535   2]\n",
            " [228 213 481 440   2]\n",
            " [507 247 741 455   2]]\n",
            "epoch:19 step:   23/60, lr:0.000001, giou_loss:   3.46, conf_loss:  20.20, prob_loss:   7.61, total_loss:  31.27\n",
            "[[  62   37 1716  934    1]\n",
            " [ 483   86 1996 1154    1]\n",
            " [   6   11 1599  590    1]]\n",
            "[[ 168    1 1126  741    2]\n",
            " [   0  643  798 1066    2]]\n",
            "[[ 74  11 253 181   2]]\n",
            "[[ 351   61  774  487    2]\n",
            " [  39  145  519  629    0]\n",
            " [ 149  233 1038  782    1]]\n",
            "epoch:19 step:   24/60, lr:0.000001, giou_loss:   1.78, conf_loss:  18.25, prob_loss:   2.16, total_loss:  22.18\n",
            "[[142 121 622 325   1]]\n",
            "[[ 74  83 243 191   1]]\n",
            "[[176 179 940 521   1]\n",
            " [  4 160 654 703   1]\n",
            " [224 136 980 434   1]]\n",
            "[[146 265 698 539   1]]\n",
            "epoch:19 step:   25/60, lr:0.000001, giou_loss:   1.34, conf_loss:  18.06, prob_loss:   3.04, total_loss:  22.44\n",
            "[[ 485  178 1592  933    1]\n",
            " [ 188  597 1459 1278    1]\n",
            " [ 786   11 1761  621    1]\n",
            " [1041   11 1905  560    1]]\n",
            "[[  2  94 203 299   2]]\n",
            "[[ 39  12 658 626   0]]\n",
            "[[  7   6 430 335   1]]\n",
            "epoch:19 step:   26/60, lr:0.000001, giou_loss:   1.42, conf_loss:  17.34, prob_loss:   0.96, total_loss:  19.72\n",
            "[[  2  28 299 315   0]]\n",
            "[[206 119 288 207   2]\n",
            " [148 116 221 191   2]\n",
            " [ 18   2 248  98   1]\n",
            " [  7 137 101 228   0]]\n",
            "[[174  62 607 387   1]\n",
            " [322  77 696 439   1]\n",
            " [116  48 555 293   1]]\n",
            "[[  2   2 325 336   0]]\n",
            "epoch:19 step:   27/60, lr:0.000001, giou_loss:   2.27, conf_loss:  18.38, prob_loss:   2.11, total_loss:  22.76\n",
            "[[ 130  800  764 1800    1]\n",
            " [ 546  621 1071 1679    1]]\n",
            "[[  39   56 1396 1376    0]]\n",
            "[[ 68  55 154 143   2]\n",
            " [ 44  42 122 133   2]]\n",
            "[[ 13  12 245 182   1]\n",
            " [ 80  43 265 216   1]\n",
            " [145  56 295 246   1]\n",
            " [263  75 349 290   1]]\n",
            "epoch:19 step:   28/60, lr:0.000001, giou_loss:   3.07, conf_loss:  18.58, prob_loss:   2.43, total_loss:  24.08\n",
            "[[145  14 242 119   2]]\n",
            "[[313 111 537 342   1]\n",
            " [ 44 137 417 323   1]\n",
            " [ 77  62 452 210   1]]\n",
            "[[ 17  56 530 568   2]]\n",
            "[[344  56 991 420   1]]\n",
            "epoch:19 step:   29/60, lr:0.000001, giou_loss:   1.36, conf_loss:  17.83, prob_loss:   3.40, total_loss:  22.59\n",
            "[[  9  19 435 350   1]]\n",
            "[[1483  325 2948 1899    2]]\n",
            "[[167 324 651 800   0]\n",
            " [  1 122 368 595   0]]\n",
            "[[  7   3 161 148   2]]\n",
            "epoch:19 step:   30/60, lr:0.000001, giou_loss:   0.81, conf_loss:  16.75, prob_loss:   0.52, total_loss:  18.08\n",
            "[[ 19  21 489 463   0]]\n",
            "[[161  14 840 762   0]]\n",
            "[[575  85 877 399   0]\n",
            " [178 171 457 424   0]\n",
            " [487 232 764 474   0]\n",
            " [ 77 145 317 413   0]]\n",
            "[[ 203  115 1082 1001    2]]\n",
            "epoch:19 step:   31/60, lr:0.000001, giou_loss:   1.80, conf_loss:  17.45, prob_loss:   1.79, total_loss:  21.03\n",
            "[[  17    1 1590  624    1]]\n",
            "[[  5 150 907 628   1]]\n",
            "[[ 30  22 328 310   0]]\n",
            "[[133  76 329 321   1]]\n",
            "epoch:19 step:   32/60, lr:0.000001, giou_loss:   0.75, conf_loss:  16.58, prob_loss:   3.14, total_loss:  20.46\n",
            "[[ 97  83 533 320   1]]\n",
            "[[ 200  139  888  659    1]\n",
            " [ 626  139 1055  659    1]]\n",
            "[[238 227 405 404   0]\n",
            " [ 94 219 271 376   0]\n",
            " [152 128 331 297   0]]\n",
            "[[141  30 410 294   0]]\n",
            "epoch:19 step:   33/60, lr:0.000001, giou_loss:   1.93, conf_loss:  17.29, prob_loss:   2.42, total_loss:  21.64\n",
            "[[167 274 332 469   2]\n",
            " [325 269 518 492   0]\n",
            " [ 27 487 572 740   1]]\n",
            "[[  8  30 195 232   2]]\n",
            "[[ 73  86 285 291   2]]\n",
            "[[ 56  44 266 306   1]]\n",
            "epoch:19 step:   34/60, lr:0.000001, giou_loss:   1.80, conf_loss:  17.58, prob_loss:   2.33, total_loss:  21.71\n",
            "[[154  59 482 361   1]\n",
            " [ 38 136 436 393   1]\n",
            " [110  53 422 248   1]]\n",
            "[[ 12  26 191 198   0]]\n",
            "[[204 154 624 596   0]]\n",
            "[[304   4 966 707   2]]\n",
            "epoch:19 step:   35/60, lr:0.000001, giou_loss:   1.09, conf_loss:  16.44, prob_loss:   0.63, total_loss:  18.16\n",
            "[[ 32  67 173 308   1]\n",
            " [164  56 248 317   1]\n",
            " [254  73 327 312   1]\n",
            " [330  80 425 317   1]]\n",
            "[[318 146 680 511   0]]\n",
            "[[ 13  15 253 219   0]]\n",
            "[[ 76  14 438 341   2]]\n",
            "epoch:19 step:   36/60, lr:0.000001, giou_loss:   3.41, conf_loss:  18.87, prob_loss:   2.84, total_loss:  25.12\n",
            "[[ 79  31 322 254   2]]\n",
            "[[ 56 113 278 332   2]\n",
            " [213  98 413 320   2]]\n",
            "[[ 200  304 1171 1088    1]\n",
            " [ 234  363  858  962    0]]\n",
            "[[ 35   3 242 211   0]]\n",
            "epoch:19 step:   37/60, lr:0.000001, giou_loss:   1.14, conf_loss:  16.97, prob_loss:   1.82, total_loss:  19.93\n",
            "[[ 146  365 1547 1756    2]]\n",
            "[[ 652  153 1031  502    0]]\n",
            "[[  6   9 325 121   1]]\n",
            "[[  81   10 1394 1077    1]]\n",
            "epoch:19 step:   38/60, lr:0.000001, giou_loss:   1.20, conf_loss:  16.50, prob_loss:   0.50, total_loss:  18.19\n",
            "[[144 109 382 387   2]\n",
            " [404  99 660 370   2]]\n",
            "[[118 110 516 525   0]]\n",
            "[[ 79  23 415 393   2]\n",
            " [433  12 762 334   2]]\n",
            "[[  39  226  656  846    2]\n",
            " [ 614  314 1202  918    2]]\n",
            "epoch:19 step:   39/60, lr:0.000001, giou_loss:   1.50, conf_loss:  18.46, prob_loss:   3.91, total_loss:  23.86\n",
            "[[ 23  28 279 284   0]]\n",
            "[[  8 125 427 319   1]\n",
            " [ 99  62 421 199   1]\n",
            " [105   7 380 142   1]]\n",
            "[[ 29  14 170 171   0]\n",
            " [169   9 271 118   0]\n",
            " [120  77 231 186   0]]\n",
            "[[152  18 513 309   2]]\n",
            "epoch:19 step:   40/60, lr:0.000001, giou_loss:   1.57, conf_loss:  17.73, prob_loss:   1.46, total_loss:  20.75\n",
            "[[ 188   14  608  390    2]\n",
            " [  61  267 1008  569    1]\n",
            " [ 564   55  933  367    0]]\n",
            "[[301  57 897 724   1]]\n",
            "[[279  27 547 304   0]]\n",
            "[[186  52 588 141   1]\n",
            " [185  60 581 212   1]\n",
            " [175  96 572 305   1]\n",
            " [ 98 116 449 387   1]]\n",
            "epoch:19 step:   41/60, lr:0.000001, giou_loss:   3.38, conf_loss:  18.68, prob_loss:   3.99, total_loss:  26.06\n",
            "[[  4 126 535 631   2]]\n",
            "[[  2  74 461 324   1]]\n",
            "[[  61  410  710 1114    0]]\n",
            "[[  50   15 2782 2498    1]]\n",
            "epoch:19 step:   42/60, lr:0.000001, giou_loss:   0.54, conf_loss:  15.83, prob_loss:   0.36, total_loss:  16.72\n",
            "[[561 273 794 540   0]\n",
            " [385 361 624 585   0]\n",
            " [ 56 255 260 487   0]\n",
            " [239 207 469 422   0]\n",
            " [488 192 681 343   0]\n",
            " [347  38 579 232   0]\n",
            " [581  71 746 236   0]]\n",
            "[[ 63   5 283 206   0]\n",
            " [ 28 197 246 433   0]\n",
            " [176 157 375 391   0]\n",
            " [598 278 780 493   0]\n",
            " [491 350 668 547   0]\n",
            " [326 219 567 443   0]\n",
            " [184 330 366 523   0]\n",
            " [436 405 648 578   0]]\n",
            "[[ 15  30 215 218   0]]\n",
            "[[ 283  189 1262 1184    0]]\n",
            "epoch:19 step:   43/60, lr:0.000001, giou_loss:   6.41, conf_loss:  26.50, prob_loss:   9.53, total_loss:  42.43\n",
            "[[105  94 435 426   2]]\n",
            "[[  8  34 256 290   2]]\n",
            "[[ 340    2 1040  709    0]]\n",
            "[[ 41  67 151 177   0]\n",
            " [118  40 219 135   0]\n",
            " [223  53 327 164   0]]\n",
            "epoch:19 step:   44/60, lr:0.000001, giou_loss:   1.32, conf_loss:  17.48, prob_loss:   2.98, total_loss:  21.77\n",
            "[[ 66 168 185 283   0]\n",
            " [206 188 337 313   0]\n",
            " [262  71 368 166   0]\n",
            " [329   8 464 112   0]\n",
            " [418  53 539 169   0]\n",
            " [322 111 436 218   0]]\n",
            "[[394 215 509 314   2]\n",
            " [ 19 193  99 268   2]\n",
            " [ 27 136 125 213   2]\n",
            " [238 103 495 203   1]\n",
            " [223 145 457 240   1]\n",
            " [164 102 321 247   1]\n",
            " [157 152 293 281   1]\n",
            " [207  27 316 130   0]\n",
            " [ 92  60 206 165   0]]\n",
            "[[ 22 128 448 342   1]]\n",
            "[[301 204 613 492   2]\n",
            " [ 33 356 858 552   1]\n",
            " [ 43 475 886 683   1]]\n",
            "epoch:19 step:   45/60, lr:0.000001, giou_loss:  12.27, conf_loss:  33.34, prob_loss:  12.84, total_loss:  58.45\n",
            "[[  6   4 510 531   0]]\n",
            "[[347 126 859 683   0]]\n",
            "[[ 57  20 183 160   0]]\n",
            "[[ 28  41 196 211   0]]\n",
            "epoch:19 step:   46/60, lr:0.000001, giou_loss:   0.57, conf_loss:  16.40, prob_loss:   2.38, total_loss:  19.35\n",
            "[[189  99 445 329   2]\n",
            " [361   1 576 187   2]\n",
            " [  0  47 199 297   2]\n",
            " [183  25 395 209   2]\n",
            " [ 34 272 298 398   2]]\n",
            "[[ 99  47 363 319   2]]\n",
            "[[ 50  98 248 289   2]\n",
            " [214  75 383 248   2]]\n",
            "[[232  96 465 315   2]]\n",
            "epoch:19 step:   47/60, lr:0.000001, giou_loss:   2.18, conf_loss:  20.08, prob_loss:   6.72, total_loss:  28.98\n",
            "[[ 87 113 278 302   2]\n",
            " [  5 105 165 283   2]]\n",
            "[[  1  55 194 257   0]]\n",
            "[[ 71  21 559 328   1]]\n",
            "[[ 366  575 1173 1514    1]\n",
            " [  46  524 1011 1202    1]\n",
            " [   1  399  899  889    1]\n",
            " [ 164  212  945  791    1]]\n",
            "epoch:19 step:   48/60, lr:0.000001, giou_loss:   2.13, conf_loss:  19.23, prob_loss:   2.22, total_loss:  23.57\n",
            "[[ 541   45 1274  820    2]\n",
            " [   9    8  702  740    2]]\n",
            "[[  2   5 284 250   0]]\n",
            "[[  2 265 755 947   0]]\n",
            "[[  6  87 179 259   2]\n",
            " [122  93 407 376   1]\n",
            " [165   5 329 166   0]]\n",
            "epoch:19 step:   49/60, lr:0.000001, giou_loss:   1.14, conf_loss:  17.87, prob_loss:   1.28, total_loss:  20.28\n",
            "[[ 19  21 337 325   1]]\n",
            "[[  3  35 181 213   2]\n",
            " [206  49 374 192   0]\n",
            " [  3 266 315 390   1]]\n",
            "[[371 216 935 796   0]\n",
            " [ 52 179 564 668   0]]\n",
            "[[129  11 271 156   0]\n",
            " [219 134 341 255   0]\n",
            " [182 250 334 374   0]\n",
            " [  1 120 167 277   0]\n",
            " [309  40 408 130   0]\n",
            " [377 187 451 262   0]\n",
            " [402  16 463  77   0]\n",
            " [395  91 460 158   0]]\n",
            "epoch:19 step:   50/60, lr:0.000001, giou_loss:   5.59, conf_loss:  24.48, prob_loss:   5.51, total_loss:  35.57\n",
            "[[ 71  55 282 251   2]\n",
            " [ 24 294 233 512   2]\n",
            " [201 374 413 573   2]\n",
            " [136 459 338 629   2]]\n",
            "[[  2  50 178 239   0]]\n",
            "[[ 25  40 917 527   1]]\n",
            "[[ 47  52 379 381   2]]\n",
            "epoch:19 step:   51/60, lr:0.000001, giou_loss:   1.97, conf_loss:  18.75, prob_loss:   4.02, total_loss:  24.74\n",
            "[[  4  61 297 177   1]]\n",
            "[[498 423 781 693   0]\n",
            " [406 126 654 379   0]\n",
            " [ 90 184 404 451   0]\n",
            " [281   2 533 225   0]\n",
            " [556  20 821 254   0]]\n",
            "[[123  99 227 206   2]]\n",
            "[[  5  14 292 300   0]]\n",
            "epoch:19 step:   52/60, lr:0.000001, giou_loss:   2.14, conf_loss:  19.94, prob_loss:   3.54, total_loss:  25.62\n",
            "[[226 139 396 427   1]\n",
            " [440 162 552 478   1]\n",
            " [472 122 623 379   1]\n",
            " [344 175 455 492   1]]\n",
            "[[243  95 568 424   0]\n",
            " [ 27  62 298 353   0]]\n",
            "[[ 33  14 285 273   2]]\n",
            "[[102  10 533 451   2]]\n",
            "epoch:19 step:   53/60, lr:0.000001, giou_loss:   3.51, conf_loss:  20.66, prob_loss:   3.90, total_loss:  28.08\n",
            "[[116  44 301 136   1]\n",
            " [304  43 488 137   1]]\n",
            "[[ 30 132 254 374   2]]\n",
            "[[ 145  237  879  958    2]\n",
            " [ 725  161 1413  823    2]]\n",
            "[[ 200    1 1005  214    1]]\n",
            "epoch:19 step:   54/60, lr:0.000001, giou_loss:   1.95, conf_loss:  18.84, prob_loss:   2.08, total_loss:  22.86\n",
            "[[368  73 626 321   2]\n",
            " [ 26  35 325 334   2]]\n",
            "[[449 267 713 580   2]\n",
            " [402 115 722 370   0]\n",
            " [ 98  51 647 353   1]]\n",
            "[[205  20 447 275   2]\n",
            " [424  85 650 341   0]\n",
            " [ 38 165 611 465   1]]\n",
            "[[126 108 580 564   2]]\n",
            "epoch:19 step:   55/60, lr:0.000001, giou_loss:   1.95, conf_loss:  17.53, prob_loss:   3.73, total_loss:  23.22\n",
            "[[140 300 489 668   2]\n",
            " [389 337 818 688   2]\n",
            " [621 277 965 620   2]\n",
            " [365  61 805 419   2]]\n",
            "[[  41  808  844 1629    0]\n",
            " [ 547   79  953  695    0]\n",
            " [ 330   82  850  635    0]]\n",
            "[[286   3 649 350   0]]\n",
            "[[ 16  33 540 391   1]]\n",
            "epoch:19 step:   56/60, lr:0.000001, giou_loss:   2.42, conf_loss:  19.99, prob_loss:   2.91, total_loss:  25.32\n",
            "[[149 138 537 313   1]]\n",
            "[[ 795  369 1173  780    2]\n",
            " [ 147   48  869  476    1]\n",
            " [ 169  180  839  798    1]]\n",
            "[[599   8 895 280   1]\n",
            " [138  38 406 381   1]\n",
            " [221  56 510 400   1]\n",
            " [250 136 510 530   1]\n",
            " [464 123 634 549   1]\n",
            " [530 122 821 457   1]\n",
            " [484  37 857 318   1]]\n",
            "[[ 17  82 574 316   1]]\n",
            "epoch:19 step:   57/60, lr:0.000001, giou_loss:   4.83, conf_loss:  22.65, prob_loss:  11.16, total_loss:  38.65\n",
            "[[ 11  43 592 448   1]\n",
            " [ 24 174 599 657   1]]\n",
            "[[ 21 369 313 485   1]]\n",
            "[[388  92 525 251   2]\n",
            " [398  17 534 156   2]\n",
            " [ 59  87 191 232   2]\n",
            " [ 17  22 166 152   2]\n",
            " [155  44 298 188   2]\n",
            " [222  96 373 238   2]\n",
            " [304   1 437 127   2]]\n",
            "[[ 39  25 641 478   1]\n",
            " [ 46   1 617 298   1]\n",
            " [ 69   5 580 214   1]\n",
            " [472 145 671 478   1]]\n",
            "epoch:19 step:   58/60, lr:0.000001, giou_loss:   6.01, conf_loss:  26.44, prob_loss:   6.95, total_loss:  39.41\n",
            "[[ 91   2 585 249   1]\n",
            " [114  10 340 236   1]]\n",
            "[[153   6 299 149   2]\n",
            " [  4 148 310 230   1]\n",
            " [ 12   1 149 146   0]]\n",
            "[[  7 105 476 439   0]\n",
            " [305  40 777 439   0]]\n",
            "[[ 32  43 281 275   2]]\n",
            "epoch:19 step:   59/60, lr:0.000001, giou_loss:   1.55, conf_loss:  16.77, prob_loss:   4.27, total_loss:  22.60\n",
            "[[ 71  78 430 411   1]\n",
            " [158  34 596 377   1]\n",
            " [177   3 642 221   1]]\n",
            "[[122 147 525 555   2]]\n",
            "[[152  52 730 564   2]]\n",
            "[[ 34   4 211 171   0]]\n",
            "epoch:19 step:    0/60, lr:0.000001, giou_loss:   0.71, conf_loss:  16.15, prob_loss:   0.69, total_loss:  17.55\n",
            "[[ 39  37 225 219   0]]\n",
            "[[ 34 257 637 868   2]]\n",
            "[[273  76 692 474   2]\n",
            " [ 17   2 272 243   2]]\n",
            "[[177 187 644 462   1]\n",
            " [187 126 620 356   1]]\n",
            "epoch:19 step:    1/60, lr:0.000001, giou_loss:   1.44, conf_loss:  16.27, prob_loss:   1.37, total_loss:  19.08\n",
            "[[162  50 310 354   1]\n",
            " [ 81  16 220 348   1]]\n",
            "[[113  36 276 182   0]\n",
            " [280  83 452 255   1]\n",
            " [188  77 412 217   1]\n",
            " [172  78 395 176   1]]\n",
            "[[112 144 173 211   0]\n",
            " [250 140 322 215   0]]\n",
            "[[ 42  41 193 182   2]\n",
            " [158   1 299 109   2]\n",
            " [284  17 355 147   2]\n",
            " [  1  15  61 138   2]\n",
            " [ 34   1 172  85   2]]\n",
            "[[ 242  460  963 1229    0]]\n",
            "[[ 75  62 711 745   2]]\n",
            "[[  1   1 794 738   0]]\n",
            "[[  99   96  532  592    2]\n",
            " [ 652  196 1123  710    2]\n",
            " [ 430  108  776  525    2]]\n",
            "[[ 48 234 593 789   2]]\n",
            "[[100  64 381 190   1]\n",
            " [ 95 280 380 405   1]]\n",
            "[[145  36 421 286   2]]\n",
            "[[ 21 216 173 371   2]\n",
            " [108 160 244 310   2]\n",
            " [263 166 415 307   2]]\n",
            "[[203 115 584 452   1]]\n",
            "[[143  40 415 346   0]]\n",
            "[[ 25 135 663 543   1]\n",
            " [ 86  92 736 385   1]]\n",
            "[[155 105 453 436   0]]\n",
            "[[114 114 324 431   1]\n",
            " [ 23  56 170 422   1]]\n",
            "[[123 110 414 427   0]\n",
            " [338   1 638 242   0]]\n",
            "[[ 64  84 484 457   0]\n",
            " [550  44 850 356   0]\n",
            " [197   1 559 273   0]]\n",
            "[[ 88  41 415 393   0]]\n",
            "[[165 163 367 336   2]\n",
            " [  1 100 189 266   2]\n",
            " [167  88 329 237   2]]\n",
            "[[ 419  297 2602 1034    1]]\n",
            "[[ 71  60 175 164   0]\n",
            " [ 12  22 105 111   0]\n",
            " [134  23 243 115   0]\n",
            " [107 126 216 229   0]\n",
            " [207 138 298 229   0]]\n",
            "[[  58  124 1776 1910    0]]\n",
            "[[ 65 122 365 404   0]]\n",
            "[[ 43 134 358 455   0]]\n",
            "[[133 165 922 525   1]]\n",
            "[[ 29  11 246 348   1]]\n",
            "[[227  62 723 500   0]]\n",
            "[[ 43  57 143 160   2]\n",
            " [148  62 249 162   2]]\n",
            "[[ 85 138 553 352   1]]\n",
            "[[ 77  74 540 518   0]]\n",
            "[[ 19  68 278 343   0]]\n",
            "[[ 44 164 369 277   1]\n",
            " [ 87 220 401 355   1]]\n",
            "[[ 219  494  946 1173    0]\n",
            " [ 930  598 1667 1174    0]\n",
            " [  78  323  744  945    0]\n",
            " [1228  312 1896  916    0]]\n",
            "[[ 146  361 1112 1254    2]]\n",
            "[[133 246 337 434   2]\n",
            " [270 364 400 476   2]\n",
            " [522 344 649 470   2]\n",
            " [537 302 661 402   2]\n",
            " [328 229 544 422   0]]\n",
            "[[   1  571  923 1006    1]\n",
            " [  80    6  481  395    0]\n",
            " [ 543   17  942  430    2]]\n",
            "[[ 146  205  493  594    2]\n",
            " [ 252  528  571  821    0]\n",
            " [ 468   49 1228  287    1]\n",
            " [ 540  208 1244  464    1]\n",
            " [ 506  301 1279  574    1]]\n",
            "[[122 127 484 471   1]\n",
            " [212 115 691 407   1]\n",
            " [238  77 743 294   1]]\n",
            "[[383   3 596 308   1]\n",
            " [265  15 513 276   1]\n",
            " [516  52 762 315   1]\n",
            " [639  42 819 325   1]]\n",
            "[[  45  228 1232  658    1]]\n",
            "[[ 63  17 560 323   1]]\n",
            "[[111  51 372 277   2]]\n",
            "[[150 165 923 983   2]]\n",
            "[[ 77 183 641 716   0]]\n",
            "[[ 61 130 415 473   2]]\n",
            "[[ 17 195 202 356   2]\n",
            " [200 207 376 365   2]\n",
            " [223  52 389 217   2]\n",
            " [261 157 412 264   2]]\n",
            "[[279  14 562 295   2]]\n",
            "[[174  20 364 199   2]]\n",
            "[[  70  398 1388 1731    0]]\n",
            "[[  90  287  608  809    2]\n",
            " [ 560  217 1145  769    2]\n",
            " [ 323   37  786  551    2]]\n",
            "[[  5  12 333 353   1]]\n",
            "[[166  92 638 559   2]]\n",
            "[[ 313  228  935 1864    1]\n",
            " [ 401  129 1078 1890    1]\n",
            " [ 135  291  642 1747    1]]\n",
            "[[ 23 472 848 880   1]\n",
            " [ 66 233 878 657   1]\n",
            " [212 111 949 611   1]]\n",
            "[[  1   4 348 309   1]]\n",
            "[[228  83 401 270   2]\n",
            " [ 43  74 183 244   1]\n",
            " [128  56 282 221   0]]\n",
            "[[  1 123 130 299   2]\n",
            " [379   1 558 144   2]]\n",
            "[[ 10   8 344 336   0]]\n",
            "\n",
            "\n",
            "giou_val_loss:    nan, conf_val_loss:  19.23, prob_val_loss:   3.62, total_val_loss:    nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-3Ae77yB81l",
        "outputId": "f569a35b-21db-45e7-c6c4-150330b02b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.188984044392903"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NoPYfFSXlWw"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "MKS9tanWXjI4",
        "outputId": "b5583a2e-2088-4e7b-ecc1-fbeab2672c2c"
      },
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "YOLO_INPUT_SIZE = 416\n",
        "input_size=YOLO_INPUT_SIZE\n",
        "\n",
        "\n",
        "\n",
        "image_path =\"/content/drive/MyDrive/fruit/test/banana_77.jpg\" #image_info[0]\n",
        "\n",
        "yolo = Create_Yolov3(input_size=input_size, CLASSES=TRAIN_CLASSES)\n",
        "yolo.load_weights(\"./chkpt_fruits/yolov3_custom\")\n",
        "\n",
        "\n",
        "\n",
        "img = detect_image(yolo, image_path, \"\", input_size=input_size, show=True, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x360 at 0x7F25F0EE62D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JThlN9YaFW5c",
        "outputId": "d371f3e8-2ad0-4a0c-8f73-dbceeee210ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jHWJOLySH8Vh",
        "outputId": "1d7664c4-7a14-482a-8bb3-60c73dcb7ffe"
      },
      "source": [
        "image_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/fruit/test/banana_77.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}